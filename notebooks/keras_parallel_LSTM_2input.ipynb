{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data manipulation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_multiple_bins_for_LSTM(\n",
    "    dataframe,\n",
    "    target_column_index,\n",
    "    history_size,\n",
    "    target_size, \n",
    "    step\n",
    "):\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    spatial_bins = dataframe.groupby(['lat', 'lon'])\n",
    "    \n",
    "    for bin_name, spatial_bin in spatial_bins:\n",
    "        \n",
    "        spatial_bin = spatial_bin.sort_index()\n",
    "        \n",
    "        spatial_bin = np.array(spatial_bin.values)\n",
    "        target = spatial_bin[:, target_column_index]\n",
    "        \n",
    "        bin_data = []\n",
    "        bin_labels = []\n",
    "    \n",
    "        start_index = history_size\n",
    "        end_index = len(spatial_bin) - target_size\n",
    "\n",
    "        for i in range(start_index, end_index):\n",
    "            indices = range(i - history_size, i, step)\n",
    "            bin_data.append(spatial_bin[indices])\n",
    "            bin_labels.append(target[i + target_size])\n",
    "\n",
    "        data.append(np.array(bin_data))\n",
    "        labels.append(np.array(bin_labels))\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/training_data/1992-2015_training_data_added_features.csv'\n",
    "\n",
    "# Datatypes for dataframe loading\n",
    "dtypes = {\n",
    "    'lat': float,\n",
    "    'lon': float,\n",
    "    'weather_bin_year': int,\n",
    "    'weather_bin_month': int,\n",
    "    'weather_bin_day': int,\n",
    "    'air.2m': float,\n",
    "    'apcp': float,\n",
    "    'rhum.2m': float,\n",
    "    'dpt.2m': float,\n",
    "    'pres.sfc': float,\n",
    "    'uwnd.10m': float,\n",
    "    'vwnd.10m': float,\n",
    "    'veg': float,\n",
    "    'vis': float,\n",
    "    'ignition': float,\n",
    "    'mean.air.2m': float,\n",
    "    'mean.apcp': float,\n",
    "    'mean.rhum.2m': float,\n",
    "    'mean.dpt.2m': float,\n",
    "    'mean.pres.sfc': float,\n",
    "    'mean.uwnd.10m': float,\n",
    "    'mean.vwnd.10m': float,\n",
    "    'mean.veg': float,\n",
    "    'mean.vis': float,\n",
    "    'max.air.2m': float,\n",
    "    'max.apcp': float,\n",
    "    'max.rhum.2m': float,\n",
    "    'max.dpt.2m': float,\n",
    "    'max.pres.sfc': float,\n",
    "    'max.uwnd.10m': float,\n",
    "    'max.vwnd.10m': float,\n",
    "    'max.veg': float,\n",
    "    'max.vis': float,\n",
    "    'min.air.2m': float,\n",
    "    'min.apcp': float,\n",
    "    'min.rhum.2m': float,\n",
    "    'min.dpt.2m': float,\n",
    "    'min.pres.sfc': float,\n",
    "    'min.uwnd.10m': float,\n",
    "    'min.vwnd.10m': float,\n",
    "    'min.veg': float,\n",
    "    'min.vis': float,\n",
    "    'total_fires': float\n",
    "\n",
    "}\n",
    "\n",
    "# Features to use during training \n",
    "features = [\n",
    "    'lat',\n",
    "    'lon',\n",
    "    'weather_bin_year',\n",
    "    'weather_bin_month',\n",
    "    'weather_bin_day',\n",
    "    'veg',\n",
    "    'ignition',\n",
    "    'mean.air.2m',\n",
    "    'mean.apcp',\n",
    "    'mean.rhum.2m',\n",
    "    'mean.dpt.2m',\n",
    "    'mean.pres.sfc',\n",
    "    'mean.uwnd.10m',\n",
    "    'mean.vwnd.10m',\n",
    "    'mean.veg',\n",
    "    'mean.vis',\n",
    "    'total_fires'\n",
    "]\n",
    "\n",
    "features_to_scale = [\n",
    "    'weather_bin_year',\n",
    "    'weather_bin_month',\n",
    "    'veg',\n",
    "    'mean.air.2m',\n",
    "    'mean.apcp',\n",
    "    'mean.rhum.2m',\n",
    "    'mean.dpt.2m',\n",
    "    'mean.pres.sfc',\n",
    "    'mean.uwnd.10m',\n",
    "    'mean.vwnd.10m',\n",
    "    'mean.vis',\n",
    "    'total_fires'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(data_file, index_col=0, parse_dates=True, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>weather_bin_year</th>\n",
       "      <th>weather_bin_month</th>\n",
       "      <th>weather_bin_day</th>\n",
       "      <th>air.2m</th>\n",
       "      <th>apcp</th>\n",
       "      <th>rhum.2m</th>\n",
       "      <th>dpt.2m</th>\n",
       "      <th>pres.sfc</th>\n",
       "      <th>...</th>\n",
       "      <th>min.air.2m</th>\n",
       "      <th>min.apcp</th>\n",
       "      <th>min.rhum.2m</th>\n",
       "      <th>min.dpt.2m</th>\n",
       "      <th>min.pres.sfc</th>\n",
       "      <th>min.uwnd.10m</th>\n",
       "      <th>min.vwnd.10m</th>\n",
       "      <th>min.veg</th>\n",
       "      <th>min.vis</th>\n",
       "      <th>total_fires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>32.68389</td>\n",
       "      <td>-117.1809</td>\n",
       "      <td>1992</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>292.078990</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>77.730052</td>\n",
       "      <td>287.287171</td>\n",
       "      <td>100208.78575</td>\n",
       "      <td>...</td>\n",
       "      <td>287.399184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.981636</td>\n",
       "      <td>285.914549</td>\n",
       "      <td>100190.64825</td>\n",
       "      <td>-2.124688</td>\n",
       "      <td>-0.066462</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9910.280000</td>\n",
       "      <td>1592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992-07-02</td>\n",
       "      <td>32.68389</td>\n",
       "      <td>-117.1809</td>\n",
       "      <td>1992</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>292.275739</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>75.398328</td>\n",
       "      <td>287.056254</td>\n",
       "      <td>100366.05925</td>\n",
       "      <td>...</td>\n",
       "      <td>287.689669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.805910</td>\n",
       "      <td>286.502401</td>\n",
       "      <td>100122.39125</td>\n",
       "      <td>-0.490090</td>\n",
       "      <td>-0.863408</td>\n",
       "      <td>15.6</td>\n",
       "      <td>9742.057125</td>\n",
       "      <td>1592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992-07-30</td>\n",
       "      <td>32.68389</td>\n",
       "      <td>-117.1809</td>\n",
       "      <td>1992</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>294.410629</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>76.250808</td>\n",
       "      <td>289.455551</td>\n",
       "      <td>100466.27125</td>\n",
       "      <td>...</td>\n",
       "      <td>289.904944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.541946</td>\n",
       "      <td>289.185196</td>\n",
       "      <td>100422.27750</td>\n",
       "      <td>-0.668172</td>\n",
       "      <td>0.388485</td>\n",
       "      <td>15.6</td>\n",
       "      <td>17817.148625</td>\n",
       "      <td>1592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1993-03-11</td>\n",
       "      <td>32.68389</td>\n",
       "      <td>-117.1809</td>\n",
       "      <td>1993</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>287.692444</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>86.818202</td>\n",
       "      <td>285.193045</td>\n",
       "      <td>100778.05575</td>\n",
       "      <td>...</td>\n",
       "      <td>283.378929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.503744</td>\n",
       "      <td>282.942706</td>\n",
       "      <td>100647.46825</td>\n",
       "      <td>-2.139523</td>\n",
       "      <td>-3.294209</td>\n",
       "      <td>15.7</td>\n",
       "      <td>8705.802000</td>\n",
       "      <td>1592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1993-04-19</td>\n",
       "      <td>32.68389</td>\n",
       "      <td>-117.1809</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>289.102930</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>82.173999</td>\n",
       "      <td>285.493621</td>\n",
       "      <td>100517.83125</td>\n",
       "      <td>...</td>\n",
       "      <td>284.245581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.257054</td>\n",
       "      <td>284.049155</td>\n",
       "      <td>100189.34375</td>\n",
       "      <td>-1.847700</td>\n",
       "      <td>-3.232248</td>\n",
       "      <td>15.7</td>\n",
       "      <td>8783.023750</td>\n",
       "      <td>1592.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lat       lon  weather_bin_year  weather_bin_month  \\\n",
       "1992-05-21  32.68389 -117.1809              1992                  5   \n",
       "1992-07-02  32.68389 -117.1809              1992                  7   \n",
       "1992-07-30  32.68389 -117.1809              1992                  7   \n",
       "1993-03-11  32.68389 -117.1809              1993                  3   \n",
       "1993-04-19  32.68389 -117.1809              1993                  4   \n",
       "\n",
       "            weather_bin_day      air.2m      apcp    rhum.2m      dpt.2m  \\\n",
       "1992-05-21               21  292.078990  0.019531  77.730052  287.287171   \n",
       "1992-07-02                2  292.275739  0.000757  75.398328  287.056254   \n",
       "1992-07-30               30  294.410629  0.003906  76.250808  289.455551   \n",
       "1993-03-11               11  287.692444  0.000240  86.818202  285.193045   \n",
       "1993-04-19               19  289.102930  0.001942  82.173999  285.493621   \n",
       "\n",
       "                pres.sfc  ...  min.air.2m  min.apcp  min.rhum.2m  min.dpt.2m  \\\n",
       "1992-05-21  100208.78575  ...  287.399184       0.0    44.981636  285.914549   \n",
       "1992-07-02  100366.05925  ...  287.689669       0.0    46.805910  286.502401   \n",
       "1992-07-30  100466.27125  ...  289.904944       0.0    50.541946  289.185196   \n",
       "1993-03-11  100778.05575  ...  283.378929       0.0    63.503744  282.942706   \n",
       "1993-04-19  100517.83125  ...  284.245581       0.0    50.257054  284.049155   \n",
       "\n",
       "            min.pres.sfc  min.uwnd.10m  min.vwnd.10m  min.veg       min.vis  \\\n",
       "1992-05-21  100190.64825     -2.124688     -0.066462     15.6   9910.280000   \n",
       "1992-07-02  100122.39125     -0.490090     -0.863408     15.6   9742.057125   \n",
       "1992-07-30  100422.27750     -0.668172      0.388485     15.6  17817.148625   \n",
       "1993-03-11  100647.46825     -2.139523     -3.294209     15.7   8705.802000   \n",
       "1993-04-19  100189.34375     -1.847700     -3.232248     15.7   8783.023750   \n",
       "\n",
       "            total_fires  \n",
       "1992-05-21       1592.0  \n",
       "1992-07-02       1592.0  \n",
       "1992-07-30       1592.0  \n",
       "1993-03-11       1592.0  \n",
       "1993-04-19       1592.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out columns of intrest\n",
    "data = raw_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date time index\n",
    "# one_bin_training_data = one_bin_training_data.sort_index()\n",
    "data = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "# one_bin_training_data = one_bin_training_data.drop(['lat', 'lon', 'weather_bin_day'], axis=1)\n",
    "data = data.drop(['weather_bin_day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data[features_to_scale])\n",
    "data[features_to_scale] = scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data up into training, testing and validation sets\n",
    "test_data = data.tail(int(len(data)*0.1))\n",
    "leftover_data = data.iloc[:-int(len(data)*0.1)]\n",
    "\n",
    "validation_data = data.tail(int(len(leftover_data)*0.3))\n",
    "training_data = data.iloc[:-int(len(leftover_data)*0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_index = 5\n",
    "past_history = 3\n",
    "future_target = 1\n",
    "step = 1\n",
    "\n",
    "x_train, y_train = format_multiple_bins_for_LSTM(\n",
    "    training_data, \n",
    "    target_column_index, \n",
    "    past_history,\n",
    "    future_target, \n",
    "    step,\n",
    ")\n",
    "\n",
    "x_validation, y_validation = format_multiple_bins_for_LSTM(\n",
    "    validation_data, \n",
    "    target_column_index, \n",
    "    past_history,\n",
    "    future_target, \n",
    "    step,\n",
    ")\n",
    "\n",
    "x_test, y_test = format_multiple_bins_for_LSTM(\n",
    "    test_data, \n",
    "    target_column_index, \n",
    "    past_history,\n",
    "    future_target, \n",
    "    step,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = []\n",
    "\n",
    "for sample in y_train:\n",
    "    sample_sizes.append(len(sample))\n",
    "    \n",
    "smallest_sample = min(sample_sizes)\n",
    "\n",
    "y_train_reshaped = []\n",
    "\n",
    "for i in range(smallest_sample):\n",
    "    y = []\n",
    "    for j in range(len(y_train)):\n",
    "        try:\n",
    "            y.append(y_train[j][i])\n",
    "        except:\n",
    "            print(\"Index out of range\")\n",
    "    \n",
    "    y_train_reshaped.append(np.array(y))\n",
    "    \n",
    "trimmed_x_training = []    \n",
    "    \n",
    "for sample in x_train:\n",
    "    trimmed_sample = sample[-smallest_sample:,:]\n",
    "    trimmed_x_training.append(trimmed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = []\n",
    "\n",
    "for sample in y_validation:\n",
    "    sample_sizes.append(len(sample))\n",
    "    \n",
    "smallest_sample = min(sample_sizes)\n",
    "y_validation_reshaped = []\n",
    "\n",
    "for i in range(smallest_sample):\n",
    "    y = []\n",
    "    for j in range(len(y_validation)):\n",
    "        try:\n",
    "            y.append(y_validation[j][i])\n",
    "        except:\n",
    "            print(\"Index out of range\")\n",
    "    \n",
    "    y_validation_reshaped.append(np.array(y))\n",
    "    \n",
    "trimmed_x_validation = []    \n",
    "    \n",
    "for sample in x_validation:\n",
    "    trimmed_sample = sample[-smallest_sample:,:]\n",
    "    trimmed_x_validation.append(trimmed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = []\n",
    "\n",
    "for sample in y_test:\n",
    "    sample_sizes.append(len(sample))\n",
    "    \n",
    "smallest_sample = min(sample_sizes)\n",
    "y_test_reshaped = []\n",
    "\n",
    "for i in range(smallest_sample):\n",
    "    y = []\n",
    "    for j in range(len(y_test)):\n",
    "        try:\n",
    "            y.append(y_test[j][i])\n",
    "        except:\n",
    "            print(\"Index out of range\")\n",
    "    \n",
    "    y_test_reshaped.append(np.array(y))\n",
    "    \n",
    "trimmed_x_test = []    \n",
    "    \n",
    "for sample in x_test:\n",
    "    trimmed_sample = sample[-smallest_sample:,:]\n",
    "    trimmed_x_test.append(trimmed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sample = trimmed_x_training[:2]\n",
    "y_train_sample = np.array(y_train_reshaped)[:,:2]\n",
    "\n",
    "x_train_a = x_train_sample[0]\n",
    "x_train_b = x_train_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation_sample = trimmed_x_validation[:2]\n",
    "y_validation_sample = np.array(y_validation_reshaped)[:,:2]\n",
    "\n",
    "x_validation_a = x_validation_sample[0]\n",
    "x_validation_b = x_validation_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sample = trimmed_x_training[:2]\n",
    "y_train_sample = np.array(y_train_reshaped)[:,:2]\n",
    "\n",
    "x_train_a = x_train_sample[0]\n",
    "x_train_b = x_train_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 30\n",
    "dense_units = 30\n",
    "l2_lambda = 0.1\n",
    "learning_rate = 0.1\n",
    "\n",
    "initial_bias = -1.4\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "\n",
    "weight_for_0 = 0.5 \n",
    "weight_for_1 = 13\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "evaluation_interval = 100\n",
    "epochs = 10\n",
    "\n",
    "metrics = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 16)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 3, 16)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 30)           5640        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 30)           5640        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           1830        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            62          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 13,172\n",
      "Trainable params: 13,172\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_a = keras.Input(shape=x_train_a.shape[-2:])\n",
    "input_b = keras.Input(shape=x_train_a.shape[-2:])\n",
    "\n",
    "LSTM_a = keras.layers.LSTM(lstm_units)(input_a)\n",
    "LSTM_b = keras.layers.LSTM(lstm_units)(input_b)\n",
    "\n",
    "merged = keras.layers.concatenate([LSTM_a, LSTM_b])\n",
    "\n",
    "hidden_output = keras.layers.Dense(dense_units)(merged)\n",
    "\n",
    "output = keras.layers.Dense(2)(hidden_output)\n",
    "\n",
    "model = keras.Model(inputs=[input_a, input_b], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=learning_rate), \n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    #metrics=metrics\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6395, 3, 16)\n",
      "(6395, 3, 16)\n",
      "(6395, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_a.shape)\n",
    "print(x_train_b.shape)\n",
    "print(y_train_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2362, 3, 16)\n",
      "(2362, 3, 16)\n",
      "(2362, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_validation_a.shape)\n",
    "print(x_validation_b.shape)\n",
    "print(y_validation_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 6395 samples, validate on 2362 samples\n",
      "Epoch 1/5\n",
      "6395/6395 [==============================] - 4s 685us/sample - loss: 19.0753 - val_loss: 12.6985\n",
      "Epoch 2/5\n",
      "6395/6395 [==============================] - 1s 203us/sample - loss: 19.0713 - val_loss: 12.6985\n",
      "Epoch 3/5\n",
      "6395/6395 [==============================] - 1s 205us/sample - loss: 19.0713 - val_loss: 12.6985\n",
      "Epoch 4/5\n",
      "6395/6395 [==============================] - 1s 206us/sample - loss: 19.0713 - val_loss: 12.6985\n",
      "Epoch 5/5\n",
      "6395/6395 [==============================] - 1s 203us/sample - loss: 19.0713 - val_loss: 12.6985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f66a3e19da0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [x_train_a, x_train_b], \n",
    "    y_train_sample,\n",
    "    #batch_size=64, \n",
    "    epochs=5,\n",
    "    validation_data=([x_validation_a, x_validation_b], y_validation_sample),\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
