{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "As a first pass at developing a machine learning model to predict California wildfires I will evaluate and tune several different gradient boosting algorithms. The procedure will be as follows:\n",
    "\n",
    "1. Determine the best gradient boosting for the data\n",
    "2. Determine the best scoring function/metric for optimization\n",
    "3. Tune model hyperparameters\n",
    "4. Investigate feature importance and possibly trim/apply dimensionality reduction techniques to the data\n",
    "\n",
    "There are two anticipated issues which will need to be dealt with first:\n",
    "\n",
    "1. Large dataset size - current working dataset has 7.3 million observations of 25 variables and this is likely to grow as the project progresses\n",
    "2. Highly imbalanced data (~20 times more observations without fire than with)\n",
    "\n",
    "Future goals are to add several more factors from various data sources including: elevation, population density, time since last fire and total fires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports and notebook setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import math\n",
    "\n",
    "from random import randint\n",
    "from time import time\n",
    "from statistics import mean\n",
    "from scipy import stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from IPython.display import display_markdown\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable definitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_file = '../data/training_data/1992-1997_training_data.csv'\n",
    "rolling_window_data_file = '../data/training_data/1992-1997_training_data_rolling_window.csv'\n",
    "daily_mean_data_file = '../data/training_data/1992-1997_training_data_daily_mean.csv'\n",
    "rand_seed = 123\n",
    "\n",
    "data_sample_size = int(7300000 * 0.01)\n",
    "\n",
    "test_train_split_ratio = 0.3 \n",
    "classifier_jobs = 15\n",
    "optimization_jobs = 1\n",
    "max_jobs = classifier_jobs * optimization_jobs\n",
    "num_trials = 3\n",
    "search_iterations = 500\n",
    "search_scoring_func = make_scorer(average_precision_score)\n",
    "plot_grid_resolution = 500\n",
    "contourf_levels = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_random_sample(data, k):\n",
    "    n = len(data)\n",
    "    \n",
    "    indices = random.sample(range(0, n), k)\n",
    "    \n",
    "    return data.iloc[indices]\n",
    "\n",
    "def stratified_train_test_split(data, targets, rand_seed):\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=test_train_split_ratio, \n",
    "        random_state=rand_seed\n",
    "    )\n",
    "\n",
    "    for train_index, test_index in sss.split(data, targets):\n",
    "        x_train, x_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        y_train, y_test = targets.iloc[train_index], targets.iloc[test_index]\n",
    "        \n",
    "        return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "\n",
    "def sample_data(data, data_sample_size):\n",
    "\n",
    "    # split positive and negative datsets up\n",
    "    ignitions = data[data['ignition'] > 0]\n",
    "    no_ignitions = data[data['ignition'] == 0]\n",
    "    \n",
    "    # due to the moving average we will have some positive observations with\n",
    "    # fractional ignition values\n",
    "    ignitions = ignitions.assign(ignition=1)\n",
    "    \n",
    "    # sample data\n",
    "    no_ignitions_sample = k_random_sample(no_ignitions, data_sample_size)\n",
    "    ignitions_sample = k_random_sample(ignitions, data_sample_size)\n",
    "\n",
    "    # combine\n",
    "    sampled_data = no_ignitions_sample.append(ignitions_sample)\n",
    "    \n",
    "    return sampled_data\n",
    "    \n",
    "def calc_false_neg_pos_rate(model, x_test, y_test):\n",
    "    cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "\n",
    "    TN = cm[0][0]\n",
    "    FN = cm[1][0]\n",
    "    FP = cm[0][1]\n",
    "\n",
    "    false_neg_rate = FN / (FN + TN)\n",
    "    false_pos_rate = FP / (FP + TN)\n",
    "    \n",
    "    return false_neg_rate, false_pos_rate\n",
    "\n",
    "def train_model(classifier, x_train, y_train):\n",
    "    model = classifier\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "    \n",
    "\n",
    "def compare_algorithms(\n",
    "    classifiers, \n",
    "    model_descriptions,\n",
    "    num_trials,\n",
    "    data_moving_avg,\n",
    "    data_sample_size\n",
    "):\n",
    "    \n",
    "    # Set up empty dataframe to hold resutlts\n",
    "    model_scores_columns = [\n",
    "        'Classifier',\n",
    "        'n trials',\n",
    "        'Sample size',\n",
    "        'Time (min.)',\n",
    "        'Peak memory (GB)',\n",
    "        'Training score +/- SD',\n",
    "        'Test score +/- SD',\n",
    "        'False positive rate +/- SD',\n",
    "        'False negative rate +/- SD'\n",
    "    ]\n",
    "    \n",
    "    model_scores = pd.DataFrame(columns=model_scores_columns)    \n",
    "    \n",
    "    # Loop over the diffrent classifiers\n",
    "    for classifier, description in zip(classifiers, model_descriptions):\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        false_pos_rates = []\n",
    "        false_neg_rates = []\n",
    "        mem_usages = []\n",
    "        \n",
    "        start = time()\n",
    "        \n",
    "        for i in range(num_trials):\n",
    "            # Resample and train-test split data\n",
    "            sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "            targets = sampled_data['ignition']\n",
    "            data = sampled_data.drop(['ignition'], axis=1)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(data.values, targets.values)\n",
    "        \n",
    "            # Initalize and train model on sampled data\n",
    "            mem_usage, model = memory_usage((train_model, (classifier, x_train, y_train)), retval=True)\n",
    "            max_mem = max(mem_usage)\n",
    "            mem_usages.append(max_mem)\n",
    "\n",
    "            train_scores.append(average_precision_score(model.predict(x_train), y_train))\n",
    "            test_scores.append(average_precision_score(model.predict(x_test), y_test))\n",
    "            false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(model, x_test, y_test)\n",
    "            false_neg_rates.append(false_neg_rate)\n",
    "            false_pos_rates.append(false_pos_rate)\n",
    "            \n",
    "        stop = time()\n",
    "        dT = np.round(((stop - start)/60), 2)\n",
    "        \n",
    "        peak_memory = np.round((max(mem_usages)/1000), 5)\n",
    "        \n",
    "        avg_train_score = mean(train_scores)\n",
    "        avg_test_score = mean(test_scores)\n",
    "        avg_false_neg_rate = mean(false_neg_rates)\n",
    "        avg_false_pos_rate = mean(false_pos_rates)\n",
    "        \n",
    "        std_train_score = np.std(train_scores)\n",
    "        std_test_score = np.std(test_scores)\n",
    "        std_false_neg_rate = np.std(false_neg_rates)\n",
    "        std_false_pos_rate = np.std(false_pos_rates)\n",
    "        \n",
    "        print('{} trials with {} took {} min. on {} observations'.format(\n",
    "            num_trials, \n",
    "            description, \n",
    "            dT,\n",
    "            data_sample_size\n",
    "        ))\n",
    "        \n",
    "        model_scores = model_scores.append(pd.Series([\n",
    "            description,\n",
    "            num_trials,\n",
    "            data_sample_size,\n",
    "            dT,\n",
    "            peak_memory,\n",
    "            '{:.2f} +/- {:.3f}'.format(np.round(avg_train_score,2), np.round(std_train_score,3)),\n",
    "            '{:.2f} +/- {:.3f}'.format(np.round(avg_test_score,2), np.round(std_test_score,3)),\n",
    "            '{:.2f} +/- {:.3f}'.format(np.round(avg_false_pos_rate,2), np.round(std_false_pos_rate,3)),\n",
    "            '{:.2f} +/- {:.3f}'.format(np.round(avg_false_neg_rate,2), np.round(std_false_neg_rate,3)),\n",
    "        ], index=model_scores.columns), ignore_index=True)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return model_scores\n",
    "    \n",
    "def test_scoring_functions(\n",
    "    num_trials,\n",
    "    scoring_functions, \n",
    "    data_moving_avg,\n",
    "    data_sample_size,\n",
    "    max_jobs\n",
    "):\n",
    "    \n",
    "    # Set up empty dataframe to hold resutlts\n",
    "    model_scores_columns = [\n",
    "        'Scoring function',\n",
    "        'n',\n",
    "        'Training score +/- STD',\n",
    "        'Test score +/- STD',\n",
    "        'False positive rate +/- STD',\n",
    "        'False negative rate +/- STD'\n",
    "    ]\n",
    "    \n",
    "    model_scores = pd.DataFrame(columns=model_scores_columns)\n",
    "\n",
    "    for scoring_function in scoring_functions:\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        false_pos_rates = []\n",
    "        false_neg_rates = []\n",
    "        \n",
    "        for i in range(num_trials):\n",
    "            # Resample and train-test split data\n",
    "            sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "            targets = sampled_data['ignition']\n",
    "            data = sampled_data.drop(['ignition'], axis=1)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(data.values, targets.values)\n",
    "            \n",
    "            catboost_mod = CatBoostClassifier(\n",
    "                thread_count = max_jobs,\n",
    "                score_function = scoring_function\n",
    "            )\n",
    "\n",
    "            catboost_mod.fit(x_train, y_train, silent=True)\n",
    "\n",
    "            train_scores.append(average_precision_score(catboost_mod.predict(x_train), y_train))\n",
    "            test_scores.append(average_precision_score(catboost_mod.predict(x_test), y_test))\n",
    "            false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(catboost_mod, x_test, y_test)\n",
    "            false_neg_rates.append(false_neg_rate)\n",
    "            false_pos_rates.append(false_pos_rate)\n",
    "            \n",
    "        avg_train_score = mean(train_scores)\n",
    "        avg_test_score = mean(test_scores)\n",
    "        avg_false_neg_rate = mean(false_neg_rates)\n",
    "        avg_false_pos_rate = mean(false_pos_rates)\n",
    "        \n",
    "        std_train_score = np.std(train_scores)\n",
    "        std_test_score = np.std(test_scores)\n",
    "        std_false_neg_rate = np.std(false_neg_rates)\n",
    "        std_false_pos_rate = np.std(false_pos_rates)\n",
    "        \n",
    "        model_scores = model_scores.append(pd.Series([\n",
    "            scoring_function,\n",
    "            num_trials,\n",
    "            '{} +/- {}'.format(np.round(avg_train_score,2), np.round(std_train_score,3)),\n",
    "            '{} +/- {}'.format(np.round(avg_test_score,2), np.round(std_test_score,3)),\n",
    "            '{} +/- {}'.format(np.round(avg_false_pos_rate,2), np.round(std_false_pos_rate,3)),\n",
    "            '{} +/- {}'.format(np.round(avg_false_neg_rate,2), np.round(std_false_neg_rate,3)),\n",
    "        ], index=model_scores.columns), ignore_index=True)\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def plot_relative_feature_importance(model, data, x_test, x_tick_size):\n",
    "    importances = catboost_model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    feature_names = np.array(list(data))\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.rc('axes', titlesize=30)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=30)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=x_tick_size)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=25)    # fontsize of the tick labels\n",
    "    plt.title(\"Feature importance\")\n",
    "    plt.bar(range(x_test.shape[1]), importances[indices],\n",
    "           color=\"darkblue\", align=\"center\")\n",
    "    plt.xticks(np.arange(len(indices)), feature_names[indices], rotation='vertical')\n",
    "    plt.xlim([-1, x_test.shape[1]])\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Relative importance\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def tune_class_weight(\n",
    "    class_weights, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test\n",
    "):\n",
    "    model_scores_columns = [\n",
    "        'Class weight',\n",
    "        'Training score',\n",
    "        'Test score',\n",
    "        'False positive rate',\n",
    "        'False negative rate'\n",
    "    ]\n",
    "    \n",
    "    model_scores = pd.DataFrame(columns=model_scores_columns)\n",
    "\n",
    "    for class_weight in class_weights:\n",
    "        catboost_mod = CatBoostClassifier(\n",
    "            thread_count = (classifier_jobs * optimization_jobs),\n",
    "            score_function = 'Cosine',\n",
    "            scale_pos_weight = class_weight\n",
    "        )\n",
    "\n",
    "        catboost_mod.fit(x_train, y_train, silent=True)\n",
    "\n",
    "        training_score = average_precision_score(catboost_mod.predict(x_train), y_train)\n",
    "        test_score = average_precision_score(catboost_mod.predict(x_test), y_test)\n",
    "        false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(catboost_mod, x_test, y_test)\n",
    "        model_scores = model_scores.append(pd.Series([class_weight, np.round(training_score,2), np.round(test_score,2), np.round(false_pos_rate,2), np.round(false_neg_rate,2)], index=model_scores.columns), ignore_index=True)\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def plot_class_weight_tuning_results(model_scores):\n",
    "    sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "    plt.subplots(1,2,figsize=(12,5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    plt.scatter(\n",
    "        np.log10(model_scores['Class weight']), \n",
    "        model_scores['False positive rate'], \n",
    "        s=20, \n",
    "        c='darkblue', \n",
    "        label='False positive'\n",
    "    )\n",
    "    \n",
    "    plt.scatter(\n",
    "        np.log10(model_scores['Class weight']), \n",
    "        model_scores['False negative rate'], \n",
    "        s=20, \n",
    "        c='darkred', \n",
    "        label='False negative'\n",
    "    )\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(\"Log 10 class weight\")\n",
    "    plt.ylabel(\"Rate\")\n",
    "    plt.title(\"Class weight and false prediction rates\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    plt.scatter(\n",
    "        np.log10(model_scores['Class weight']), \n",
    "        model_scores['Training score'], \n",
    "        s=20, \n",
    "        c='darkblue', \n",
    "        label='Training'\n",
    "    )\n",
    "    \n",
    "    plt.scatter(\n",
    "        np.log10(model_scores['Class weight']),\n",
    "        model_scores['Test score'],\n",
    "        s=20, \n",
    "        c='darkred', \n",
    "        label='Test'\n",
    "    )\n",
    "    \n",
    "    plt.legend(loc='lower right');\n",
    "    plt.xlabel(\"Log 10 class weight\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Class weight and precision-recall score\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def train_catboost_with_sampling(\n",
    "    num_trials,\n",
    "    known_params,\n",
    "    data_moving_avg,\n",
    "    data_sample_size,\n",
    "    max_jobs\n",
    "):\n",
    "    \n",
    "    # Set up empty dataframe to hold resutlts\n",
    "    model_scores_columns = [\n",
    "        'Scoring function',\n",
    "        'n',\n",
    "        'Training score +/- STD',\n",
    "        'Test score +/- STD',\n",
    "        'False positive rate +/- STD',\n",
    "        'False negative rate +/- STD'\n",
    "    ]\n",
    "    \n",
    "    model_scores = pd.DataFrame(columns=model_scores_columns)\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    false_pos_rates = []\n",
    "    false_neg_rates = []\n",
    "        \n",
    "    for i in range(num_trials):\n",
    "        # Resample and train-test split data\n",
    "        sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "        targets = sampled_data['ignition']\n",
    "        data = sampled_data.drop(['ignition'], axis=1)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data.values, targets.values)\n",
    "\n",
    "        catboost_mod = CatBoostClassifier(**known_params)\n",
    "        catboost_mod.fit(x_train, y_train, silent=True)\n",
    "\n",
    "        train_scores.append(average_precision_score(catboost_mod.predict(x_train), y_train))\n",
    "        test_scores.append(average_precision_score(catboost_mod.predict(x_test), y_test))\n",
    "        false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(catboost_mod, x_test, y_test)\n",
    "        false_neg_rates.append(false_neg_rate)\n",
    "        false_pos_rates.append(false_pos_rate)\n",
    "        \n",
    "        i += 1\n",
    "            \n",
    "    avg_train_score = mean(train_scores)\n",
    "    avg_test_score = mean(test_scores)\n",
    "    avg_false_neg_rate = mean(false_neg_rates)\n",
    "    avg_false_pos_rate = mean(false_pos_rates)\n",
    "\n",
    "    sem_train_score = stats.sem(train_scores)\n",
    "    sem_test_score = stats.sem(test_scores)\n",
    "    sem_false_neg_rate = stats.sem(false_neg_rates)\n",
    "    sem_false_pos_rate = stats.sem(false_pos_rates)\n",
    "\n",
    "    model_scores = model_scores.append(pd.Series([\n",
    "        'Catboost with scoring function & class weight',\n",
    "        num_trials,\n",
    "        '{} +/- {}'.format(np.round(avg_train_score,2), np.round(sem_train_score,3)),\n",
    "        '{} +/- {}'.format(np.round(avg_test_score,2), np.round(sem_test_score,3)),\n",
    "        '{} +/- {}'.format(np.round(avg_false_pos_rate,2), np.round(sem_false_pos_rate,3)),\n",
    "        '{} +/- {}'.format(np.round(avg_false_neg_rate,2), np.round(sem_false_neg_rate,3)),\n",
    "    ], index=model_scores.columns), ignore_index=True)\n",
    "\n",
    "    return model_scores\n",
    "\n",
    "def tune_hyperparameters(\n",
    "    known_params,\n",
    "    param_dist, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    num_jobs, \n",
    "    search_iterations, \n",
    "    search_scoring_func\n",
    "):\n",
    "\n",
    "    # initalize catboost classifier\n",
    "    model = CatBoostClassifier(**known_params)\n",
    "\n",
    "    # set up random search\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model, \n",
    "        param_distributions=param_dist,\n",
    "        scoring=search_scoring_func,\n",
    "        n_iter=search_iterations,\n",
    "        n_jobs=num_jobs\n",
    "    )\n",
    "\n",
    "    # run and time search\n",
    "    start = time()\n",
    "    best_model = random_search.fit(x_train, y_train)\n",
    "    print(\"RandomizedSearchCV took %.f min. for %d candidate\"\n",
    "          \" parameter settings.\" % (((time() - start)/60), search_iterations))\n",
    "    \n",
    "    return best_model, random_search\n",
    "\n",
    "def regularize_grid(x, y, z, resolution):\n",
    "\n",
    "    # target grid to interpolate to\n",
    "    xi = np.arange(min(x), max(x), ((max(x) - min(x)) / resolution))\n",
    "    yi = np.arange(min(y), max(y), ((max(y) - min(y)) / resolution))\n",
    "    xi, yi = np.meshgrid(xi, yi)\n",
    "\n",
    "    # interpolate\n",
    "    zi = griddata((x, y), z, (xi, yi), method='linear')\n",
    "    \n",
    "    return xi, yi, zi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_bin_time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>air.sfc</th>\n",
       "      <th>air.2m</th>\n",
       "      <th>apcp</th>\n",
       "      <th>crain</th>\n",
       "      <th>rhum.2m</th>\n",
       "      <th>dpt.2m</th>\n",
       "      <th>pres.sfc</th>\n",
       "      <th>...</th>\n",
       "      <th>hcdc</th>\n",
       "      <th>mcdc</th>\n",
       "      <th>hpbl</th>\n",
       "      <th>prate</th>\n",
       "      <th>vis</th>\n",
       "      <th>ulwrf.sfc</th>\n",
       "      <th>fire_discovery_time</th>\n",
       "      <th>size</th>\n",
       "      <th>size_class</th>\n",
       "      <th>ignition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1992-01-01 00:00:00</td>\n",
       "      <td>40.29749</td>\n",
       "      <td>-124.3408</td>\n",
       "      <td>284.35388</td>\n",
       "      <td>284.81824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.3125</td>\n",
       "      <td>282.89040</td>\n",
       "      <td>100173.56</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>533.4578</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>20007.979</td>\n",
       "      <td>359.9375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1992-01-01 00:00:00</td>\n",
       "      <td>38.96153</td>\n",
       "      <td>-123.5579</td>\n",
       "      <td>285.66638</td>\n",
       "      <td>286.25574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.9375</td>\n",
       "      <td>280.43730</td>\n",
       "      <td>99073.56</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>671.8578</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>20007.979</td>\n",
       "      <td>353.8750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1992-01-01 00:00:00</td>\n",
       "      <td>39.24150</td>\n",
       "      <td>-123.6393</td>\n",
       "      <td>286.04138</td>\n",
       "      <td>286.81824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.8125</td>\n",
       "      <td>281.35916</td>\n",
       "      <td>99573.56</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>786.9578</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>20007.979</td>\n",
       "      <td>349.4375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1992-01-01 00:00:00</td>\n",
       "      <td>39.52163</td>\n",
       "      <td>-123.7215</td>\n",
       "      <td>286.04138</td>\n",
       "      <td>286.81824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.8125</td>\n",
       "      <td>281.35916</td>\n",
       "      <td>99473.56</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>917.4578</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>20007.979</td>\n",
       "      <td>349.4375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1992-01-01 00:00:00</td>\n",
       "      <td>39.80193</td>\n",
       "      <td>-123.8045</td>\n",
       "      <td>283.35388</td>\n",
       "      <td>284.06824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.8125</td>\n",
       "      <td>278.55447</td>\n",
       "      <td>96573.56</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>833.7578</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>20007.979</td>\n",
       "      <td>341.6250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      weather_bin_time       lat       lon    air.sfc     air.2m  apcp  crain  \\\n",
       "0  1992-01-01 00:00:00  40.29749 -124.3408  284.35388  284.81824   0.0    0.0   \n",
       "1  1992-01-01 00:00:00  38.96153 -123.5579  285.66638  286.25574   0.0    0.0   \n",
       "2  1992-01-01 00:00:00  39.24150 -123.6393  286.04138  286.81824   0.0    0.0   \n",
       "3  1992-01-01 00:00:00  39.52163 -123.7215  286.04138  286.81824   0.0    0.0   \n",
       "4  1992-01-01 00:00:00  39.80193 -123.8045  283.35388  284.06824   0.0    0.0   \n",
       "\n",
       "   rhum.2m     dpt.2m   pres.sfc  ...  hcdc  mcdc      hpbl     prate  \\\n",
       "0  88.3125  282.89040  100173.56  ...  11.0   0.0  533.4578 -0.000003   \n",
       "1  67.9375  280.43730   99073.56  ...   6.0   0.0  671.8578 -0.000003   \n",
       "2  69.8125  281.35916   99573.56  ...   6.0   0.0  786.9578 -0.000003   \n",
       "3  69.8125  281.35916   99473.56  ...   6.0   0.0  917.4578 -0.000003   \n",
       "4  68.8125  278.55447   96573.56  ...   6.0   0.0  833.7578 -0.000003   \n",
       "\n",
       "         vis  ulwrf.sfc  fire_discovery_time  size  size_class  ignition  \n",
       "0  20007.979   359.9375                  NaN   NaN         NaN       NaN  \n",
       "1  20007.979   353.8750                  NaN   NaN         NaN       NaN  \n",
       "2  20007.979   349.4375                  NaN   NaN         NaN       NaN  \n",
       "3  20007.979   349.4375                  NaN   NaN         NaN       NaN  \n",
       "4  20007.979   341.6250                  NaN   NaN         NaN       NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(raw_data_file, low_memory=False)\n",
    "raw_data['ignition'].fillna(0, inplace=True)\n",
    "raw_data['weather_bin_time'] = pd.to_datetime(raw_data['weather_bin_time'])\n",
    "raw_data['weather_bin_day'] = raw_data['weather_bin_time'].dt.day\n",
    "raw_data['weather_bin_month'] = raw_data['weather_bin_time'].dt.month\n",
    "raw_data['weather_bin_year'] = raw_data['weather_bin_time'].dt.year\n",
    "raw_data.drop(['fire_discovery_time', 'size', 'size_class', 'weather_bin_time'], axis=1, inplace=True)\n",
    "raw_data.dropna(inplace=True)\n",
    "\n",
    "data_rolling_window = pd.read_csv(rolling_window_data_file, low_memory=False)\n",
    "\n",
    "data_daily_mean = pd.read_csv(daily_mean_data_file, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: default and oracle models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal here is to establish upper and lower bounds on what is possible with our dataset. We will do this by creating two models:\n",
    "\n",
    "1. 'Oracle' - best possible performance, train directly on the test set with no regularization\n",
    "2. Default - predict major class for all test set observations\n",
    "\n",
    "These two models will give us a context in which to evaluate how well we are doing. At the same time we will also evaluate three diffrent versions of our dataset.\n",
    "\n",
    "1. Raw data\n",
    "2. Data averaged with a 24 hr rolling mean\n",
    "3. Data averaged by day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier selection: kitchen sink approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to throw a bunch of different classifiers with default settings at the problem and see how they do. See list below for contenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifiers to test\n",
    "model_descriptions = [\n",
    "    'XGBoost',\n",
    "    'CatBoost',\n",
    "    'LightGBM',\n",
    "    'Rand. forest',\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Proc.\",\n",
    "    \"Decision Tree\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\"\n",
    "]\n",
    "\n",
    "classifiers = (\n",
    "    XGBClassifier(n_jobs = max_jobs), \n",
    "    CatBoostClassifier(thread_count = max_jobs, silent = True), \n",
    "    LGBMClassifier(n_jobs = max_jobs),\n",
    "    RandomForestClassifier(n_jobs = max_jobs),\n",
    "    SVC(kernel = \"linear\"),\n",
    "    SVC(),\n",
    "    GaussianProcessClassifier(n_jobs = max_jobs),\n",
    "    DecisionTreeClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(), #failed on 73000 observations: Unable to allocate array with shape (109500, 109500) and data type float64\n",
    "    QuadraticDiscriminantAnalysis()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a small sample of the data to quickly get a sense of how well each classifier works. Hopefully we can discard some to make test run times shorter in the next round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 trials with XGBoost took 0.95 min. on 5000 observations\n",
      "50 trials with CatBoost took 5.64 min. on 5000 observations\n",
      "50 trials with LightGBM took 0.98 min. on 5000 observations\n",
      "50 trials with Rand. forest took 1.52 min. on 5000 observations\n",
      "50 trials with Linear SVM took 34.97 min. on 5000 observations\n",
      "50 trials with RBF SVM took 7.52 min. on 5000 observations\n",
      "50 trials with Gaussian Proc. took 42.57 min. on 5000 observations\n",
      "50 trials with Decision Tree took 0.97 min. on 5000 observations\n",
      "50 trials with AdaBoost took 1.68 min. on 5000 observations\n",
      "50 trials with Naive Bayes took 0.8 min. on 5000 observations\n",
      "50 trials with QDA took 0.81 min. on 5000 observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>n trials</th>\n",
       "      <th>Sample size</th>\n",
       "      <th>Time (min.)</th>\n",
       "      <th>Peak memory (GB)</th>\n",
       "      <th>Training score +/- SD</th>\n",
       "      <th>Test score +/- SD</th>\n",
       "      <th>False positive rate +/- SD</th>\n",
       "      <th>False negative rate +/- SD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>5.64</td>\n",
       "      <td>2.88154</td>\n",
       "      <td>0.91 +/- 0.005</td>\n",
       "      <td>0.78 +/- 0.013</td>\n",
       "      <td>0.22 +/- 0.014</td>\n",
       "      <td>0.17 +/- 0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.88854</td>\n",
       "      <td>0.90 +/- 0.005</td>\n",
       "      <td>0.77 +/- 0.010</td>\n",
       "      <td>0.22 +/- 0.014</td>\n",
       "      <td>0.18 +/- 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.83508</td>\n",
       "      <td>0.79 +/- 0.007</td>\n",
       "      <td>0.76 +/- 0.008</td>\n",
       "      <td>0.26 +/- 0.012</td>\n",
       "      <td>0.19 +/- 0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Rand. forest</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.92854</td>\n",
       "      <td>1.00 +/- 0.000</td>\n",
       "      <td>0.76 +/- 0.013</td>\n",
       "      <td>0.23 +/- 0.015</td>\n",
       "      <td>0.19 +/- 0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>QDA</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.81</td>\n",
       "      <td>3.39432</td>\n",
       "      <td>0.80 +/- 0.007</td>\n",
       "      <td>0.80 +/- 0.009</td>\n",
       "      <td>0.45 +/- 0.023</td>\n",
       "      <td>0.19 +/- 0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>2.92833</td>\n",
       "      <td>0.92 +/- 0.004</td>\n",
       "      <td>0.92 +/- 0.005</td>\n",
       "      <td>0.80 +/- 0.011</td>\n",
       "      <td>0.19 +/- 0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.68</td>\n",
       "      <td>3.39150</td>\n",
       "      <td>0.76 +/- 0.008</td>\n",
       "      <td>0.75 +/- 0.012</td>\n",
       "      <td>0.28 +/- 0.013</td>\n",
       "      <td>0.20 +/- 0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.39150</td>\n",
       "      <td>0.79 +/- 0.005</td>\n",
       "      <td>0.79 +/- 0.010</td>\n",
       "      <td>0.49 +/- 0.016</td>\n",
       "      <td>0.23 +/- 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>34.97</td>\n",
       "      <td>2.92833</td>\n",
       "      <td>0.71 +/- 0.010</td>\n",
       "      <td>0.70 +/- 0.013</td>\n",
       "      <td>0.32 +/- 0.014</td>\n",
       "      <td>0.25 +/- 0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.39159</td>\n",
       "      <td>1.00 +/- 0.000</td>\n",
       "      <td>0.66 +/- 0.012</td>\n",
       "      <td>0.28 +/- 0.016</td>\n",
       "      <td>0.28 +/- 0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Gaussian Proc.</td>\n",
       "      <td>50</td>\n",
       "      <td>5000</td>\n",
       "      <td>42.57</td>\n",
       "      <td>5.53526</td>\n",
       "      <td>1.00 +/- 0.000</td>\n",
       "      <td>0.03 +/- 0.004</td>\n",
       "      <td>0.00 +/- 0.002</td>\n",
       "      <td>0.49 +/- 0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Classifier n trials Sample size  Time (min.)  Peak memory (GB)  \\\n",
       "1         CatBoost       50        5000         5.64           2.88154   \n",
       "2         LightGBM       50        5000         0.98           2.88854   \n",
       "0          XGBoost       50        5000         0.95           2.83508   \n",
       "3     Rand. forest       50        5000         1.52           2.92854   \n",
       "10             QDA       50        5000         0.81           3.39432   \n",
       "5          RBF SVM       50        5000         7.52           2.92833   \n",
       "8         AdaBoost       50        5000         1.68           3.39150   \n",
       "9      Naive Bayes       50        5000         0.80           3.39150   \n",
       "4       Linear SVM       50        5000        34.97           2.92833   \n",
       "7    Decision Tree       50        5000         0.97           3.39159   \n",
       "6   Gaussian Proc.       50        5000        42.57           5.53526   \n",
       "\n",
       "   Training score +/- SD Test score +/- SD False positive rate +/- SD  \\\n",
       "1         0.91 +/- 0.005    0.78 +/- 0.013             0.22 +/- 0.014   \n",
       "2         0.90 +/- 0.005    0.77 +/- 0.010             0.22 +/- 0.014   \n",
       "0         0.79 +/- 0.007    0.76 +/- 0.008             0.26 +/- 0.012   \n",
       "3         1.00 +/- 0.000    0.76 +/- 0.013             0.23 +/- 0.015   \n",
       "10        0.80 +/- 0.007    0.80 +/- 0.009             0.45 +/- 0.023   \n",
       "5         0.92 +/- 0.004    0.92 +/- 0.005             0.80 +/- 0.011   \n",
       "8         0.76 +/- 0.008    0.75 +/- 0.012             0.28 +/- 0.013   \n",
       "9         0.79 +/- 0.005    0.79 +/- 0.010             0.49 +/- 0.016   \n",
       "4         0.71 +/- 0.010    0.70 +/- 0.013             0.32 +/- 0.014   \n",
       "7         1.00 +/- 0.000    0.66 +/- 0.012             0.28 +/- 0.016   \n",
       "6         1.00 +/- 0.000    0.03 +/- 0.004             0.00 +/- 0.002   \n",
       "\n",
       "   False negative rate +/- SD  \n",
       "1              0.17 +/- 0.014  \n",
       "2              0.18 +/- 0.011  \n",
       "0              0.19 +/- 0.011  \n",
       "3              0.19 +/- 0.013  \n",
       "10             0.19 +/- 0.013  \n",
       "5              0.19 +/- 0.022  \n",
       "8              0.20 +/- 0.014  \n",
       "9              0.23 +/- 0.017  \n",
       "4              0.25 +/- 0.015  \n",
       "7              0.28 +/- 0.015  \n",
       "6              0.49 +/- 0.009  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from memory_profiler import memory_usage\n",
    "\n",
    "# start with a smaller sample to quickly get an inital sense of how well \n",
    "# each classifier works\n",
    "data_sample_size = 5000\n",
    "num_trials = 50\n",
    "\n",
    "# repeatedly test each classifier on new samples of the data\n",
    "model_score_comparision = compare_algorithms(\n",
    "    classifiers, \n",
    "    model_descriptions,\n",
    "    num_trials,\n",
    "    data_moving_avg,\n",
    "    data_sample_size\n",
    ")\n",
    "\n",
    "model_score_comparision = model_score_comparision.sort_values(\n",
    "    ['False negative rate +/- SD', 'False positive rate +/- SD'], \n",
    "    ascending=[1, 1]\n",
    ")\n",
    "\n",
    "model_score_comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we definitely do not want Gaussian process. We should also probably exclude the SVM based algorithms on the grounds of performance (RBF) and compute time (linear). It's tempting to drop decision trees as well due to likely overfitting, but it might be possible to ameliorate that at a later phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-41c02543696f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# exclude algorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_descriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Gaussian Process'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_descriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Linear SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_descriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RBF SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# exclude algorithms\n",
    "model_descriptions.remove('Gaussian Process')\n",
    "model_descriptions.remove('Linear SVM')\n",
    "model_descriptions.remove('RBF SVM')\n",
    "\n",
    "classifiers = (\n",
    "    XGBClassifier(n_jobs = max_jobs), \n",
    "    CatBoostClassifier(thread_count = max_jobs, silent = True), \n",
    "    LGBMClassifier(n_jobs = max_jobs),\n",
    "    RandomForestClassifier(n_jobs = max_jobs),\n",
    "    #SVC(kernel = \"linear\"),\n",
    "    #SVC(),\n",
    "    #GaussianProcessClassifier(n_jobs = max_jobs),\n",
    "    DecisionTreeClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(), #failed on 73000 observations: Unable to allocate array with shape (109500, 109500) and data type float64\n",
    "    QuadraticDiscriminantAnalysis()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we make a choice, let's see how well the classifiers scale in terms of compute time and memory usage as the dataset gets larger. We don't want to devote time and energy to optimizing a classifier which won't be able to handle the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sample size and number of trials per round\n",
    "data_sample_size = 1000\n",
    "num_trials = 1\n",
    "\n",
    "# Set up empty dataframe to hold results\n",
    "increasing_n_results_columns = [\n",
    "    'Classifier',\n",
    "    'n trials',\n",
    "    'Sample size',\n",
    "    'Time (min.)',\n",
    "    'Peak memory (GB)',\n",
    "    'Training score +/- SD',\n",
    "    'Test score +/- SD',\n",
    "    'False positive rate +/- SD',\n",
    "    'False negative rate +/- SD'\n",
    "]\n",
    "\n",
    "increasing_n_results = pd.DataFrame(columns=increasing_n_results_columns)\n",
    "\n",
    "for i in range(11):\n",
    "    \n",
    "    # repeatedly test each classifier on new samples of the data\n",
    "    model_score_comparision = compare_algorithms(\n",
    "        classifiers, \n",
    "        model_descriptions,\n",
    "        num_trials,\n",
    "        data_moving_avg,\n",
    "        data_sample_size\n",
    "    )\n",
    "    \n",
    "    # double sample size\n",
    "    data_sample_size = data_sample_size * 2\n",
    "    \n",
    "    increasing_n_results = increasing_n_results.append(model_score_comparision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x='Sample size', y='Time (min.)', hue='Classifier', data=increasing_n_results)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(x='Sample size', y='Peak memory (GB)', hue='Classifier', data=increasing_n_results)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_history_columns = [\n",
    "    'Description',\n",
    "    'n',\n",
    "    'Training score +/- STD',\n",
    "    'Test score +/- STD',\n",
    "    'False positive rate +/- STD',\n",
    "    'False negative rate +/- STD'\n",
    "]\n",
    "\n",
    "model_score_history = pd.DataFrame(columns=model_score_history_columns)\n",
    "\n",
    "model_score_history = model_score_history.append(pd.Series([\n",
    "    'Default CatBoost model',\n",
    "    num_trials,\n",
    "    model_scores.iloc[1]['Training score +/- STD'], \n",
    "    model_scores.iloc[1]['Test score +/- STD'], \n",
    "    model_scores.iloc[1]['False positive rate +/- STD'], \n",
    "    model_scores.iloc[1]['False negative rate +/- STD'],\n",
    "], index=model_score_history.columns), ignore_index=True)\n",
    "\n",
    "model_score_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost scoring function selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: CatBoost only has cosine and L2 avalible for non GPU computation\n",
    "scoring_functions = [\n",
    "#    'SolarL2',\n",
    "     'Cosine', \n",
    "#     'NewtonL2', \n",
    "#     'NewtonCosine', \n",
    "#     'LOOL2', \n",
    "#     'SatL2', \n",
    "     'L2'\n",
    "]\n",
    "\n",
    "model_scores = test_scoring_functions(\n",
    "    num_trials,\n",
    "    scoring_functions, \n",
    "    data_moving_avg,\n",
    "    data_sample_size,\n",
    "    max_jobs\n",
    ")\n",
    "\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, looks similar, the Cosine false negative rate is slightly lower on some trials, so let's go with that. Before moving on to hyperparameter optimization, let's take a look at our relative feature importances and see if we can simplify the model any.\n",
    "\n",
    "Before we move on, update out hyperparameter dictionary with our new finding and save the score results to a dataframe so we can track our progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_params = {\n",
    "    'random_state': rand_seed,\n",
    "    'thread_count': max_jobs,\n",
    "    'score_function': 'Cosine',\n",
    "    'silent': True\n",
    "}\n",
    "\n",
    "model_score_history = model_score_history.append(pd.Series([\n",
    "    'CatBoost model with Cosine scoring function',\n",
    "    num_trials,\n",
    "    model_scores.iloc[0]['Training score +/- STD'], \n",
    "    model_scores.iloc[0]['Test score +/- STD'], \n",
    "    model_scores.iloc[0]['False positive rate +/- STD'], \n",
    "    model_scores.iloc[0]['False negative rate +/- STD'],\n",
    "], index=model_score_history.columns), ignore_index=True)\n",
    "\n",
    "model_score_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain catboost model on new train-test split with new hyperparameters\n",
    "sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "targets = sampled_data['ignition']\n",
    "data = sampled_data.drop(['ignition'], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.values, targets.values)\n",
    "          \n",
    "catboost_model = CatBoostClassifier(**known_params)\n",
    "catboost_model.fit(x_train, y_train)\n",
    "\n",
    "plot_relative_feature_importance(catboost_model, data, x_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, some features which were expected to be important are fairly far down on the list. For example: air temperature at 2 meters and u/v components of wind speed. Before we go throwing variables away or trying to reduce dimensionality let's do some hyperparameter optimization and see if the relative feature importances change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization: class weight\n",
    "We sampled our data so we have the same number of positive and negative results so we may not need a class weight. Let's try a few values and see how if effects our false positive and false negative rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.logspace(-2.5, 2.5, num=25, base=10)\n",
    "\n",
    "model_scores = tune_class_weight(\n",
    "    class_weights, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test\n",
    ")\n",
    "\n",
    "plot_class_weight_tuning_results(model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. We can use larger class weights to drive down the false negative rate at the expense of false positives. Looking at the clearly sigmoidal precision recall curve, the optimum value looks like it's around 1. Before just using no weight, let's try this again with a narrower range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.logspace(-0.2, 0.2, num=25, base=10)\n",
    "\n",
    "model_scores = tune_class_weight(\n",
    "    class_weights, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    x_test, \n",
    "    y_test\n",
    ")\n",
    "\n",
    "plot_class_weight_tuning_results(model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, this one is actually pretty subjective... I'm calling it somewhere between one and three. Let's use 1.8 for now. This should give us ~90/85 precision-recall and put our false positive and false negative rates at 0.25 and ~0.1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_params = {\n",
    "    'random_state': rand_seed,\n",
    "    'thread_count': max_jobs,\n",
    "    'score_function': 'Cosine',\n",
    "    'silent': True,\n",
    "    'scale_pos_weight': 1.78\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Important to keep in mind here that we can tune our false positive/false negative rates easily with this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with new class weight\n",
    "model_scores = train_catboost_with_sampling(\n",
    "    num_trials,\n",
    "    known_params,\n",
    "    data_moving_avg,\n",
    "    data_sample_size,\n",
    "    max_jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_history = model_score_history.append(pd.Series([\n",
    "    'CatBoost with scoring function & class weight',\n",
    "    num_trials,\n",
    "    model_scores.iloc[0]['Training score +/- STD'], \n",
    "    model_scores.iloc[0]['Test score +/- STD'], \n",
    "    model_scores.iloc[0]['False positive rate +/- STD'], \n",
    "    model_scores.iloc[0]['False negative rate +/- STD'],\n",
    "], index=model_score_history.columns), ignore_index=True)\n",
    "\n",
    "model_score_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: learning rate and tree count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try taking one sample of the full dataset and then using RandomizedSearchCV to try and find the best values for learning rate and tree count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'learning_rate': loguniform(0.0001, 1),\n",
    "    'n_estimators': range(1,200)\n",
    "}\n",
    "\n",
    "# Resample and train-test split data\n",
    "sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "targets = sampled_data['ignition']\n",
    "data = sampled_data.drop(['ignition'], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.values, targets.values) \n",
    "\n",
    "best_model, random_search = tune_hyperparameters(\n",
    "    known_params,\n",
    "    param_dist, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    optimization_jobs, \n",
    "    search_iterations, \n",
    "    search_scoring_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search_results = pd.DataFrame(random_search.cv_results_).dropna()\n",
    "\n",
    "x = rand_search_results['param_n_estimators']\n",
    "y = rand_search_results['param_learning_rate']\n",
    "z = rand_search_results['mean_test_score']\n",
    "xi, yi, zi = regularize_grid(x, y, z, plot_grid_resolution)\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "plt.contourf(xi, yi, zi, contourf_levels, cmap=plt.cm.Blues)\n",
    "plt.xlabel(\"N estimators\")\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.title(\"Effect of estimator count and \\nlearning rate on score\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprised by how 'rough' hyperparameter space is. Let's keep the winning numbers and save the scores to our log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_learning_rate = rand_search_results.iloc[0]['param_learning_rate']\n",
    "best_n_estimators = rand_search_results.iloc[0]['param_n_estimators']\n",
    "\n",
    "known_params = {\n",
    "    'random_state': rand_seed,\n",
    "    'thread_count': classifier_jobs,\n",
    "    'score_function': 'Cosine',\n",
    "    'silent': True,\n",
    "    'scale_pos_weight': 1.78,\n",
    "    'learning_rate': best_learning_rate,\n",
    "    'n_estimators': best_n_estimators\n",
    "}\n",
    "\n",
    "# Resample and train-test split data\n",
    "sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "targets = sampled_data['ignition']\n",
    "data = sampled_data.drop(['ignition'], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.values, targets.values) \n",
    "\n",
    "# Train model with new hyperparameters\n",
    "model_scores = train_catboost_with_sampling(\n",
    "    num_trials,\n",
    "    known_params,\n",
    "    data_moving_avg,\n",
    "    data_sample_size,\n",
    "    max_jobs\n",
    ")\n",
    "\n",
    "# Add results to score history dataframe\n",
    "model_score_history = model_score_history.append(pd.Series([\n",
    "    'CatBoost with n estimators and learning rate',\n",
    "    num_trials,\n",
    "    model_scores.iloc[0]['Training score +/- STD'], \n",
    "    model_scores.iloc[0]['Test score +/- STD'], \n",
    "    model_scores.iloc[0]['False positive rate +/- STD'], \n",
    "    model_scores.iloc[0]['False negative rate +/- STD'],\n",
    "], index=model_score_history.columns), ignore_index=True)\n",
    "\n",
    "model_score_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just for fun, let's see how our winning values for number of estimators and learning rate vary across repeated trials with different sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'learning_rate': loguniform(0.0001, 1),\n",
    "    'n_estimators': range(1,200)\n",
    "}\n",
    "\n",
    "scores = []\n",
    "learning_rates = []\n",
    "n_estimators = []\n",
    "\n",
    "itterations = 100\n",
    "\n",
    "for i in range(itterations):\n",
    "    # Resample and train-test split data\n",
    "    sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "    targets = sampled_data['ignition']\n",
    "    data = sampled_data.drop(['ignition'], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.values, targets.values) \n",
    "    \n",
    "    best_model, random_search = tune_hyperparameters(\n",
    "        known_params,\n",
    "        param_dist, \n",
    "        x_train, \n",
    "        y_train, \n",
    "        optimization_jobs, \n",
    "        search_iterations, \n",
    "        search_scoring_func\n",
    "    )\n",
    "    \n",
    "    rand_search_results = pd.DataFrame(random_search.cv_results_).dropna()\n",
    "    winner = rand_search_results[rand_search_results['rank_test_score'] == 1]\n",
    "    avg_score = winner.iloc[0]['mean_test_score']\n",
    "    learning_rate = winner.iloc[0]['param_learning_rate']\n",
    "    n_estimator = winner.iloc[0]['param_n_estimators']\n",
    "    \n",
    "    scores.append(avg_score)\n",
    "    learning_rates.append(learning_rate)\n",
    "    n_estimators.append(n_estimator)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = n_estimators\n",
    "y = learning_rates\n",
    "z = scores\n",
    "xi, yi, zi = regularize_grid(x, y, z, plot_grid_resolution)\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "plt.contourf(xi, yi, zi, contourf_levels, cmap=plt.cm.Blues)\n",
    "plt.xlabel(\"N estimators\")\n",
    "plt.ylabel(\"Learning rate\")\n",
    "plt.title(\"Winning estimator count and\\n learning rate vs score\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: tree depth and L2 coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'depth': range(1, 21, 1),\n",
    "    'l2_leaf_reg': np.linspace(0, 10, 101)\n",
    "}\n",
    "\n",
    "best_model, random_search = tune_hyperparameters(\n",
    "    known_params,\n",
    "    param_dist, \n",
    "    x_train, \n",
    "    y_train, \n",
    "    optimization_jobs, \n",
    "    search_iterations, \n",
    "    search_scoring_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search_results = pd.DataFrame(random_search.cv_results_).dropna()\n",
    "\n",
    "x = rand_search_results['param_depth']\n",
    "y = rand_search_results['param_l2_leaf_reg']\n",
    "z = rand_search_results['mean_test_score']\n",
    "xi, yi, zi = regularize_grid(x, y, z, plot_grid_resolution)\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "plt.contourf(xi, yi, zi, contourf_levels, cmap=plt.cm.Blues)\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.ylabel(\"L2 coefficient\")\n",
    "plt.title(\"Effect of tree depth and \\nL2 coefficient on score\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, store winning parameters in dictionary and add score results to log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_depth = rand_search_results.iloc[0]['param_depth']\n",
    "best_l2_leaf_reg = rand_search_results.iloc[0]['param_l2_leaf_reg']\n",
    "\n",
    "known_params = {\n",
    "    'random_state': rand_seed,\n",
    "    'thread_count': classifier_jobs,\n",
    "    'score_function': 'Cosine',\n",
    "    'silent': True,\n",
    "    'scale_pos_weight': 1.78,\n",
    "    'learning_rate': best_learning_rate,\n",
    "    'n_estimators': best_n_estimators,\n",
    "    'depth': best_depth,\n",
    "    'l2_leaf_reg': best_l2_leaf_reg\n",
    "}\n",
    "\n",
    "# Resample and train-test split data\n",
    "sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "targets = sampled_data['ignition']\n",
    "data = sampled_data.drop(['ignition'], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.values, targets.values) \n",
    "\n",
    "# Train model with new hyperparameters\n",
    "model_scores = train_catboost_with_sampling(\n",
    "    num_trials,\n",
    "    known_params,\n",
    "    data_moving_avg,\n",
    "    data_sample_size,\n",
    "    max_jobs\n",
    ")\n",
    "\n",
    "# Add results to score history dataframe\n",
    "model_score_history = model_score_history.append(pd.Series([\n",
    "    'CatBoost with depth and L2 coefficient',\n",
    "    num_trials,\n",
    "    model_scores.iloc[0]['Training score +/- STD'], \n",
    "    model_scores.iloc[0]['Test score +/- STD'], \n",
    "    model_scores.iloc[0]['False positive rate +/- STD'], \n",
    "    model_scores.iloc[0]['False negative rate +/- STD'],\n",
    "], index=model_score_history.columns), ignore_index=True)\n",
    "\n",
    "model_score_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model: feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CatBoostClassifier(**known_params)\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "plot_relative_feature_importance(catboost_model, data, x_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model: effect of feature count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = list()\n",
    "test_scores = list()\n",
    "\n",
    "feature_names = np.array(list(data))\n",
    "importances = catboost_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for n in range(1,(len(feature_names) + 1)):\n",
    "    # grab top n feature names\n",
    "    top_n_features = feature_names[indices[0:n]]\n",
    "\n",
    "    # rebuild training and test sets with feature subset\n",
    "    sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "    targets = sampled_data['ignition']\n",
    "    data = sampled_data.drop(['ignition'], axis=1)\n",
    "    data_subset = data[top_n_features]\n",
    "    x_train_subset, x_test_subset, y_train_subset, y_test_subset  = train_test_split(data_subset, targets)\n",
    "\n",
    "    # instantiate and train classifier\n",
    "    catboost_model = CatBoostClassifier(**known_params)\n",
    "    catboost_model.fit(x_train_subset, y_train_subset)\n",
    "\n",
    "    # report score for feature subset\n",
    "    training_score = average_precision_score(catboost_model.predict(x_train_subset), y_train_subset)\n",
    "    test_score = average_precision_score(catboost_model.predict(x_test_subset), y_test_subset)\n",
    "    \n",
    "    train_scores.append(training_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    #print('Top {} features, precision-recall score train/test: {}/{}'.format(n,np.round(training_score,2),np.round(test_score,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(range(1,(len(feature_names) + 1)), train_scores, s=20, c='darkblue', label='Training data')\n",
    "ax.scatter(range(1,(len(feature_names) + 1)), test_scores, s=20, c='darkred', label='Test data')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Model performance and feature count\")\n",
    "plt.xlabel(\"N features\")\n",
    "plt.ylabel(\"Avg. precision-recall score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model: robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = list()\n",
    "test_scores = list()\n",
    "false_neg_rates = list()\n",
    "false_pos_rates = list()\n",
    "\n",
    "# grab top n feature names\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_n_features = feature_names[indices[0:7]]\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    # rebuild training and test sets with feature subset\n",
    "    sampled_data = sample_data(data_moving_avg, data_sample_size)\n",
    "    targets = sampled_data['ignition']\n",
    "    data = sampled_data.drop(['ignition'], axis=1)\n",
    "    data_subset = data[top_n_features]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_subset.values, targets.values)\n",
    "\n",
    "    # instantiate and train classifier\n",
    "    catboost_model = CatBoostClassifier(**known_params)\n",
    "    catboost_model.fit(x_train, y_train)\n",
    "\n",
    "    predicted_y = catboost_model.predict(x_test)\n",
    "    \n",
    "    training_score = average_precision_score(catboost_model.predict(x_train), y_train)\n",
    "    test_score = average_precision_score(predicted_y, y_test)\n",
    "\n",
    "    train_scores.append(training_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    false_neg_rate, false_pos_rate = calc_false_neg_pos_rate(catboost_model, x_test, y_test)\n",
    "\n",
    "    false_neg_rates.append(false_neg_rate)\n",
    "    false_pos_rates.append(false_pos_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "ax = sns.kdeplot(train_scores, label=\"Training data\", shade=True, color=\"darkblue\")\n",
    "ax = sns.kdeplot(test_scores, label=\"Test data\", shade=True, color=\"darkred\")\n",
    "ax.set_title(\"Precision-recall score distributions\")\n",
    "ax.set(xlabel='Avg. precision-recall score', ylabel='Density')\n",
    "plt.legend()\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(false_neg_rates, label=\"False negative\", shade=True, color=\"darkblue\")\n",
    "ax = sns.kdeplot(false_pos_rates, label=\"False positive\", shade=True, color=\"darkred\")\n",
    "ax.set_title(\"False positive and negative rates\")\n",
    "ax.set(xlabel='Rate', ylabel='Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(false_neg_rates, false_pos_rates, s=5)\n",
    "plt.xlabel(\"False negative rate\")\n",
    "plt.ylabel(\"False positive rate\")\n",
    "plt.title(\"False positive vs false negative rate\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_comparisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
