{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal ###\n",
    "Find the nearest [California Data Exchange Center](https://cdec.water.ca.gov/) weather station to each of our California bins. This information will be used to assign each bin weather variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "%matplotlib inline\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have many bins which do not contain a weather monitoring station, the next step is to fill in their values from the nearest station. First find the nearest station to each bin. To do this we will use scipy.spatial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.read_csv('../data/spatial_data/california_bins.csv')\n",
    "stations = pd.read_csv('../data/CDEC_weather_station_data/target_stations.csv')\n",
    "stations.columns = ['station','elevation', 'lat', 'long']\n",
    "stations = stations[stations.long != 0]\n",
    "bin_array = np.column_stack([bins['long'], bins['lat']])\n",
    "station_array = np.column_stack([stations['long'], stations['lat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "station_tree = spatial.cKDTree(station_array)\n",
    "dist, indexes = station_tree.query(bin_array)\n",
    "\n",
    "nearest_station_names = []\n",
    "for index in indexes:\n",
    "    nearest_station_names.append(stations.iloc[index, 0])\n",
    "    \n",
    "bins['nearest_station_name'] = nearest_station_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the temperature dataset as a test case, now we will make an hourly time series spanning from 2006 to 2016 and assign each bin a temprature from it's nearest station each hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5622044 entries, 2015-01-01 23:00:00 to 2016-01-01 23:00:00\n",
      "Data columns (total 2 columns):\n",
      "STATION_ID    object\n",
      "VALUE         int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 128.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Annoying, but here goes...\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "\n",
    "temp_data = pd.read_csv(\"../data/weather_data/TEMP_1d.csv\", parse_dates = ['OBS_DATE'], usecols = [\"STATION_ID\", \"OBS_DATE\", \"VALUE\"], index_col = \"OBS_DATE\")\n",
    "# temp_data = pd.read_csv(\"../data/weather_data/TEMP_1d.csv\")\n",
    "temp_data = temp_data[temp_data.VALUE != '---']\n",
    "#temp_data = temp_data.drop_duplicates()\n",
    "#temp_data = temp_data.drop_duplicates()\n",
    "temp_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a station which does not report regularly on the hour. I am sure there are many other cases of this in the dataset. There are also almost certainly missing values. To fix this, we will resample and interpolate to a regular hourly frequency over the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_ID</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBS_DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2015-01-01 23:00:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-01 23:15:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-01 23:30:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-01 23:45:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATION_ID  VALUE\n",
       "OBS_DATE                             \n",
       "2015-01-01 23:00:00        BUD     33\n",
       "2015-01-01 23:15:00        BUD     33\n",
       "2015-01-01 23:30:00        BUD     33\n",
       "2015-01-01 23:45:00        BUD     33\n",
       "2015-01-02 00:00:00        BUD     33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bud_station = temp_data[temp_data['STATION_ID'] == 'BUD']\n",
    "bud_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_ID</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBS_DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2015-01-01 23:00:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-02 01:00:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-02 02:00:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-02 03:00:00</td>\n",
       "      <td>BUD</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    STATION_ID  VALUE\n",
       "OBS_DATE                             \n",
       "2015-01-01 23:00:00        BUD   33.0\n",
       "2015-01-02 00:00:00        BUD   33.0\n",
       "2015-01-02 01:00:00        BUD   33.0\n",
       "2015-01-02 02:00:00        BUD   32.0\n",
       "2015-01-02 03:00:00        BUD   32.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bud_station = bud_station.drop_duplicates()\n",
    "bud_station_min = bud_station.resample('min')\n",
    "bud_station_min = bud_station_min.interpolate(method = 'linear')\n",
    "bud_station_hr = bud_station_min.resample('H')\n",
    "bud_station_hr = bud_station_hr.interpolate(method = 'linear')\n",
    "bud_station_hr['STATION_ID'] = 'BUD'\n",
    "bud_station_hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def regularize(group):\n",
    "#     #group = group.drop_duplicates()\n",
    "#     group = group.loc[~group.index.duplicated()]\n",
    "#     group = group.resample('min')\n",
    "#     group = group.interpolate(method = 'linear')\n",
    "#     group = group.resample('H')\n",
    "#     group = group.interpolate(method = 'linear')\n",
    "#     return group\n",
    "    \n",
    "# grouped_temp_data = temp_data.groupby('STATION_ID')\n",
    "# st_regularized_temp_data = grouped_temp_data.apply(regularize)\n",
    "\n",
    "# st_regularized_temp_data['STATION_ID'] = st_regularized_temp_data.index.get_level_values(0)\n",
    "# st_regularized_temp_data = st_regularized_temp_data.reset_index(level = 0, drop = True)\n",
    "# st_regularized_temp_data = st_regularized_temp_data.set_index(['STATION_ID'], append = True)\n",
    "# st_regularized_temp_data['VALUE'].replace('', np.nan, inplace = True)\n",
    "# st_regularized_temp_data.dropna(subset = ['VALUE'], inplace = True)\n",
    "# st_regularized_temp_data = st_regularized_temp_data.loc[~st_regularized_temp_data.index.duplicated()]\n",
    "# st_regularized_temp_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize it?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-8-62852d4194c3>\", line 15, in group_data\n",
      "    return grouped_data.apply(regularize)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\", line 725, in apply\n",
      "    result = self._python_apply_general(f)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\", line 742, in _python_apply_general\n",
      "    keys, values, mutated = self.grouper.apply(f, self._selected_obj, self.axis)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/ops.py\", line 237, in apply\n",
      "    res = f(group)\n",
      "  File \"<ipython-input-8-62852d4194c3>\", line 7, in regularize\n",
      "    group = group.interpolate(method = 'linear')\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/resample.py\", line 796, in interpolate\n",
      "    **kwargs\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/generic.py\", line 7019, in interpolate\n",
      "    _maybe_transposed_self.T\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/frame.py\", line 2756, in transpose\n",
      "    return super().transpose(1, 0, **kwargs)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/generic.py\", line 735, in transpose\n",
      "    return self._constructor(new_values, **new_axes).__finalize__(self)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/frame.py\", line 440, in __init__\n",
      "    mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/construction.py\", line 204, in init_ndarray\n",
      "    make_block(dvals_list[n], placement=[n]) for n in range(len(dvals_list))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/construction.py\", line 204, in <listcomp>\n",
      "    make_block(dvals_list[n], placement=[n]) for n in range(len(dvals_list))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 3260, in make_block\n",
      "    klass = get_block_type(values, dtype)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 3221, in get_block_type\n",
      "    elif is_interval_dtype(dtype) or is_period_dtype(dtype):\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/dtypes/common.py\", line 675, in is_interval_dtype\n",
      "    return IntervalDtype.is_dtype(arr_or_dtype)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/dtypes/dtypes.py\", line 1110, in is_dtype\n",
      "    return super().is_dtype(dtype)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/dtypes/base.py\", line 256, in is_dtype\n",
      "    if isinstance(dtype, (ABCSeries, ABCIndexClass, ABCDataFrame, np.dtype)):\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\", line 7, in _check\n",
      "    @classmethod\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-62852d4194c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmt_regularized_temp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmt_regularized_temp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STATION_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmt_regularized_temp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-62852d4194c3>\u001b[0m in \u001b[0;36mparallelize\u001b[0;34m(temp_data, func, n_cores)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtemp_data_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_data_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wildfire/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wildfire/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-8-62852d4194c3>\", line 15, in group_data\n",
      "    return grouped_data.apply(regularize)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\", line 725, in apply\n",
      "    result = self._python_apply_general(f)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\", line 742, in _python_apply_general\n",
      "    keys, values, mutated = self.grouper.apply(f, self._selected_obj, self.axis)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/ops.py\", line 237, in apply\n",
      "    res = f(group)\n",
      "  File \"<ipython-input-8-62852d4194c3>\", line 7, in regularize\n",
      "    group = group.interpolate(method = 'linear')\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/resample.py\", line 796, in interpolate\n",
      "    **kwargs\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/generic.py\", line 7019, in interpolate\n",
      "    _maybe_transposed_self.T\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/frame.py\", line 2756, in transpose\n",
      "    return super().transpose(1, 0, **kwargs)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/generic.py\", line 735, in transpose\n",
      "    return self._constructor(new_values, **new_axes).__finalize__(self)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/frame.py\", line 440, in __init__\n",
      "    mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/construction.py\", line 204, in init_ndarray\n",
      "    make_block(dvals_list[n], placement=[n]) for n in range(len(dvals_list))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/construction.py\", line 204, in <listcomp>\n",
      "    make_block(dvals_list[n], placement=[n]) for n in range(len(dvals_list))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 3260, in make_block\n",
      "    klass = get_block_type(values, dtype)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 3216, in get_block_type\n",
      "    elif issubclass(vtype, np.datetime64):\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-8-62852d4194c3>\", line 15, in group_data\n",
      "    return grouped_data.apply(regularize)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\", line 725, in apply\n",
      "    result = self._python_apply_general(f)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\", line 742, in _python_apply_general\n",
      "    keys, values, mutated = self.grouper.apply(f, self._selected_obj, self.axis)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/groupby/ops.py\", line 237, in apply\n",
      "    res = f(group)\n",
      "  File \"<ipython-input-8-62852d4194c3>\", line 7, in regularize\n",
      "    group = group.interpolate(method = 'linear')\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/resample.py\", line 796, in interpolate\n",
      "    **kwargs\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/generic.py\", line 7019, in interpolate\n",
      "    _maybe_transposed_self.T\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/frame.py\", line 2756, in transpose\n",
      "    return super().transpose(1, 0, **kwargs)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/generic.py\", line 735, in transpose\n",
      "    return self._constructor(new_values, **new_axes).__finalize__(self)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/frame.py\", line 440, in __init__\n",
      "    mgr = init_ndarray(data, index, columns, dtype=dtype, copy=copy)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/construction.py\", line 204, in init_ndarray\n",
      "    make_block(dvals_list[n], placement=[n]) for n in range(len(dvals_list))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/construction.py\", line 204, in <listcomp>\n",
      "    make_block(dvals_list[n], placement=[n]) for n in range(len(dvals_list))\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 3267, in make_block\n",
      "    return klass(values, ndim=ndim, placement=placement)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 2775, in __init__\n",
      "    super().__init__(values, ndim=ndim, placement=placement)\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 122, in __init__\n",
      "    self.mgr_locs = placement\n",
      "  File \"/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 246, in mgr_locs\n",
      "    new_mgr_locs = libinternals.BlockPlacement(new_mgr_locs)\n",
      "  File \"pandas/_libs/internals.pyx\", line 51, in pandas._libs.internals.BlockPlacement.__init__\n",
      "  File \"/home/siderealyear/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\", line 223, in require\n",
      "    @set_module('numpy')\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "n_threads = 14\n",
    "\n",
    "def regularize(group):\n",
    "    #group = group.drop_duplicates()\n",
    "    group = group.loc[~group.index.duplicated()]\n",
    "    group = group.resample('min')\n",
    "    group = group.interpolate(method = 'linear')\n",
    "    group = group.resample('H')\n",
    "    group = group.interpolate(method = 'linear')\n",
    "    #print(group)\n",
    "    return group\n",
    "\n",
    "def group_data(temp_data_split):\n",
    "    grouped_data = temp_data_split.groupby('STATION_ID')\n",
    "    return grouped_data.apply(regularize)\n",
    "    \n",
    "def parallelize(temp_data, func, n_cores = n_threads):\n",
    "    '''Parallelizes regularization, takes temp data and\n",
    "    splits up regularization fuction over avalibile threads'''\n",
    "    temp_data_split = np.array_split(temp_data, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    result = pd.concat(pool.map(func, temp_data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return result\n",
    "    \n",
    "%timeit mt_regularized_temp_data = parallelize(temp_data, group_data)\n",
    "\n",
    "mt_regularized_temp_data['STATION_ID'] = mt_regularized_temp_data.index.get_level_values(0)\n",
    "mt_regularized_temp_data = mt_regularized_temp_data.reset_index(level = 0, drop = True)\n",
    "mt_regularized_temp_data = mt_regularized_temp_data.set_index(['STATION_ID'], append = True)\n",
    "mt_regularized_temp_data['VALUE'].replace('', np.nan, inplace = True)\n",
    "mt_regularized_temp_data.dropna(subset = ['VALUE'], inplace = True)\n",
    "mt_regularized_temp_data = mt_regularized_temp_data.loc[~mt_regularized_temp_data.index.duplicated()]\n",
    "mt_regularized_temp_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next big block uses resampling to bin the temp. data at a resolution of six hours. In early runs I had memory issues so I added this. Hoping I won't need it in the final product. Keeping the code here I case I want to use it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_threads = 14\n",
    "\n",
    "# def downsample_timeseries(group):\n",
    "#     group = group.sort_index()\n",
    "#     group.loc[:,'resampled_value'] = group.VALUE.rolling('6H').mean()\n",
    "#     group = group.drop(['VALUE'], axis = 1)\n",
    "#     return group.iloc[0::12, :]\n",
    "\n",
    "# def group_timeseries_data(stations):\n",
    "#     data = temp_data.loc[temp_data['STATION_ID'].isin(stations)]\n",
    "#     grouped_data = data.groupby('STATION_ID')\n",
    "#     return grouped_data.apply(downsample_timeseries)\n",
    "    \n",
    "# def parallelize(stations, func, n_cores = n_threads):\n",
    "#     '''Parallelizes downsampling, takes list of stations and\n",
    "#     splits up the downsampling fuction over avalibile threads'''\n",
    "#     stations_split = np.array_split(stations, n_cores)\n",
    "#     pool = Pool(n_cores)\n",
    "#     result = pd.concat(pool.map(func, stations_split))\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#     return result\n",
    "    \n",
    "# stations = temp_data['STATION_ID'].unique().tolist()\n",
    "# binned_temp_data = parallelize(stations, group_timeseries_data)\n",
    "# binned_temp_data = binned_temp_data.reset_index(level = 0, drop = True)\n",
    "# binned_temp_data = binned_temp_data.set_index(['STATION_ID'], append = True)\n",
    "# binned_temp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binned_temp_data.to_csv('../data/training_data/weather_data/TEMP_1yr_binned_6hr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = pd.date_range(\"2015-01-01 23:00:00\", \"2015-01-02 23:00:00\", freq = \"H\")\n",
    "time_series = time_series.to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a dataframe of 'noxels' or n-dimentional voxels. Each row will be a bin at a specific time. Once we have this dataframe, we can go back though and assign weather variable values to each noxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_bins(time_series, bins):\n",
    "    return bins.assign(time = time_series)\n",
    "\n",
    "noxels = pd.concat(time_series.apply(apply_to_bins, args = (bins,)).tolist())\n",
    "noxels.to_csv('../data/noxels.csv', index = False)\n",
    "noxels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noxels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_regularized_temp_data.at[('2015-01-01 23:00:00', 'ACN'), 'VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threads = 14\n",
    "\n",
    "def try_except(row):\n",
    "    try:\n",
    "        return mt_regularized_temp_data.loc[(row['time'], row['nearest_station_name']), 'VALUE']\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def add_data(noxels):\n",
    "    noxels['temp'] = noxels.apply(lambda row: try_except(row), axis = 1)\n",
    "    return noxels\n",
    "\n",
    "def parallelize(noxels, func, n_cores = n_threads):\n",
    "    '''Parallelizes downsampling, takes list of stations and\n",
    "    splits up the downsampling fuction over avalibile threads'''\n",
    "    noxels_split = np.array_split(noxels, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    result = pd.concat(pool.map(func, noxels_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return result\n",
    "\n",
    "%timeit noxels = parallelize(noxels, add_data)\n",
    "\n",
    "noxels = noxels.dropna()\n",
    "noxels.to_csv('../data/noxels_TEMP.csv', index = False)\n",
    "noxels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noxels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so, working to a first approximation. I am worried that we a loosing a bunch of data somewhere. Lets check some lengths and see. If we filled every bin with a temperature value, then we should have bins x time_series rows in our data file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(noxels) / (len(bins) * len(time_series))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
