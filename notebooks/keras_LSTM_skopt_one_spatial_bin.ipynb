{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/siderealyear/anaconda3/envs/wildfire/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_objective_2D #, plot_histogram\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics =  ['loss', 'auc', 'precision', 'recall', 'fp', 'fn']\n",
    "    \n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(3,2,n+1)\n",
    "        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        \n",
    "    if metric == 'loss':\n",
    "        plt.ylim([0, plt.ylim()[1]])\n",
    "        \n",
    "    elif metric == 'auc':\n",
    "        plt.ylim([0.8,1])\n",
    "        \n",
    "    else:\n",
    "        #plt.ylim([0,1])\n",
    "        plt.legend()\n",
    "\n",
    "def multivariate_data(\n",
    "    dataset,\n",
    "    target, \n",
    "    start_index, \n",
    "    end_index, \n",
    "    history_size,\n",
    "    target_size, \n",
    "    step\n",
    "):\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    \n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        labels.append(target[i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "def log_dir_name(\n",
    "    learning_rate,\n",
    "    past_history,\n",
    "    lstm_units,\n",
    "    hidden_layers,\n",
    "    hidden_units,\n",
    "    #lstm_l2_lambda,\n",
    "    hidden_l2_lambda,\n",
    "    class_0_weight,\n",
    "    class_1_weight\n",
    "):\n",
    "\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./LSTM_logs/past_history_{1}_hidden_layers_{3}/\"\n",
    "\n",
    "    # Insert all the hyper-parameters in the dir-name.\n",
    "    log_dir = s.format(\n",
    "        learning_rate,\n",
    "        past_history,\n",
    "        lstm_units,\n",
    "        hidden_layers,\n",
    "        hidden_units,\n",
    "        #lstm_l2_lambda,\n",
    "        hidden_l2_lambda,\n",
    "        class_0_weight,\n",
    "        class_1_weight\n",
    "    )\n",
    "\n",
    "    return log_dir\n",
    "\n",
    "def f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2 * ((precision*10) * recall) / ((precision*10) + recall + K.epsilon())\n",
    "    \n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/training_data/1992-2015_training_data_added_features.csv'\n",
    "\n",
    "# Datatypes for dataframe loading\n",
    "dtypes = {\n",
    "    'lat': float,\n",
    "    'lon': float,\n",
    "    'weather_bin_year': int,\n",
    "    'weather_bin_month': int,\n",
    "    'weather_bin_day': int,\n",
    "    'air.2m': float,\n",
    "    'apcp': float,\n",
    "    'rhum.2m': float,\n",
    "    'dpt.2m': float,\n",
    "    'pres.sfc': float,\n",
    "    'uwnd.10m': float,\n",
    "    'vwnd.10m': float,\n",
    "    'veg': float,\n",
    "    'vis': float,\n",
    "    'ignition': float,\n",
    "    'mean.air.2m': float,\n",
    "    'mean.apcp': float,\n",
    "    'mean.rhum.2m': float,\n",
    "    'mean.dpt.2m': float,\n",
    "    'mean.pres.sfc': float,\n",
    "    'mean.uwnd.10m': float,\n",
    "    'mean.vwnd.10m': float,\n",
    "    'mean.veg': float,\n",
    "    'mean.vis': float,\n",
    "    'max.air.2m': float,\n",
    "    'max.apcp': float,\n",
    "    'max.rhum.2m': float,\n",
    "    'max.dpt.2m': float,\n",
    "    'max.pres.sfc': float,\n",
    "    'max.uwnd.10m': float,\n",
    "    'max.vwnd.10m': float,\n",
    "    'max.veg': float,\n",
    "    'max.vis': float,\n",
    "    'min.air.2m': float,\n",
    "    'min.apcp': float,\n",
    "    'min.rhum.2m': float,\n",
    "    'min.dpt.2m': float,\n",
    "    'min.pres.sfc': float,\n",
    "    'min.uwnd.10m': float,\n",
    "    'min.vwnd.10m': float,\n",
    "    'min.veg': float,\n",
    "    'min.vis': float,\n",
    "    'total_fires': float\n",
    "\n",
    "}\n",
    "\n",
    "# Features to use during training \n",
    "features = [\n",
    "    'lat',\n",
    "    'lon',\n",
    "    'weather_bin_month',\n",
    "    'veg',\n",
    "    'ignition',\n",
    "    'mean.air.2m',\n",
    "    'mean.apcp',\n",
    "    'mean.rhum.2m',\n",
    "    'mean.dpt.2m',\n",
    "    'mean.pres.sfc',\n",
    "    'mean.uwnd.10m',\n",
    "    'mean.vwnd.10m',\n",
    "    'mean.veg',\n",
    "    'mean.vis',\n",
    "    'mean.air.2m',\n",
    "    'mean.apcp',\n",
    "    'mean.rhum.2m',\n",
    "    'mean.dpt.2m',\n",
    "    'mean.pres.sfc',\n",
    "    'mean.uwnd.10m',\n",
    "    'mean.vwnd.10m',\n",
    "    'mean.vis',\n",
    "    'max.air.2m',\n",
    "    'max.apcp',\n",
    "    'max.rhum.2m',\n",
    "    'max.dpt.2m',\n",
    "    'max.pres.sfc',\n",
    "    'max.uwnd.10m',\n",
    "    'max.vwnd.10m',\n",
    "    'max.vis',\n",
    "    'min.air.2m',\n",
    "    'min.apcp',\n",
    "    'min.rhum.2m',\n",
    "    'min.dpt.2m',\n",
    "    'min.pres.sfc',\n",
    "    'min.uwnd.10m',\n",
    "    'min.vwnd.10m',\n",
    "    'min.vis',\n",
    "    'total_fires'\n",
    "]\n",
    "\n",
    "features_to_scale = [\n",
    "    'veg',\n",
    "    'mean.air.2m',\n",
    "    'mean.apcp',\n",
    "    'mean.rhum.2m',\n",
    "    'mean.dpt.2m',\n",
    "    'mean.pres.sfc',\n",
    "    'mean.uwnd.10m',\n",
    "    'mean.vwnd.10m',\n",
    "    'mean.vis',\n",
    "    'max.air.2m',\n",
    "    'max.apcp',\n",
    "    'max.rhum.2m',\n",
    "    'max.dpt.2m',\n",
    "    'max.pres.sfc',\n",
    "    'max.uwnd.10m',\n",
    "    'max.vwnd.10m',\n",
    "    'max.vis',\n",
    "    'min.air.2m',\n",
    "    'min.apcp',\n",
    "    'min.rhum.2m',\n",
    "    'min.dpt.2m',\n",
    "    'min.pres.sfc',\n",
    "    'min.uwnd.10m',\n",
    "    'min.vwnd.10m',\n",
    "    'min.vis',\n",
    "    'total_fires'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(data_file, index_col=0, parse_dates=True, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out columns of intrest\n",
    "data = raw_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one spatial bin with fires\n",
    "data = data[(data['lat'] == 39.42233) & (data['lon'] == -120.6546)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also drop lat, lon, day and year columns (unnecessary)\n",
    "data.drop(['lat', 'lon'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode month\n",
    "column_names = [\n",
    "    'January',\n",
    "    'February',\n",
    "    'March',\n",
    "    'April',\n",
    "    'May',\n",
    "    'June',\n",
    "    'July',\n",
    "    'August',\n",
    "    'Septermber',\n",
    "    'October',\n",
    "    'November',\n",
    "    'December'\n",
    "]\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Training data\n",
    "month = np.array(data['weather_bin_month']).reshape(-1, 1)\n",
    "onehot_month = onehot_encoder.fit_transform(month)\n",
    "\n",
    "data.drop('weather_bin_month', axis=1, inplace=True)\n",
    "onehot_month_df = pd.DataFrame(onehot_month, columns=column_names)\n",
    "\n",
    "onehot_month_df['datetime'] = pd.to_datetime(data.index)\n",
    "onehot_month_df = onehot_month_df.set_index('datetime')\n",
    "data = pd.concat([data, onehot_month_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data[features_to_scale])\n",
    "data[features_to_scale] = scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date time index\n",
    "# one_bin_training_data = one_bin_training_data.sort_index()\n",
    "data = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>veg</th>\n",
       "      <th>ignition</th>\n",
       "      <th>mean.air.2m</th>\n",
       "      <th>mean.apcp</th>\n",
       "      <th>mean.rhum.2m</th>\n",
       "      <th>mean.dpt.2m</th>\n",
       "      <th>mean.pres.sfc</th>\n",
       "      <th>mean.uwnd.10m</th>\n",
       "      <th>mean.vwnd.10m</th>\n",
       "      <th>mean.veg</th>\n",
       "      <th>...</th>\n",
       "      <th>March</th>\n",
       "      <th>April</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>August</th>\n",
       "      <th>Septermber</th>\n",
       "      <th>October</th>\n",
       "      <th>November</th>\n",
       "      <th>December</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>0.503702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.138237</td>\n",
       "      <td>-0.368419</td>\n",
       "      <td>-0.485131</td>\n",
       "      <td>-1.694950</td>\n",
       "      <td>0.575796</td>\n",
       "      <td>-0.787113</td>\n",
       "      <td>0.389269</td>\n",
       "      <td>70.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>0.503702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.916780</td>\n",
       "      <td>-0.359414</td>\n",
       "      <td>-0.717171</td>\n",
       "      <td>-1.648949</td>\n",
       "      <td>-0.455567</td>\n",
       "      <td>-0.610320</td>\n",
       "      <td>-0.105418</td>\n",
       "      <td>70.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>0.503702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.003120</td>\n",
       "      <td>0.155398</td>\n",
       "      <td>0.521572</td>\n",
       "      <td>-0.763310</td>\n",
       "      <td>-1.945359</td>\n",
       "      <td>0.406430</td>\n",
       "      <td>0.978409</td>\n",
       "      <td>70.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992-01-04</td>\n",
       "      <td>0.503702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.013071</td>\n",
       "      <td>1.580237</td>\n",
       "      <td>1.798763</td>\n",
       "      <td>0.130060</td>\n",
       "      <td>-2.642089</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>2.634629</td>\n",
       "      <td>70.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1992-01-05</td>\n",
       "      <td>0.503702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.245384</td>\n",
       "      <td>0.645080</td>\n",
       "      <td>1.815982</td>\n",
       "      <td>-0.175384</td>\n",
       "      <td>-3.348068</td>\n",
       "      <td>0.378398</td>\n",
       "      <td>1.619435</td>\n",
       "      <td>70.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 veg  ignition  mean.air.2m  mean.apcp  mean.rhum.2m  \\\n",
       "1992-01-01  0.503702       0.0    -1.138237  -0.368419     -0.485131   \n",
       "1992-01-02  0.503702       0.0    -0.916780  -0.359414     -0.717171   \n",
       "1992-01-03  0.503702       0.0    -1.003120   0.155398      0.521572   \n",
       "1992-01-04  0.503702       0.0    -1.013071   1.580237      1.798763   \n",
       "1992-01-05  0.503702       0.0    -1.245384   0.645080      1.815982   \n",
       "\n",
       "            mean.dpt.2m  mean.pres.sfc  mean.uwnd.10m  mean.vwnd.10m  \\\n",
       "1992-01-01    -1.694950       0.575796      -0.787113       0.389269   \n",
       "1992-01-02    -1.648949      -0.455567      -0.610320      -0.105418   \n",
       "1992-01-03    -0.763310      -1.945359       0.406430       0.978409   \n",
       "1992-01-04     0.130060      -2.642089       0.746722       2.634629   \n",
       "1992-01-05    -0.175384      -3.348068       0.378398       1.619435   \n",
       "\n",
       "            mean.veg  ...  March  April  May  June  July  August  Septermber  \\\n",
       "1992-01-01      70.7  ...    0.0    0.0  0.0   0.0   0.0     0.0         0.0   \n",
       "1992-01-02      70.7  ...    0.0    0.0  0.0   0.0   0.0     0.0         0.0   \n",
       "1992-01-03      70.7  ...    0.0    0.0  0.0   0.0   0.0     0.0         0.0   \n",
       "1992-01-04      70.7  ...    0.0    0.0  0.0   0.0   0.0     0.0         0.0   \n",
       "1992-01-05      70.7  ...    0.0    0.0  0.0   0.0   0.0     0.0         0.0   \n",
       "\n",
       "            October  November  December  \n",
       "1992-01-01      0.0       0.0       0.0  \n",
       "1992-01-02      0.0       0.0       0.0  \n",
       "1992-01-03      0.0       0.0       0.0  \n",
       "1992-01-04      0.0       0.0       0.0  \n",
       "1992-01-05      0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data up into training, testing and validation sets\n",
    "test_data = data.tail(int(len(data)*0.1))\n",
    "leftover_data = data.iloc[:-int(len(data)*0.1)]\n",
    "\n",
    "validation_data = data.tail(int(len(leftover_data)*0.3))\n",
    "training_data = data.iloc[:-int(len(leftover_data)*0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "training_data = np.array(training_data)\n",
    "validation_data = np.array(validation_data)\n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_target = 1\n",
    "step = 1\n",
    "\n",
    "initial_bias = -1.4\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "\n",
    "# weight_for_0 = 0.5 \n",
    "# weight_for_1 = 13\n",
    "# class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 100\n",
    "STEPS_PER_EPOCH = (len(training_data) * 0.25) // BATCH_SIZE\n",
    "VALIDATION_STEPS = (len(validation_data) * 0.25) // BATCH_SIZE\n",
    "\n",
    "path_best_model = 'best_LTSM.keras'\n",
    "best_fraction_incorrect = 1.0\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'), \n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    f1\n",
    "]\n",
    "\n",
    "dim_learning_rate = Real(\n",
    "    low=0.00001, \n",
    "    high=0.1, \n",
    "    prior='log-uniform',\n",
    "    name='learning_rate'\n",
    ")\n",
    "\n",
    "dim_past_history = Integer(\n",
    "    low=1,\n",
    "    high=30, \n",
    "    name='past_history'\n",
    ")\n",
    "\n",
    "dim_lstm_units = Integer(\n",
    "    low=5, \n",
    "    high=500,\n",
    "    name='lstm_units'\n",
    ")\n",
    "\n",
    "dim_hidden_layers = Integer(\n",
    "    low=1, \n",
    "    high=10,\n",
    "    name='hidden_layers'\n",
    ")\n",
    "\n",
    "dim_hidden_units = Integer(\n",
    "    low=5, \n",
    "    high=500,\n",
    "    name='hidden_units'\n",
    ")\n",
    "\n",
    "# dim_lstm_l2_lambda = Real(\n",
    "#     low=0.0001, \n",
    "#     high=0.1,\n",
    "#     prior='log-uniform',\n",
    "#     name='lstm_l2_lambda'\n",
    "# )\n",
    "\n",
    "dim_hidden_l2_lambda = Real(\n",
    "    low=0.0001, \n",
    "    high=0.1,\n",
    "    prior='log-uniform',\n",
    "    name='hidden_l2_lambda'\n",
    ")\n",
    "\n",
    "dim_class_0_weight = Real(\n",
    "    low=0.1, \n",
    "    high=1,\n",
    "    name='class_0_weight'\n",
    ")\n",
    "\n",
    "dim_class_1_weight = Integer(\n",
    "    low=10, \n",
    "    high=20,\n",
    "    name='class_1_weight'\n",
    ")\n",
    "\n",
    "default_parameters = [0.001, 3, 50, 2, 50, 0.1, 0.5, 15]\n",
    "\n",
    "dimensions = [\n",
    "    dim_learning_rate,\n",
    "    dim_past_history,\n",
    "    dim_lstm_units,\n",
    "    dim_hidden_layers,\n",
    "    dim_hidden_units,\n",
    "    #dim_lstm_l2_lambda,\n",
    "    dim_hidden_l2_lambda,\n",
    "    dim_class_0_weight,\n",
    "    dim_class_1_weight\n",
    "]\n",
    "\n",
    "# Use early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    input_dim,\n",
    "    learning_rate,\n",
    "    lstm_units,\n",
    "    hidden_layers,\n",
    "    hidden_units,\n",
    "    #lstm_l2_lambda,\n",
    "    hidden_l2_lambda\n",
    "):    \n",
    "    input_shape = (100, input_dim[0], input_dim[1])\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        lstm_units,\n",
    "        batch_input_shape=input_shape,\n",
    "#         bias_initializer=keras.initializers.VarianceScaling(\n",
    "#             scale=1.0,\n",
    "#             mode='fan_in', \n",
    "#             distribution='normal', \n",
    "#             seed=None\n",
    "#         ),\n",
    "#         kernel_regularizer=keras.regularizers.l2(lstm_l2_lambda),\n",
    "#         activation = 'relu',\n",
    "         stateful = True\n",
    "    ))\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(keras.layers.Dense(\n",
    "            hidden_units,\n",
    "            bias_initializer=keras.initializers.VarianceScaling(\n",
    "                scale=1.0,\n",
    "                mode='fan_in', \n",
    "                distribution='normal', \n",
    "                seed=None\n",
    "            ),\n",
    "            kernel_regularizer=keras.regularizers.l2(hidden_l2_lambda),\n",
    "            activation = 'relu'\n",
    "        ))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        1,\n",
    "        activation = 'sigmoid',\n",
    "        bias_initializer = output_bias)\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr = learning_rate), \n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(\n",
    "    learning_rate,\n",
    "    past_history,\n",
    "    lstm_units,\n",
    "    hidden_layers,\n",
    "    hidden_units,\n",
    "    #lstm_l2_lambda,\n",
    "    hidden_l2_lambda,\n",
    "    class_0_weight,\n",
    "    class_1_weight\n",
    "):\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('past history:', past_history)\n",
    "    print('LSTM units:', lstm_units)\n",
    "    print('hidden layers:', hidden_layers)\n",
    "    print('hidden units:', hidden_units)\n",
    "    #print('lstm l2 lambda: {0:.1e}'.format(lstm_l2_lambda))\n",
    "    print('hidden l2 lambda: {0:.1e}'.format(hidden_l2_lambda))\n",
    "    print('class 0 weight:', class_0_weight)\n",
    "    print('class 1 weight:', class_1_weight)\n",
    "    print()\n",
    "    \n",
    "    # create data stream\n",
    "    x_train, y_train = multivariate_data(\n",
    "        training_data, \n",
    "        training_data[:, 1], \n",
    "        0,\n",
    "        None,\n",
    "        past_history,\n",
    "        future_target, \n",
    "        step\n",
    "    )\n",
    "    \n",
    "    x_validation, y_validation = multivariate_data(\n",
    "        validation_data, \n",
    "        validation_data[:, 1], \n",
    "        0,\n",
    "        None,\n",
    "        past_history,\n",
    "        future_target, \n",
    "        step\n",
    "    )\n",
    "    \n",
    "    start_index = (x_train.shape[0] - (x_train.shape[0] % 100))\n",
    "    end_index = x_train.shape[0]\n",
    "    \n",
    "    x_train = np.delete(x_train, range(start_index, end_index), axis=0)\n",
    "    y_train = np.delete(y_train, range(start_index, end_index), axis=0)\n",
    "    \n",
    "    start_index = (x_validation.shape[0] - (x_validation.shape[0] % 100))\n",
    "    end_index = x_validation.shape[0]\n",
    "    \n",
    "    x_validation = np.delete(x_validation, range(start_index, end_index), axis=0)\n",
    "    y_validation = np.delete(y_validation, range(start_index, end_index), axis=0)\n",
    "    \n",
    "    input_dim = x_train.shape[-2:]\n",
    "    \n",
    "    class_weight = {0: class_0_weight, 1: class_1_weight}\n",
    "    \n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = make_model(\n",
    "        input_dim,\n",
    "        learning_rate = learning_rate,\n",
    "        lstm_units = lstm_units,\n",
    "        hidden_layers = hidden_layers,\n",
    "        hidden_units = hidden_units,\n",
    "        #lstm_l2_lambda = lstm_l2_lambda,\n",
    "        hidden_l2_lambda = hidden_l2_lambda,\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "    print()\n",
    "\n",
    "    # Dir-name for the TensorBoard log-files.\n",
    "    log_dir = log_dir_name(\n",
    "        learning_rate,\n",
    "        past_history,\n",
    "        lstm_units,\n",
    "        hidden_layers,\n",
    "        hidden_units,\n",
    "        #lstm_l2_lambda,\n",
    "        hidden_l2_lambda,\n",
    "        class_0_weight,\n",
    "        class_1_weight\n",
    "    )\n",
    "    \n",
    "    # Create a callback-function for Keras which will be\n",
    "    # run after each epoch has ended during training.\n",
    "    # This saves the log-files for TensorBoard.\n",
    "    # Note that there are complications when histogram_freq=1.\n",
    "    # It might give strange errors and it also does not properly\n",
    "    # support Keras data-generators for the validation-set.\n",
    "    callback_log = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False\n",
    "    )\n",
    "   \n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        callbacks = [early_stopping],\n",
    "        validation_data=(x_validation, y_validation),\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        class_weight=class_weight,\n",
    "        workers=8\n",
    "    )\n",
    "\n",
    "    # Get fraction incorrect on the validation-set\n",
    "    # after the last training-epoch.\n",
    "          \n",
    "    val_fp = history.history['val_fp'][-1]\n",
    "    val_fn = history.history['val_fn'][-1]\n",
    "    val_tp = history.history['val_tp'][-1]\n",
    "    val_tn = history.history['val_tn'][-1]\n",
    "          \n",
    "    fraction_incorrect = (val_fn /(val_fn + val_tp + K.epsilon())) + (val_fp / (val_fp + val_tn + K.epsilon()))\n",
    "    \n",
    "    print()\n",
    "    print(\"Validation fraction incorrect: {0:.2}\".format(fraction_incorrect))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_fraction_incorrect\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if fraction_incorrect < best_fraction_incorrect:\n",
    "        # Save the new model to harddisk.\n",
    "        model.save(path_best_model)\n",
    "        \n",
    "        # Update the classification accuracy.\n",
    "        best_fraction_incorrect = fraction_incorrect\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return fraction_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-03\n",
      "past history: 3\n",
      "LSTM units: 50\n",
      "hidden layers: 2\n",
      "hidden units: 50\n",
      "hidden l2 lambda: 1.0e-01\n",
      "class 0 weight: 0.5\n",
      "class 1 weight: 15\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 50)                 19800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 50)                 2550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 50)                 2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 1)                  51        \n",
      "=================================================================\n",
      "Total params: 24,951\n",
      "Trainable params: 24,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 9.9303 - tp: 28.0000 - fp: 468.0000 - tn: 962.0000 - fn: 42.0000 - accuracy: 0.6600 - precision: 0.0565 - recall: 0.4000 - auc: 0.5524 - f1: 0.2934 - val_loss: 1.9503 - val_tp: 19.0000 - val_fp: 466.0000 - val_tn: 15.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0680 - val_precision: 0.0392 - val_recall: 1.0000 - val_auc: 0.6869 - val_f1: 0.4648Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 8.3441 - tp: 70.0000 - fp: 1309.0000 - tn: 121.0000 - fn: 0.0000e+00 - accuracy: 0.1273 - precision: 0.0508 - recall: 1.0000 - auc: 0.7375 - f1: 0.6544Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 7.0411 - tp: 76.0000 - fp: 922.0000 - tn: 500.0000 - fn: 2.0000 - accuracy: 0.3840 - precision: 0.0762 - recall: 0.9744 - auc: 0.7457 - f1: 0.8166 - val_loss: 1.3743 - val_tp: 18.0000 - val_fp: 324.0000 - val_tn: 157.0000 - val_fn: 1.0000 - val_accuracy: 0.3500 - val_precision: 0.0526 - val_recall: 0.9474 - val_auc: 0.6898 - val_f1: 0.4769Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 5.8600 - tp: 69.0000 - fp: 871.0000 - tn: 558.0000 - fn: 2.0000 - accuracy: 0.4180 - precision: 0.0734 - recall: 0.9718 - auc: 0.7970 - f1: 0.7649 - val_loss: 1.1546 - val_tp: 17.0000 - val_fp: 252.0000 - val_tn: 229.0000 - val_fn: 2.0000 - val_accuracy: 0.4920 - val_precision: 0.0632 - val_recall: 0.8947 - val_auc: 0.6943 - val_f1: 0.4778Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 4.9762 - tp: 83.0000 - fp: 799.0000 - tn: 617.0000 - fn: 1.0000 - accuracy: 0.4667 - precision: 0.0941 - recall: 0.9881 - auc: 0.7537 - f1: 0.9220 - val_loss: 0.9741 - val_tp: 17.0000 - val_fp: 277.0000 - val_tn: 204.0000 - val_fn: 2.0000 - val_accuracy: 0.4420 - val_precision: 0.0578 - val_recall: 0.8947 - val_auc: 0.7095 - val_f1: 0.4600Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 4.2067 - tp: 83.0000 - fp: 672.0000 - tn: 739.0000 - fn: 6.0000 - accuracy: 0.5480 - precision: 0.1099 - recall: 0.9326 - auc: 0.7787 - f1: 0.9782 - val_loss: 0.8185 - val_tp: 18.0000 - val_fp: 256.0000 - val_tn: 225.0000 - val_fn: 1.0000 - val_accuracy: 0.4860 - val_precision: 0.0657 - val_recall: 0.9474 - val_auc: 0.7179 - val_f1: 0.4915Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 3.4439 - tp: 59.0000 - fp: 623.0000 - tn: 816.0000 - fn: 2.0000 - accuracy: 0.5833 - precision: 0.0865 - recall: 0.9672 - auc: 0.8231 - f1: 0.8730 - val_loss: 0.6856 - val_tp: 17.0000 - val_fp: 203.0000 - val_tn: 278.0000 - val_fn: 2.0000 - val_accuracy: 0.5900 - val_precision: 0.0773 - val_recall: 0.8947 - val_auc: 0.7335 - val_f1: 0.5019Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 2.9461 - tp: 52.0000 - fp: 521.0000 - tn: 917.0000 - fn: 10.0000 - accuracy: 0.6460 - precision: 0.0908 - recall: 0.8387 - auc: 0.8020 - f1: 0.8250 - val_loss: 0.5813 - val_tp: 17.0000 - val_fp: 217.0000 - val_tn: 264.0000 - val_fn: 2.0000 - val_accuracy: 0.5620 - val_precision: 0.0726 - val_recall: 0.8947 - val_auc: 0.7359 - val_f1: 0.4858Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 2.5958 - tp: 72.0000 - fp: 666.0000 - tn: 754.0000 - fn: 8.0000 - accuracy: 0.5507 - precision: 0.0976 - recall: 0.9000 - auc: 0.7816 - f1: 0.8825 - val_loss: 0.5025 - val_tp: 19.0000 - val_fp: 262.0000 - val_tn: 219.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4760 - val_precision: 0.0676 - val_recall: 1.0000 - val_auc: 0.7349 - val_f1: 0.5141Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 2.2096 - tp: 76.0000 - fp: 700.0000 - tn: 720.0000 - fn: 4.0000 - accuracy: 0.5307 - precision: 0.0979 - recall: 0.9500 - auc: 0.7798 - f1: 0.9396 - val_loss: 0.4309 - val_tp: 19.0000 - val_fp: 252.0000 - val_tn: 229.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4960 - val_precision: 0.0701 - val_recall: 1.0000 - val_auc: 0.7342 - val_f1: 0.5164Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 1.8396 - tp: 60.0000 - fp: 588.0000 - tn: 847.0000 - fn: 5.0000 - accuracy: 0.6047 - precision: 0.0926 - recall: 0.9231 - auc: 0.8167 - f1: 0.8821 - val_loss: 0.3679 - val_tp: 17.0000 - val_fp: 206.0000 - val_tn: 275.0000 - val_fn: 2.0000 - val_accuracy: 0.5840 - val_precision: 0.0762 - val_recall: 0.8947 - val_auc: 0.7297 - val_f1: 0.4972Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 1.6217 - tp: 68.0000 - fp: 598.0000 - tn: 831.0000 - fn: 3.0000 - accuracy: 0.5993 - precision: 0.1021 - recall: 0.9577 - auc: 0.7999 - f1: 0.9539 - val_loss: 0.3220 - val_tp: 18.0000 - val_fp: 217.0000 - val_tn: 264.0000 - val_fn: 1.0000 - val_accuracy: 0.5640 - val_precision: 0.0766 - val_recall: 0.9474 - val_auc: 0.7275 - val_f1: 0.5157Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 1.4039 - tp: 57.0000 - fp: 549.0000 - tn: 890.0000 - fn: 4.0000 - accuracy: 0.6313 - precision: 0.0941 - recall: 0.9344 - auc: 0.8065 - f1: 0.8683 - val_loss: 0.2836 - val_tp: 17.0000 - val_fp: 208.0000 - val_tn: 273.0000 - val_fn: 2.0000 - val_accuracy: 0.5800 - val_precision: 0.0756 - val_recall: 0.8947 - val_auc: 0.7236 - val_f1: 0.4970Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 1.3112 - tp: 70.0000 - fp: 620.0000 - tn: 805.0000 - fn: 5.0000 - accuracy: 0.5833 - precision: 0.1014 - recall: 0.9333 - auc: 0.7908 - f1: 0.9630 - val_loss: 0.2555 - val_tp: 19.0000 - val_fp: 241.0000 - val_tn: 240.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5180 - val_precision: 0.0731 - val_recall: 1.0000 - val_auc: 0.7203 - val_f1: 0.5256Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 1.2249 - tp: 83.0000 - fp: 705.0000 - tn: 707.0000 - fn: 5.0000 - accuracy: 0.5267 - precision: 0.1053 - recall: 0.9432 - auc: 0.7688 - f1: 0.9630\n",
      "Validation fraction incorrect: 0.51\n",
      "\n",
      "learning rate: 1.5e-02\n",
      "past history: 6\n",
      "LSTM units: 391\n",
      "hidden layers: 6\n",
      "hidden units: 226\n",
      "hidden l2 lambda: 2.0e-04\n",
      "class 0 weight: 0.5133240027692806\n",
      "class 1 weight: 13\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 391)                688160    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 226)                88592     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 226)                51302     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 226)                51302     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 226)                51302     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 226)                51302     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 226)                51302     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 1)                  227       \n",
      "=================================================================\n",
      "Total params: 1,033,489\n",
      "Trainable params: 1,033,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 24s - loss: 3.8613 - tp: 23.0000 - fp: 461.0000 - tn: 969.0000 - fn: 47.0000 - accuracy: 0.6613 - precision: 0.0475 - recall: 0.3286 - auc: 0.4897 - f1: 0.2112 - val_loss: 0.2069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 482.0000 - val_fn: 18.0000 - val_accuracy: 0.9640 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3192 - val_f1: 0.0000e+00Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 1.0427 - tp: 57.0000 - fp: 800.0000 - tn: 620.0000 - fn: 23.0000 - accuracy: 0.4513 - precision: 0.0665 - recall: 0.7125 - auc: 0.5837 - f1: 0.5723 - val_loss: 0.1938 - val_tp: 18.0000 - val_fp: 331.0000 - val_tn: 151.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3380 - val_precision: 0.0516 - val_recall: 1.0000 - val_auc: 0.7843 - val_f1: 0.4822Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.9476 - tp: 46.0000 - fp: 573.0000 - tn: 856.0000 - fn: 25.0000 - accuracy: 0.6013 - precision: 0.0743 - recall: 0.6479 - auc: 0.6817 - f1: 0.5734 - val_loss: 0.1974 - val_tp: 18.0000 - val_fp: 263.0000 - val_tn: 219.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4740 - val_precision: 0.0641 - val_recall: 1.0000 - val_auc: 0.7846 - val_f1: 0.4986Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.8353 - tp: 60.0000 - fp: 517.0000 - tn: 906.0000 - fn: 17.0000 - accuracy: 0.6440 - precision: 0.1040 - recall: 0.7792 - auc: 0.7867 - f1: 0.7976 - val_loss: 0.1597 - val_tp: 10.0000 - val_fp: 128.0000 - val_tn: 354.0000 - val_fn: 8.0000 - val_accuracy: 0.7280 - val_precision: 0.0725 - val_recall: 0.5556 - val_auc: 0.7607 - val_f1: 0.3654Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.9043 - tp: 55.0000 - fp: 627.0000 - tn: 797.0000 - fn: 21.0000 - accuracy: 0.5680 - precision: 0.0806 - recall: 0.7237 - auc: 0.7144 - f1: 0.6041 - val_loss: 0.1824 - val_tp: 17.0000 - val_fp: 292.0000 - val_tn: 190.0000 - val_fn: 1.0000 - val_accuracy: 0.4140 - val_precision: 0.0550 - val_recall: 0.9444 - val_auc: 0.7286 - val_f1: 0.4664Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 1.0198 - tp: 72.0000 - fp: 1128.0000 - tn: 287.0000 - fn: 13.0000 - accuracy: 0.2393 - precision: 0.0600 - recall: 0.8471 - auc: 0.5587 - f1: 0.6245 - val_loss: 0.1763 - val_tp: 18.0000 - val_fp: 344.0000 - val_tn: 138.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3120 - val_precision: 0.0497 - val_recall: 1.0000 - val_auc: 0.7287 - val_f1: 0.4879Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.8725 - tp: 7.0000 - fp: 97.0000 - tn: 1346.0000 - fn: 50.0000 - accuracy: 0.9020 - precision: 0.0673 - recall: 0.1228 - auc: 0.5442 - f1: 0.1045 - val_loss: 0.1711 - val_tp: 16.0000 - val_fp: 231.0000 - val_tn: 251.0000 - val_fn: 2.0000 - val_accuracy: 0.5340 - val_precision: 0.0648 - val_recall: 0.8889 - val_auc: 0.7496 - val_f1: 0.4659Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 8s - loss: 0.8136 - tp: 60.0000 - fp: 863.0000 - tn: 573.0000 - fn: 4.0000 - accuracy: 0.4220 - precision: 0.0650 - recall: 0.9375 - auc: 0.7217 - f1: 0.7073 - val_loss: 0.1685 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 482.0000 - val_fn: 18.0000 - val_accuracy: 0.9640 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7684 - val_f1: 0.0000e+00Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.8057 - tp: 47.0000 - fp: 402.0000 - tn: 1025.0000 - fn: 26.0000 - accuracy: 0.7147 - precision: 0.1047 - recall: 0.6438 - auc: 0.7690 - f1: 0.6566 - val_loss: 0.1479 - val_tp: 15.0000 - val_fp: 186.0000 - val_tn: 296.0000 - val_fn: 3.0000 - val_accuracy: 0.6220 - val_precision: 0.0746 - val_recall: 0.8333 - val_auc: 0.7619 - val_f1: 0.4691Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.8743 - tp: 79.0000 - fp: 757.0000 - tn: 656.0000 - fn: 8.0000 - accuracy: 0.4900 - precision: 0.0945 - recall: 0.9080 - auc: 0.7432 - f1: 0.9070 - val_loss: 0.1646 - val_tp: 18.0000 - val_fp: 320.0000 - val_tn: 162.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3600 - val_precision: 0.0533 - val_recall: 1.0000 - val_auc: 0.7363 - val_f1: 0.4803Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.8435 - tp: 51.0000 - fp: 740.0000 - tn: 687.0000 - fn: 22.0000 - accuracy: 0.4920 - precision: 0.0645 - recall: 0.6986 - auc: 0.6634 - f1: 0.5908 - val_loss: 0.1564 - val_tp: 18.0000 - val_fp: 330.0000 - val_tn: 152.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3400 - val_precision: 0.0517 - val_recall: 1.0000 - val_auc: 0.7554 - val_f1: 0.4826Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.7736 - tp: 61.0000 - fp: 667.0000 - tn: 761.0000 - fn: 11.0000 - accuracy: 0.5480 - precision: 0.0838 - recall: 0.8472 - auc: 0.7385 - f1: 0.8147 - val_loss: 0.1428 - val_tp: 12.0000 - val_fp: 145.0000 - val_tn: 337.0000 - val_fn: 6.0000 - val_accuracy: 0.6980 - val_precision: 0.0764 - val_recall: 0.6667 - val_auc: 0.7427 - val_f1: 0.4270Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 5s - loss: 0.8317 - tp: 37.0000 - fp: 481.0000 - tn: 964.0000 - fn: 18.0000 - accuracy: 0.6673 - precision: 0.0714 - recall: 0.6727 - auc: 0.7227 - f1: 0.5903Restoring model weights from the end of the best epoch.\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 0.8315 - tp: 37.0000 - fp: 481.0000 - tn: 964.0000 - fn: 18.0000 - accuracy: 0.6673 - precision: 0.0714 - recall: 0.6727 - auc: 0.7227 - f1: 0.5903 - val_loss: 0.1640 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 482.0000 - val_fn: 18.0000 - val_accuracy: 0.9640 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7334 - val_f1: 0.0000e+00Epoch 00013: early stopping\n",
      "\n",
      "Validation fraction incorrect: 1.0\n",
      "\n",
      "learning rate: 3.7e-05\n",
      "past history: 20\n",
      "LSTM units: 33\n",
      "hidden layers: 7\n",
      "hidden units: 470\n",
      "hidden l2 lambda: 1.0e-04\n",
      "class 0 weight: 0.992990403362096\n",
      "class 1 weight: 16\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 33)                 10824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 470)                15980     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 470)                221370    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 470)                221370    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 470)                221370    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 470)                221370    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 470)                221370    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 470)                221370    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (100, 1)                  471       \n",
      "=================================================================\n",
      "Total params: 1,355,495\n",
      "Trainable params: 1,355,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 22s - loss: 1.7237 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1426.0000 - fn: 74.0000 - accuracy: 0.9507 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5218 - f1: 0.0000e+00 - val_loss: 0.2868 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5093 - val_f1: 0.0000e+00Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 4s - loss: 1.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1417.0000 - fn: 83.0000 - accuracy: 0.9447 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5612 - f1: 0.0000e+00 - val_loss: 0.2775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6509 - val_f1: 0.0000e+00Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 1.5019 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1428.0000 - fn: 72.0000 - accuracy: 0.9520 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5551 - f1: 0.0000e+00 - val_loss: 0.2734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7258 - val_f1: 0.0000e+00Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.4089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1433.0000 - fn: 67.0000 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5584 - f1: 0.0000e+00 - val_loss: 0.2750 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7384 - val_f1: 0.0000e+00Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.5391 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1415.0000 - fn: 85.0000 - accuracy: 0.9433 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6490 - f1: 0.0000e+00 - val_loss: 0.2791 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7125 - val_f1: 0.0000e+00Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.3971 - tp: 3.0000 - fp: 36.0000 - tn: 1397.0000 - fn: 64.0000 - accuracy: 0.9333 - precision: 0.0769 - recall: 0.0448 - auc: 0.6495 - f1: 0.0704 - val_loss: 0.2730 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7216 - val_f1: 0.0000e+00Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.2948 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1443.0000 - fn: 57.0000 - accuracy: 0.9620 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6657 - f1: 0.0000e+00 - val_loss: 0.2670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7268 - val_f1: 0.0000e+00Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.4807 - tp: 0.0000e+00 - fp: 1.0000 - tn: 1420.0000 - fn: 79.0000 - accuracy: 0.9467 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6286 - f1: 0.0000e+00 - val_loss: 0.2699 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 478.0000 - val_fn: 17.0000 - val_accuracy: 0.9560 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7333 - val_f1: 0.0000e+00Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.4868 - tp: 42.0000 - fp: 363.0000 - tn: 1052.0000 - fn: 43.0000 - accuracy: 0.7293 - precision: 0.1037 - recall: 0.4941 - auc: 0.7139 - f1: 0.6162 - val_loss: 0.2724 - val_tp: 16.0000 - val_fp: 252.0000 - val_tn: 231.0000 - val_fn: 1.0000 - val_accuracy: 0.4940 - val_precision: 0.0597 - val_recall: 0.9412 - val_auc: 0.7354 - val_f1: 0.4585Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 1.4470 - tp: 49.0000 - fp: 452.0000 - tn: 966.0000 - fn: 33.0000 - accuracy: 0.6767 - precision: 0.0978 - recall: 0.5976 - auc: 0.6983 - f1: 0.6963 - val_loss: 0.2649 - val_tp: 11.0000 - val_fp: 172.0000 - val_tn: 311.0000 - val_fn: 6.0000 - val_accuracy: 0.6440 - val_precision: 0.0601 - val_recall: 0.6471 - val_auc: 0.7329 - val_f1: 0.3553Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.3131 - tp: 42.0000 - fp: 503.0000 - tn: 931.0000 - fn: 24.0000 - accuracy: 0.6487 - precision: 0.0771 - recall: 0.6364 - auc: 0.7219 - f1: 0.6771 - val_loss: 0.2548 - val_tp: 1.0000 - val_fp: 29.0000 - val_tn: 454.0000 - val_fn: 16.0000 - val_accuracy: 0.9100 - val_precision: 0.0333 - val_recall: 0.0588 - val_auc: 0.7324 - val_f1: 0.0976Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.3190 - tp: 27.0000 - fp: 254.0000 - tn: 1175.0000 - fn: 44.0000 - accuracy: 0.8013 - precision: 0.0961 - recall: 0.3803 - auc: 0.7381 - f1: 0.5337 - val_loss: 0.2502 - val_tp: 8.0000 - val_fp: 100.0000 - val_tn: 383.0000 - val_fn: 9.0000 - val_accuracy: 0.7820 - val_precision: 0.0741 - val_recall: 0.4706 - val_auc: 0.7344 - val_f1: 0.3314Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.2031 - tp: 26.0000 - fp: 223.0000 - tn: 1217.0000 - fn: 34.0000 - accuracy: 0.8287 - precision: 0.1044 - recall: 0.4333 - auc: 0.7488 - f1: 0.5781 - val_loss: 0.2435 - val_tp: 8.0000 - val_fp: 93.0000 - val_tn: 390.0000 - val_fn: 9.0000 - val_accuracy: 0.7960 - val_precision: 0.0792 - val_recall: 0.4706 - val_auc: 0.7360 - val_f1: 0.3384Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.3526 - tp: 61.0000 - fp: 598.0000 - tn: 821.0000 - fn: 20.0000 - accuracy: 0.5880 - precision: 0.0926 - recall: 0.7531 - auc: 0.7147 - f1: 0.7998 - val_loss: 0.2431 - val_tp: 11.0000 - val_fp: 182.0000 - val_tn: 301.0000 - val_fn: 6.0000 - val_accuracy: 0.6240 - val_precision: 0.0570 - val_recall: 0.6471 - val_auc: 0.7393 - val_f1: 0.3446Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.2462 - tp: 50.0000 - fp: 459.0000 - tn: 967.0000 - fn: 24.0000 - accuracy: 0.6780 - precision: 0.0982 - recall: 0.6757 - auc: 0.7552 - f1: 0.7668 - val_loss: 0.2387 - val_tp: 11.0000 - val_fp: 182.0000 - val_tn: 301.0000 - val_fn: 6.0000 - val_accuracy: 0.6240 - val_precision: 0.0570 - val_recall: 0.6471 - val_auc: 0.7390 - val_f1: 0.3434\n",
      "Validation fraction incorrect: 0.73\n",
      "\n",
      "learning rate: 2.8e-03\n",
      "past history: 1\n",
      "LSTM units: 16\n",
      "hidden layers: 6\n",
      "hidden units: 203\n",
      "hidden l2 lambda: 1.4e-04\n",
      "class 0 weight: 0.9763799669573134\n",
      "class 1 weight: 12\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 16)                 4160      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 203)                3451      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 203)                41412     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 203)                41412     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 203)                41412     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 203)                41412     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 203)                41412     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 1)                  204       \n",
      "=================================================================\n",
      "Total params: 214,875\n",
      "Trainable params: 214,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 14s - loss: 1.0537 - tp: 8.0000 - fp: 186.0000 - tn: 1253.0000 - fn: 53.0000 - accuracy: 0.8407 - precision: 0.0412 - recall: 0.1311 - auc: 0.5174 - f1: 0.0741 - val_loss: 0.2185 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 480.0000 - val_fn: 20.0000 - val_accuracy: 0.9600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5125 - val_f1: 0.0000e+00Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 0s - loss: 1.1378 - tp: 9.0000 - fp: 52.0000 - tn: 1367.0000 - fn: 72.0000 - accuracy: 0.9173 - precision: 0.1475 - recall: 0.1111 - auc: 0.5464 - f1: 0.1242                  Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.8656 - tp: 57.0000 - fp: 419.0000 - tn: 1010.0000 - fn: 14.0000 - accuracy: 0.7113 - precision: 0.1197 - recall: 0.8028 - auc: 0.7862 - f1: 0.9543Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.9423 - tp: 45.0000 - fp: 373.0000 - tn: 1046.0000 - fn: 36.0000 - accuracy: 0.7273 - precision: 0.1077 - recall: 0.5556 - auc: 0.7384 - f1: 0.6187Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.8283 - tp: 58.0000 - fp: 509.0000 - tn: 919.0000 - fn: 14.0000 - accuracy: 0.6513 - precision: 0.1023 - recall: 0.8056 - auc: 0.7791 - f1: 0.8073Epoch 6/15\n",
      "1400/6300 [=====>........................] - ETA: 0s - loss: 0.8650 - tp: 37.0000 - fp: 364.0000 - tn: 970.0000 - fn: 29.0000 - accuracy: 0.7193 - precision: 0.0923 - recall: 0.5606 - auc: 0.7346 - f1: 0.5539               Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.8311 - tp: 62.0000 - fp: 441.0000 - tn: 982.0000 - fn: 15.0000 - accuracy: 0.6960 - precision: 0.1233 - recall: 0.8052 - auc: 0.7848 - f1: 0.9332 - val_loss: 0.1613 - val_tp: 17.0000 - val_fp: 170.0000 - val_tn: 310.0000 - val_fn: 3.0000 - val_accuracy: 0.6540 - val_precision: 0.0909 - val_recall: 0.8500 - val_auc: 0.7426 - val_f1: 0.5064Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.7475 - tp: 42.0000 - fp: 355.0000 - tn: 1076.0000 - fn: 27.0000 - accuracy: 0.7453 - precision: 0.1058 - recall: 0.6087 - auc: 0.8041 - f1: 0.6786 - val_loss: 0.1654 - val_tp: 18.0000 - val_fp: 217.0000 - val_tn: 263.0000 - val_fn: 2.0000 - val_accuracy: 0.5620 - val_precision: 0.0766 - val_recall: 0.9000 - val_auc: 0.7488 - val_f1: 0.4980Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.8693 - tp: 36.0000 - fp: 313.0000 - tn: 1109.0000 - fn: 42.0000 - accuracy: 0.7633 - precision: 0.1032 - recall: 0.4615 - auc: 0.7672 - f1: 0.5187 - val_loss: 0.1619 - val_tp: 17.0000 - val_fp: 167.0000 - val_tn: 313.0000 - val_fn: 3.0000 - val_accuracy: 0.6600 - val_precision: 0.0924 - val_recall: 0.8500 - val_auc: 0.7432 - val_f1: 0.5094Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.7739 - tp: 47.0000 - fp: 334.0000 - tn: 1097.0000 - fn: 22.0000 - accuracy: 0.7627 - precision: 0.1234 - recall: 0.6812 - auc: 0.8086 - f1: 0.7382 - val_loss: 0.1636 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 480.0000 - val_fn: 20.0000 - val_accuracy: 0.9600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7433 - val_f1: 0.0000e+00Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.8835 - tp: 48.0000 - fp: 377.0000 - tn: 1045.0000 - fn: 30.0000 - accuracy: 0.7287 - precision: 0.1129 - recall: 0.6154 - auc: 0.7618 - f1: 0.6529 - val_loss: 0.1675 - val_tp: 18.0000 - val_fp: 195.0000 - val_tn: 285.0000 - val_fn: 2.0000 - val_accuracy: 0.6060 - val_precision: 0.0845 - val_recall: 0.9000 - val_auc: 0.7529 - val_f1: 0.5165Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.8612 - tp: 63.0000 - fp: 454.0000 - tn: 965.0000 - fn: 18.0000 - accuracy: 0.6853 - precision: 0.1219 - recall: 0.7778 - auc: 0.7952 - f1: 0.9499 - val_loss: 0.1715 - val_tp: 18.0000 - val_fp: 186.0000 - val_tn: 294.0000 - val_fn: 2.0000 - val_accuracy: 0.6240 - val_precision: 0.0882 - val_recall: 0.9000 - val_auc: 0.7492 - val_f1: 0.5242Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.7927 - tp: 26.0000 - fp: 307.0000 - tn: 1127.0000 - fn: 40.0000 - accuracy: 0.7687 - precision: 0.0781 - recall: 0.3939 - auc: 0.7623 - f1: 0.5136 - val_loss: 0.1645 - val_tp: 18.0000 - val_fp: 184.0000 - val_tn: 296.0000 - val_fn: 2.0000 - val_accuracy: 0.6280 - val_precision: 0.0891 - val_recall: 0.9000 - val_auc: 0.7520 - val_f1: 0.5268Epoch 14/15\n",
      "1100/6300 [====>.........................] - ETA: 0s - loss: 0.7564 - tp: 41.0000 - fp: 340.0000 - tn: 715.0000 - fn: 4.0000 - accuracy: 0.6873 - precision: 0.1076 - recall: 0.9111 - auc: 0.8212 - f1: 0.9531    Restoring model weights from the end of the best epoch.\n",
      "1500/6300 [======>.......................] - ETA: 0s - loss: 0.8326 - tp: 51.0000 - fp: 437.0000 - tn: 996.0000 - fn: 16.0000 - accuracy: 0.6980 - precision: 0.1045 - recall: 0.7612 - auc: 0.7851 - f1: 0.8644 - val_loss: 0.1638 - val_tp: 15.0000 - val_fp: 153.0000 - val_tn: 327.0000 - val_fn: 5.0000 - val_accuracy: 0.6840 - val_precision: 0.0893 - val_recall: 0.7500 - val_auc: 0.7510 - val_f1: 0.4625Epoch 00014: early stopping\n",
      "\n",
      "Validation fraction incorrect: 0.57\n",
      "\n",
      "learning rate: 2.3e-05\n",
      "past history: 19\n",
      "LSTM units: 194\n",
      "hidden layers: 10\n",
      "hidden units: 236\n",
      "hidden l2 lambda: 3.8e-02\n",
      "class 0 weight: 0.7122767847290018\n",
      "class 1 weight: 15\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 194)                188568    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 236)                46020     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (100, 236)                55932     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (100, 1)                  237       \n",
      "=================================================================\n",
      "Total params: 738,213\n",
      "Trainable params: 738,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 24s - loss: 89.8846 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1424.0000 - fn: 76.0000 - accuracy: 0.9493 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5466 - f1: 0.0000e+00 - val_loss: 19.3618 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5776 - val_f1: 0.0000e+00Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 88.9606 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1431.0000 - fn: 69.0000 - accuracy: 0.9540 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5556 - f1: 0.0000e+00 - val_loss: 19.1866 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5021 - val_f1: 0.0000e+00Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 6s - loss: 88.3591 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1417.0000 - fn: 83.0000 - accuracy: 0.9447 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6096 - f1: 0.0000e+00 - val_loss: 19.0130 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5306 - val_f1: 0.0000e+00Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 87.3208 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1433.0000 - fn: 67.0000 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5886 - f1: 0.0000e+00 - val_loss: 18.8410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7214 - val_f1: 0.0000e+00Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 86.6702 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1423.0000 - fn: 77.0000 - accuracy: 0.9487 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6290 - f1: 0.0000e+00 - val_loss: 18.6707 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5369 - val_f1: 0.0000e+00Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 85.8115 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1428.0000 - fn: 72.0000 - accuracy: 0.9520 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6306 - f1: 0.0000e+00 - val_loss: 18.5017 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5306 - val_f1: 0.0000e+00Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 84.9634 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1433.0000 - fn: 67.0000 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6357 - f1: 0.0000e+00 - val_loss: 18.3342 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6387 - val_f1: 0.0000e+00Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 84.2074 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1432.0000 - fn: 68.0000 - accuracy: 0.9547 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5922 - f1: 0.0000e+00 - val_loss: 18.1684 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5773 - val_f1: 0.0000e+00Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 83.7146 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1411.0000 - fn: 89.0000 - accuracy: 0.9407 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5992 - f1: 0.0000e+00 - val_loss: 18.0040 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6350 - val_f1: 0.0000e+00Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 82.5939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1439.0000 - fn: 61.0000 - accuracy: 0.9593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6211 - f1: 0.0000e+00 - val_loss: 17.8411 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6078 - val_f1: 0.0000e+00Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 81.9460 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1431.0000 - fn: 69.0000 - accuracy: 0.9540 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6486 - f1: 0.0000e+00 - val_loss: 17.6797 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7670 - val_f1: 0.0000e+00Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 81.2265 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1429.0000 - fn: 71.0000 - accuracy: 0.9527 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6256 - f1: 0.0000e+00 - val_loss: 17.5197 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6122 - val_f1: 0.0000e+00Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 80.5819 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1421.0000 - fn: 79.0000 - accuracy: 0.9473 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6651 - f1: 0.0000e+00 - val_loss: 17.3611 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6430 - val_f1: 0.0000e+00Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 79.8909 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1417.0000 - fn: 83.0000 - accuracy: 0.9447 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6607 - f1: 0.0000e+00 - val_loss: 17.2039 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7783 - val_f1: 0.0000e+00Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 79.1586 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1417.0000 - fn: 83.0000 - accuracy: 0.9447 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6574 - f1: 0.0000e+00 - val_loss: 17.0480 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7695 - val_f1: 0.0000e+00\n",
      "Validation fraction incorrect: 1.0\n",
      "\n",
      "learning rate: 1.1e-05\n",
      "past history: 28\n",
      "LSTM units: 284\n",
      "hidden layers: 4\n",
      "hidden units: 13\n",
      "hidden l2 lambda: 4.9e-04\n",
      "class 0 weight: 0.3169229194234106\n",
      "class 1 weight: 17\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 284)                378288    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 13)                 3705      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 13)                 182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 13)                 182       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 13)                 182       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 1)                  14        \n",
      "=================================================================\n",
      "Total params: 382,553\n",
      "Trainable params: 382,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 26s - loss: 2.0278 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1421.0000 - fn: 79.0000 - accuracy: 0.9473 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5767 - f1: 0.0000e+00 - val_loss: 0.2560 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5623 - val_f1: 0.0000e+00Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 14s - loss: 1.9552 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1423.0000 - fn: 77.0000 - accuracy: 0.9487 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5341 - f1: 0.0000e+00 - val_loss: 0.2542 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5808 - val_f1: 0.0000e+00Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 14s - loss: 1.9186 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1424.0000 - fn: 76.0000 - accuracy: 0.9493 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5930 - f1: 0.0000e+00 - val_loss: 0.2532 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5742 - val_f1: 0.0000e+00Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 14s - loss: 1.5477 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1439.0000 - fn: 61.0000 - accuracy: 0.9593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5566 - f1: 0.0000e+00 - val_loss: 0.2520 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5330 - val_f1: 0.0000e+00Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 14s - loss: 2.0214 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1419.0000 - fn: 81.0000 - accuracy: 0.9460 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5621 - f1: 0.0000e+00 - val_loss: 0.2508 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6111 - val_f1: 0.0000e+00Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 14s - loss: 1.6524 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1434.0000 - fn: 66.0000 - accuracy: 0.9560 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6252 - f1: 0.0000e+00 - val_loss: 0.2498 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6303 - val_f1: 0.0000e+00Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 1.8586 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1425.0000 - fn: 75.0000 - accuracy: 0.9500 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6329 - f1: 0.0000e+00 - val_loss: 0.2483 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6155 - val_f1: 0.0000e+00Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 14s - loss: 1.8225 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1426.0000 - fn: 74.0000 - accuracy: 0.9507 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5683 - f1: 0.0000e+00 - val_loss: 0.2467 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6014 - val_f1: 0.0000e+00Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 1.8336 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1425.0000 - fn: 75.0000 - accuracy: 0.9500 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6895 - f1: 0.0000e+00 - val_loss: 0.2451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6649 - val_f1: 0.0000e+00Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 1.5426 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1437.0000 - fn: 63.0000 - accuracy: 0.9580 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6438 - f1: 0.0000e+00 - val_loss: 0.2438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6340 - val_f1: 0.0000e+00Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 1.7628 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1427.0000 - fn: 73.0000 - accuracy: 0.9513 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6067 - f1: 0.0000e+00 - val_loss: 0.2422 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5979 - val_f1: 0.0000e+00Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 13s - loss: 1.8660 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1422.0000 - fn: 78.0000 - accuracy: 0.9480 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6733 - f1: 0.0000e+00 - val_loss: 0.2404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6610 - val_f1: 0.0000e+00Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 12s - loss: 1.6467 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1431.0000 - fn: 69.0000 - accuracy: 0.9540 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6321 - f1: 0.0000e+00 - val_loss: 0.2388 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6357 - val_f1: 0.0000e+00Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 1.8818 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1420.0000 - fn: 80.0000 - accuracy: 0.9467 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6831 - f1: 0.0000e+00 - val_loss: 0.2370 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6608 - val_f1: 0.0000e+00Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 12s - loss: 1.8219 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1422.0000 - fn: 78.0000 - accuracy: 0.9480 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6490 - f1: 0.0000e+00 - val_loss: 0.2350 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 485.0000 - val_fn: 15.0000 - val_accuracy: 0.9700 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7128 - val_f1: 0.0000e+00\n",
      "Validation fraction incorrect: 1.0\n",
      "\n",
      "learning rate: 2.8e-03\n",
      "past history: 25\n",
      "LSTM units: 91\n",
      "hidden layers: 5\n",
      "hidden units: 95\n",
      "hidden l2 lambda: 1.8e-02\n",
      "class 0 weight: 0.48264028704212036\n",
      "class 1 weight: 12\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 91)                 50960     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 95)                 8740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 95)                 9120      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 95)                 9120      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 95)                 9120      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 95)                 9120      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 1)                  96        \n",
      "=================================================================\n",
      "Total params: 96,276\n",
      "Trainable params: 96,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 52s - loss: 7.1213 - tp: 39.0000 - fp: 511.0000 - tn: 926.0000 - fn: 24.0000 - accuracy: 0.6433 - precision: 0.0709 - recall: 0.6190 - auc: 0.6438 - f1: 0.4664 - val_loss: 1.0488 - val_tp: 12.0000 - val_fp: 152.0000 - val_tn: 332.0000 - val_fn: 4.0000 - val_accuracy: 0.6880 - val_precision: 0.0732 - val_recall: 0.7500 - val_auc: 0.7408 - val_f1: 0.4367Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 3s - loss: 3.6912 - tp: 82.0000 - fp: 570.0000 - tn: 840.0000 - fn: 8.0000 - accuracy: 0.6147 - precision: 0.1258 - recall: 0.9111 - auc: 0.7892 - f1: 1.0089 - val_loss: 0.5425 - val_tp: 16.0000 - val_fp: 242.0000 - val_tn: 242.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5160 - val_precision: 0.0620 - val_recall: 1.0000 - val_auc: 0.7667 - val_f1: 0.4573Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.9553 - tp: 58.0000 - fp: 537.0000 - tn: 888.0000 - fn: 17.0000 - accuracy: 0.6307 - precision: 0.0975 - recall: 0.7733 - auc: 0.7612 - f1: 0.8111 - val_loss: 0.3225 - val_tp: 16.0000 - val_fp: 272.0000 - val_tn: 212.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4560 - val_precision: 0.0556 - val_recall: 1.0000 - val_auc: 0.7696 - val_f1: 0.4497Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 1.1679 - tp: 57.0000 - fp: 540.0000 - tn: 895.0000 - fn: 8.0000 - accuracy: 0.6347 - precision: 0.0955 - recall: 0.8769 - auc: 0.7713 - f1: 0.8539 - val_loss: 0.1868 - val_tp: 15.0000 - val_fp: 202.0000 - val_tn: 282.0000 - val_fn: 1.0000 - val_accuracy: 0.5940 - val_precision: 0.0691 - val_recall: 0.9375 - val_auc: 0.7796 - val_f1: 0.4748Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.8612 - tp: 68.0000 - fp: 630.0000 - tn: 798.0000 - fn: 4.0000 - accuracy: 0.5773 - precision: 0.0974 - recall: 0.9444 - auc: 0.7835 - f1: 0.9201 - val_loss: 0.1494 - val_tp: 15.0000 - val_fp: 193.0000 - val_tn: 291.0000 - val_fn: 1.0000 - val_accuracy: 0.6120 - val_precision: 0.0721 - val_recall: 0.9375 - val_auc: 0.7588 - val_f1: 0.4869Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.7476 - tp: 67.0000 - fp: 535.0000 - tn: 890.0000 - fn: 8.0000 - accuracy: 0.6380 - precision: 0.1113 - recall: 0.8933 - auc: 0.7947 - f1: 0.9420 - val_loss: 0.1435 - val_tp: 16.0000 - val_fp: 219.0000 - val_tn: 265.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5620 - val_precision: 0.0681 - val_recall: 1.0000 - val_auc: 0.7689 - val_f1: 0.4756Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.7111 - tp: 72.0000 - fp: 542.0000 - tn: 880.0000 - fn: 6.0000 - accuracy: 0.6347 - precision: 0.1173 - recall: 0.9231 - auc: 0.7819 - f1: 0.9419 - val_loss: 0.1265 - val_tp: 14.0000 - val_fp: 169.0000 - val_tn: 315.0000 - val_fn: 2.0000 - val_accuracy: 0.6580 - val_precision: 0.0765 - val_recall: 0.8750 - val_auc: 0.7740 - val_f1: 0.4649Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.6660 - tp: 65.0000 - fp: 550.0000 - tn: 878.0000 - fn: 7.0000 - accuracy: 0.6287 - precision: 0.1057 - recall: 0.9028 - auc: 0.7821 - f1: 0.9433 - val_loss: 0.1233 - val_tp: 15.0000 - val_fp: 210.0000 - val_tn: 274.0000 - val_fn: 1.0000 - val_accuracy: 0.5780 - val_precision: 0.0667 - val_recall: 0.9375 - val_auc: 0.7564 - val_f1: 0.4638Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.6148 - tp: 57.0000 - fp: 595.0000 - tn: 841.0000 - fn: 7.0000 - accuracy: 0.5987 - precision: 0.0874 - recall: 0.8906 - auc: 0.7822 - f1: 0.8349 - val_loss: 0.1208 - val_tp: 16.0000 - val_fp: 222.0000 - val_tn: 262.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5560 - val_precision: 0.0672 - val_recall: 1.0000 - val_auc: 0.7750 - val_f1: 0.4724Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.6415 - tp: 58.0000 - fp: 563.0000 - tn: 871.0000 - fn: 8.0000 - accuracy: 0.6193 - precision: 0.0934 - recall: 0.8788 - auc: 0.7728 - f1: 0.8777 - val_loss: 0.1270 - val_tp: 16.0000 - val_fp: 218.0000 - val_tn: 266.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5640 - val_precision: 0.0684 - val_recall: 1.0000 - val_auc: 0.7651 - val_f1: 0.4752Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.6244 - tp: 83.0000 - fp: 595.0000 - tn: 819.0000 - fn: 3.0000 - accuracy: 0.6013 - precision: 0.1224 - recall: 0.9651 - auc: 0.8234 - f1: 1.0515 - val_loss: 0.1182 - val_tp: 13.0000 - val_fp: 172.0000 - val_tn: 312.0000 - val_fn: 3.0000 - val_accuracy: 0.6500 - val_precision: 0.0703 - val_recall: 0.8125 - val_auc: 0.7577 - val_f1: 0.4030Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.6278 - tp: 69.0000 - fp: 563.0000 - tn: 862.0000 - fn: 6.0000 - accuracy: 0.6207 - precision: 0.1092 - recall: 0.9200 - auc: 0.7880 - f1: 0.9625 - val_loss: 0.1191 - val_tp: 15.0000 - val_fp: 206.0000 - val_tn: 278.0000 - val_fn: 1.0000 - val_accuracy: 0.5860 - val_precision: 0.0679 - val_recall: 0.9375 - val_auc: 0.7577 - val_f1: 0.4700Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.5794 - tp: 59.0000 - fp: 523.0000 - tn: 911.0000 - fn: 7.0000 - accuracy: 0.6467 - precision: 0.1014 - recall: 0.8939 - auc: 0.8037 - f1: 0.9354 - val_loss: 0.1134 - val_tp: 16.0000 - val_fp: 202.0000 - val_tn: 282.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5960 - val_precision: 0.0734 - val_recall: 1.0000 - val_auc: 0.7714 - val_f1: 0.4997Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.6056 - tp: 69.0000 - fp: 544.0000 - tn: 880.0000 - fn: 7.0000 - accuracy: 0.6327 - precision: 0.1126 - recall: 0.9079 - auc: 0.8058 - f1: 0.9565 - val_loss: 0.1114 - val_tp: 13.0000 - val_fp: 157.0000 - val_tn: 327.0000 - val_fn: 3.0000 - val_accuracy: 0.6800 - val_precision: 0.0765 - val_recall: 0.8125 - val_auc: 0.7920 - val_f1: 0.4236Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.6132 - tp: 71.0000 - fp: 517.0000 - tn: 905.0000 - fn: 7.0000 - accuracy: 0.6507 - precision: 0.1207 - recall: 0.9103 - auc: 0.8038 - f1: 1.0131 - val_loss: 0.1099 - val_tp: 16.0000 - val_fp: 201.0000 - val_tn: 283.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5980 - val_precision: 0.0737 - val_recall: 1.0000 - val_auc: 0.7647 - val_f1: 0.5031\n",
      "Validation fraction incorrect: 0.42\n",
      "\n",
      "learning rate: 1.9e-03\n",
      "past history: 2\n",
      "LSTM units: 422\n",
      "hidden layers: 5\n",
      "hidden units: 201\n",
      "hidden l2 lambda: 6.0e-02\n",
      "class 0 weight: 0.7545447962707789\n",
      "class 1 weight: 13\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 422)                795048    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 201)                85023     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 201)                40602     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 201)                40602     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 201)                40602     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 201)                40602     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 1)                  202       \n",
      "=================================================================\n",
      "Total params: 1,042,681\n",
      "Trainable params: 1,042,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 47.6746 - tp: 20.0000 - fp: 383.0000 - tn: 1046.0000 - fn: 51.0000 - accuracy: 0.7107 - precision: 0.0496 - recall: 0.2817 - auc: 0.5021 - f1: 0.1721 - val_loss: 6.5917 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 480.0000 - val_fn: 20.0000 - val_accuracy: 0.9600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6944 - val_f1: 0.0000e+00Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 2s - loss: 20.7866 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1435.0000 - fn: 65.0000 - accuracy: 0.9567 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5264 - f1: 0.0000e+00 - val_loss: 2.6678 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 480.0000 - val_fn: 20.0000 - val_accuracy: 0.9600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7122 - val_f1: 0.0000e+00Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 8.2137 - tp: 6.0000 - fp: 46.0000 - tn: 1382.0000 - fn: 66.0000 - accuracy: 0.9253 - precision: 0.1154 - recall: 0.0833 - auc: 0.7148 - f1: 0.0951 - val_loss: 1.0221 - val_tp: 17.0000 - val_fp: 226.0000 - val_tn: 254.0000 - val_fn: 3.0000 - val_accuracy: 0.5420 - val_precision: 0.0700 - val_recall: 0.8500 - val_auc: 0.7214 - val_f1: 0.4770Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 3.3126 - tp: 65.0000 - fp: 583.0000 - tn: 834.0000 - fn: 18.0000 - accuracy: 0.5993 - precision: 0.1003 - recall: 0.7831 - auc: 0.7410 - f1: 0.8622 - val_loss: 0.4315 - val_tp: 17.0000 - val_fp: 181.0000 - val_tn: 299.0000 - val_fn: 3.0000 - val_accuracy: 0.6320 - val_precision: 0.0859 - val_recall: 0.8500 - val_auc: 0.7449 - val_f1: 0.4959Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.5481 - tp: 68.0000 - fp: 494.0000 - tn: 931.0000 - fn: 7.0000 - accuracy: 0.6660 - precision: 0.1210 - recall: 0.9067 - auc: 0.8098 - f1: 0.9926 - val_loss: 0.2588 - val_tp: 12.0000 - val_fp: 145.0000 - val_tn: 335.0000 - val_fn: 8.0000 - val_accuracy: 0.6940 - val_precision: 0.0764 - val_recall: 0.6000 - val_auc: 0.7521 - val_f1: 0.3703Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.1105 - tp: 68.0000 - fp: 506.0000 - tn: 911.0000 - fn: 15.0000 - accuracy: 0.6527 - precision: 0.1185 - recall: 0.8193 - auc: 0.7740 - f1: 0.8851 - val_loss: 0.2019 - val_tp: 19.0000 - val_fp: 216.0000 - val_tn: 264.0000 - val_fn: 1.0000 - val_accuracy: 0.5660 - val_precision: 0.0809 - val_recall: 0.9500 - val_auc: 0.7505 - val_f1: 0.5272Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9143 - tp: 44.0000 - fp: 484.0000 - tn: 955.0000 - fn: 17.0000 - accuracy: 0.6660 - precision: 0.0833 - recall: 0.7213 - auc: 0.7239 - f1: 0.6861 - val_loss: 0.1863 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 480.0000 - val_fn: 20.0000 - val_accuracy: 0.9600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7453 - val_f1: 0.0000e+00Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.8995 - tp: 33.0000 - fp: 349.0000 - tn: 1087.0000 - fn: 31.0000 - accuracy: 0.7467 - precision: 0.0864 - recall: 0.5156 - auc: 0.7387 - f1: 0.5273 - val_loss: 0.1760 - val_tp: 16.0000 - val_fp: 174.0000 - val_tn: 306.0000 - val_fn: 4.0000 - val_accuracy: 0.6440 - val_precision: 0.0842 - val_recall: 0.8000 - val_auc: 0.7421 - val_f1: 0.4637Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9342 - tp: 73.0000 - fp: 462.0000 - tn: 951.0000 - fn: 14.0000 - accuracy: 0.6827 - precision: 0.1364 - recall: 0.8391 - auc: 0.7894 - f1: 0.9859 - val_loss: 0.1790 - val_tp: 17.0000 - val_fp: 195.0000 - val_tn: 285.0000 - val_fn: 3.0000 - val_accuracy: 0.6040 - val_precision: 0.0802 - val_recall: 0.8500 - val_auc: 0.7484 - val_f1: 0.4735Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9741 - tp: 71.0000 - fp: 602.0000 - tn: 816.0000 - fn: 11.0000 - accuracy: 0.5913 - precision: 0.1055 - recall: 0.8659 - auc: 0.7184 - f1: 0.9043 - val_loss: 0.1890 - val_tp: 20.0000 - val_fp: 258.0000 - val_tn: 222.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4840 - val_precision: 0.0719 - val_recall: 1.0000 - val_auc: 0.7476 - val_f1: 0.5336Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.8371 - tp: 46.0000 - fp: 462.0000 - tn: 973.0000 - fn: 19.0000 - accuracy: 0.6793 - precision: 0.0906 - recall: 0.7077 - auc: 0.7718 - f1: 0.7157 - val_loss: 0.1758 - val_tp: 19.0000 - val_fp: 211.0000 - val_tn: 269.0000 - val_fn: 1.0000 - val_accuracy: 0.5760 - val_precision: 0.0826 - val_recall: 0.9500 - val_auc: 0.7433 - val_f1: 0.5318Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9303 - tp: 67.0000 - fp: 583.0000 - tn: 840.0000 - fn: 10.0000 - accuracy: 0.6047 - precision: 0.1031 - recall: 0.8701 - auc: 0.7580 - f1: 0.9338 - val_loss: 0.1732 - val_tp: 19.0000 - val_fp: 213.0000 - val_tn: 267.0000 - val_fn: 1.0000 - val_accuracy: 0.5720 - val_precision: 0.0819 - val_recall: 0.9500 - val_auc: 0.7239 - val_f1: 0.5318Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.7897 - tp: 50.0000 - fp: 480.0000 - tn: 961.0000 - fn: 9.0000 - accuracy: 0.6740 - precision: 0.0943 - recall: 0.8475 - auc: 0.7811 - f1: 0.8878 - val_loss: 0.1797 - val_tp: 20.0000 - val_fp: 236.0000 - val_tn: 244.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5280 - val_precision: 0.0781 - val_recall: 1.0000 - val_auc: 0.7453 - val_f1: 0.5425Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.8630 - tp: 41.0000 - fp: 446.0000 - tn: 987.0000 - fn: 26.0000 - accuracy: 0.6853 - precision: 0.0842 - recall: 0.6119 - auc: 0.7608 - f1: 0.6252 - val_loss: 0.1803 - val_tp: 20.0000 - val_fp: 243.0000 - val_tn: 237.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5140 - val_precision: 0.0760 - val_recall: 1.0000 - val_auc: 0.7371 - val_f1: 0.5399Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 1s - loss: 0.9149 - tp: 78.0000 - fp: 536.0000 - tn: 878.0000 - fn: 8.0000 - accuracy: 0.6373 - precision: 0.1270 - recall: 0.9070 - auc: 0.7805 - f1: 1.0413Restoring model weights from the end of the best epoch.\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9150 - tp: 78.0000 - fp: 536.0000 - tn: 878.0000 - fn: 8.0000 - accuracy: 0.6373 - precision: 0.1270 - recall: 0.9070 - auc: 0.7805 - f1: 1.0413 - val_loss: 0.1815 - val_tp: 19.0000 - val_fp: 220.0000 - val_tn: 260.0000 - val_fn: 1.0000 - val_accuracy: 0.5580 - val_precision: 0.0795 - val_recall: 0.9500 - val_auc: 0.7460 - val_f1: 0.5235Epoch 00015: early stopping\n",
      "\n",
      "Validation fraction incorrect: 0.51\n",
      "\n",
      "learning rate: 1.9e-03\n",
      "past history: 16\n",
      "LSTM units: 481\n",
      "hidden layers: 9\n",
      "hidden units: 375\n",
      "hidden l2 lambda: 4.2e-03\n",
      "class 0 weight: 0.6280760490974635\n",
      "class 1 weight: 20\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 481)                1019720   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 375)                180750    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 375)                141000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 375)                141000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 375)                141000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 375)                141000    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 375)                141000    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 375)                141000    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (100, 375)                141000    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (100, 375)                141000    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (100, 1)                  376       \n",
      "=================================================================\n",
      "Total params: 2,328,846\n",
      "Trainable params: 2,328,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 31s - loss: 11.3559 - tp: 35.0000 - fp: 574.0000 - tn: 852.0000 - fn: 39.0000 - accuracy: 0.5913 - precision: 0.0575 - recall: 0.4730 - auc: 0.5560 - f1: 0.3158 - val_loss: 1.6016 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7606 - val_f1: 0.0000e+00Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 5.6824 - tp: 50.0000 - fp: 917.0000 - tn: 509.0000 - fn: 24.0000 - accuracy: 0.3727 - precision: 0.0517 - recall: 0.6757 - auc: 0.5829 - f1: 0.5171 - val_loss: 0.8465 - val_tp: 13.0000 - val_fp: 158.0000 - val_tn: 325.0000 - val_fn: 4.0000 - val_accuracy: 0.6760 - val_precision: 0.0760 - val_recall: 0.7647 - val_auc: 0.7579 - val_f1: 0.3764Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 3.3372 - tp: 73.0000 - fp: 677.0000 - tn: 744.0000 - fn: 6.0000 - accuracy: 0.5447 - precision: 0.0973 - recall: 0.9241 - auc: 0.7419 - f1: 0.9019 - val_loss: 0.5690 - val_tp: 17.0000 - val_fp: 315.0000 - val_tn: 168.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3700 - val_precision: 0.0512 - val_recall: 1.0000 - val_auc: 0.7811 - val_f1: 0.4601Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 2.4628 - tp: 41.0000 - fp: 353.0000 - tn: 1082.0000 - fn: 24.0000 - accuracy: 0.7487 - precision: 0.1041 - recall: 0.6308 - auc: 0.7793 - f1: 0.5585 - val_loss: 0.4739 - val_tp: 17.0000 - val_fp: 219.0000 - val_tn: 264.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5620 - val_precision: 0.0720 - val_recall: 1.0000 - val_auc: 0.7876 - val_f1: 0.4961Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 16s - loss: 2.1540 - tp: 72.0000 - fp: 657.0000 - tn: 764.0000 - fn: 7.0000 - accuracy: 0.5573 - precision: 0.0988 - recall: 0.9114 - auc: 0.7474 - f1: 0.9112 - val_loss: 0.3992 - val_tp: 17.0000 - val_fp: 274.0000 - val_tn: 209.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4520 - val_precision: 0.0584 - val_recall: 1.0000 - val_auc: 0.7850 - val_f1: 0.4659Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.8640 - tp: 72.0000 - fp: 622.0000 - tn: 800.0000 - fn: 6.0000 - accuracy: 0.5813 - precision: 0.1037 - recall: 0.9231 - auc: 0.7643 - f1: 0.9395 - val_loss: 0.3355 - val_tp: 17.0000 - val_fp: 201.0000 - val_tn: 282.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5980 - val_precision: 0.0780 - val_recall: 1.0000 - val_auc: 0.7789 - val_f1: 0.5153Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.6415 - tp: 59.0000 - fp: 780.0000 - tn: 657.0000 - fn: 4.0000 - accuracy: 0.4773 - precision: 0.0703 - recall: 0.9365 - auc: 0.7301 - f1: 0.7821 - val_loss: 0.3251 - val_tp: 17.0000 - val_fp: 275.0000 - val_tn: 208.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4500 - val_precision: 0.0582 - val_recall: 1.0000 - val_auc: 0.7938 - val_f1: 0.4671Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.4931 - tp: 70.0000 - fp: 700.0000 - tn: 728.0000 - fn: 2.0000 - accuracy: 0.5320 - precision: 0.0909 - recall: 0.9722 - auc: 0.7547 - f1: 0.9036 - val_loss: 0.2850 - val_tp: 15.0000 - val_fp: 161.0000 - val_tn: 322.0000 - val_fn: 2.0000 - val_accuracy: 0.6740 - val_precision: 0.0852 - val_recall: 0.8824 - val_auc: 0.7864 - val_f1: 0.4900Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.4413 - tp: 50.0000 - fp: 398.0000 - tn: 1038.0000 - fn: 14.0000 - accuracy: 0.7253 - precision: 0.1116 - recall: 0.7812 - auc: 0.7322 - f1: 0.8777 - val_loss: 0.2651 - val_tp: 15.0000 - val_fp: 176.0000 - val_tn: 307.0000 - val_fn: 2.0000 - val_accuracy: 0.6440 - val_precision: 0.0785 - val_recall: 0.8824 - val_auc: 0.7934 - val_f1: 0.4701Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.3660 - tp: 67.0000 - fp: 550.0000 - tn: 871.0000 - fn: 12.0000 - accuracy: 0.6253 - precision: 0.1086 - recall: 0.8481 - auc: 0.7517 - f1: 0.9210 - val_loss: 0.2454 - val_tp: 17.0000 - val_fp: 229.0000 - val_tn: 254.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5420 - val_precision: 0.0691 - val_recall: 1.0000 - val_auc: 0.7779 - val_f1: 0.4838Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.2140 - tp: 73.0000 - fp: 612.0000 - tn: 813.0000 - fn: 2.0000 - accuracy: 0.5907 - precision: 0.1066 - recall: 0.9733 - auc: 0.7784 - f1: 0.9955 - val_loss: 0.2242 - val_tp: 16.0000 - val_fp: 205.0000 - val_tn: 278.0000 - val_fn: 1.0000 - val_accuracy: 0.5880 - val_precision: 0.0724 - val_recall: 0.9412 - val_auc: 0.7734 - val_f1: 0.4641Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.2161 - tp: 72.0000 - fp: 490.0000 - tn: 927.0000 - fn: 11.0000 - accuracy: 0.6660 - precision: 0.1281 - recall: 0.8675 - auc: 0.7870 - f1: 0.9686 - val_loss: 0.2216 - val_tp: 15.0000 - val_fp: 159.0000 - val_tn: 324.0000 - val_fn: 2.0000 - val_accuracy: 0.6780 - val_precision: 0.0862 - val_recall: 0.8824 - val_auc: 0.7760 - val_f1: 0.4934Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.1849 - tp: 59.0000 - fp: 428.0000 - tn: 998.0000 - fn: 15.0000 - accuracy: 0.7047 - precision: 0.1211 - recall: 0.7973 - auc: 0.7487 - f1: 0.9004 - val_loss: 0.2406 - val_tp: 17.0000 - val_fp: 210.0000 - val_tn: 273.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5800 - val_precision: 0.0749 - val_recall: 1.0000 - val_auc: 0.7783 - val_f1: 0.5042Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 1.1143 - tp: 53.0000 - fp: 621.0000 - tn: 819.0000 - fn: 7.0000 - accuracy: 0.5813 - precision: 0.0786 - recall: 0.8833 - auc: 0.7457 - f1: 0.7679 - val_loss: 0.2065 - val_tp: 17.0000 - val_fp: 233.0000 - val_tn: 250.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5340 - val_precision: 0.0680 - val_recall: 1.0000 - val_auc: 0.7803 - val_f1: 0.4778Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 15s - loss: 1.1692 - tp: 74.0000 - fp: 589.0000 - tn: 825.0000 - fn: 12.0000 - accuracy: 0.5993 - precision: 0.1116 - recall: 0.8605 - auc: 0.7574 - f1: 0.8769 - val_loss: 0.1963 - val_tp: 16.0000 - val_fp: 197.0000 - val_tn: 286.0000 - val_fn: 1.0000 - val_accuracy: 0.6040 - val_precision: 0.0751 - val_recall: 0.9412 - val_auc: 0.7702 - val_f1: 0.4732\n",
      "Validation fraction incorrect: 0.47\n",
      "\n",
      "learning rate: 2.7e-03\n",
      "past history: 9\n",
      "LSTM units: 152\n",
      "hidden layers: 2\n",
      "hidden units: 13\n",
      "hidden l2 lambda: 1.9e-03\n",
      "class 0 weight: 0.45539336635801286\n",
      "class 1 weight: 13\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 152)                122208    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 13)                 1989      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 13)                 182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 1)                  14        \n",
      "=================================================================\n",
      "Total params: 124,393\n",
      "Trainable params: 124,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 17s - loss: 1.1883 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1429.0000 - fn: 71.0000 - accuracy: 0.9527 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4794 - f1: 0.0000e+00 - val_loss: 0.1504 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7120 - val_f1: 0.0000e+00Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.7937 - tp: 63.0000 - fp: 985.0000 - tn: 433.0000 - fn: 19.0000 - accuracy: 0.3307 - precision: 0.0601 - recall: 0.7683 - auc: 0.6187 - f1: 0.5352 - val_loss: 0.1485 - val_tp: 17.0000 - val_fp: 451.0000 - val_tn: 32.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0980 - val_precision: 0.0363 - val_recall: 1.0000 - val_auc: 0.7018 - val_f1: 0.4369Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.6524 - tp: 59.0000 - fp: 917.0000 - tn: 517.0000 - fn: 7.0000 - accuracy: 0.3840 - precision: 0.0605 - recall: 0.8939 - auc: 0.7377 - f1: 0.6811 - val_loss: 0.1236 - val_tp: 15.0000 - val_fp: 190.0000 - val_tn: 293.0000 - val_fn: 2.0000 - val_accuracy: 0.6160 - val_precision: 0.0732 - val_recall: 0.8824 - val_auc: 0.7110 - val_f1: 0.4796Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.6059 - tp: 68.0000 - fp: 661.0000 - tn: 765.0000 - fn: 6.0000 - accuracy: 0.5553 - precision: 0.0933 - recall: 0.9189 - auc: 0.7843 - f1: 0.8745 - val_loss: 0.1129 - val_tp: 15.0000 - val_fp: 218.0000 - val_tn: 265.0000 - val_fn: 2.0000 - val_accuracy: 0.5600 - val_precision: 0.0644 - val_recall: 0.8824 - val_auc: 0.7366 - val_f1: 0.4477Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.5629 - tp: 69.0000 - fp: 616.0000 - tn: 810.0000 - fn: 5.0000 - accuracy: 0.5860 - precision: 0.1007 - recall: 0.9324 - auc: 0.7807 - f1: 0.9334 - val_loss: 0.1193 - val_tp: 17.0000 - val_fp: 248.0000 - val_tn: 235.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5040 - val_precision: 0.0642 - val_recall: 1.0000 - val_auc: 0.7373 - val_f1: 0.4906Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.5995 - tp: 71.0000 - fp: 652.0000 - tn: 770.0000 - fn: 7.0000 - accuracy: 0.5607 - precision: 0.0982 - recall: 0.9103 - auc: 0.7724 - f1: 0.9118 - val_loss: 0.1096 - val_tp: 17.0000 - val_fp: 227.0000 - val_tn: 256.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5460 - val_precision: 0.0697 - val_recall: 1.0000 - val_auc: 0.7312 - val_f1: 0.5042Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.5821 - tp: 67.0000 - fp: 690.0000 - tn: 738.0000 - fn: 5.0000 - accuracy: 0.5367 - precision: 0.0885 - recall: 0.9306 - auc: 0.7836 - f1: 0.8548 - val_loss: 0.1038 - val_tp: 15.0000 - val_fp: 198.0000 - val_tn: 285.0000 - val_fn: 2.0000 - val_accuracy: 0.6000 - val_precision: 0.0704 - val_recall: 0.8824 - val_auc: 0.7456 - val_f1: 0.4690Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.5270 - tp: 58.0000 - fp: 521.0000 - tn: 914.0000 - fn: 7.0000 - accuracy: 0.6480 - precision: 0.1002 - recall: 0.8923 - auc: 0.8074 - f1: 0.9207 - val_loss: 0.1101 - val_tp: 17.0000 - val_fp: 226.0000 - val_tn: 257.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5480 - val_precision: 0.0700 - val_recall: 1.0000 - val_auc: 0.7460 - val_f1: 0.5045Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.5561 - tp: 66.0000 - fp: 600.0000 - tn: 829.0000 - fn: 5.0000 - accuracy: 0.5967 - precision: 0.0991 - recall: 0.9296 - auc: 0.8061 - f1: 0.9241 - val_loss: 0.1035 - val_tp: 14.0000 - val_fp: 202.0000 - val_tn: 281.0000 - val_fn: 3.0000 - val_accuracy: 0.5900 - val_precision: 0.0648 - val_recall: 0.8235 - val_auc: 0.7417 - val_f1: 0.4238Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.4818 - tp: 60.0000 - fp: 616.0000 - tn: 822.0000 - fn: 2.0000 - accuracy: 0.5880 - precision: 0.0888 - recall: 0.9677 - auc: 0.8182 - f1: 0.8728 - val_loss: 0.1031 - val_tp: 17.0000 - val_fp: 221.0000 - val_tn: 262.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5580 - val_precision: 0.0714 - val_recall: 1.0000 - val_auc: 0.7374 - val_f1: 0.5076Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 1s - loss: 0.5132 - tp: 70.0000 - fp: 582.0000 - tn: 844.0000 - fn: 4.0000 - accuracy: 0.6093 - precision: 0.1074 - recall: 0.9459 - auc: 0.8021 - f1: 0.9689 - val_loss: 0.1036 - val_tp: 15.0000 - val_fp: 213.0000 - val_tn: 270.0000 - val_fn: 2.0000 - val_accuracy: 0.5700 - val_precision: 0.0658 - val_recall: 0.8824 - val_auc: 0.7416 - val_f1: 0.4525Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 1s - loss: 0.6504 - tp: 84.0000 - fp: 697.0000 - tn: 712.0000 - fn: 7.0000 - accuracy: 0.5307 - precision: 0.1076 - recall: 0.9231 - auc: 0.7918 - f1: 0.9546 - val_loss: 0.1181 - val_tp: 17.0000 - val_fp: 270.0000 - val_tn: 213.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4600 - val_precision: 0.0592 - val_recall: 1.0000 - val_auc: 0.7251 - val_f1: 0.4811Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.5223 - tp: 62.0000 - fp: 595.0000 - tn: 837.0000 - fn: 6.0000 - accuracy: 0.5993 - precision: 0.0944 - recall: 0.9118 - auc: 0.8064 - f1: 0.9064 - val_loss: 0.1070 - val_tp: 15.0000 - val_fp: 212.0000 - val_tn: 271.0000 - val_fn: 2.0000 - val_accuracy: 0.5720 - val_precision: 0.0661 - val_recall: 0.8824 - val_auc: 0.7394 - val_f1: 0.4527Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.5135 - tp: 61.0000 - fp: 554.0000 - tn: 879.0000 - fn: 6.0000 - accuracy: 0.6267 - precision: 0.0992 - recall: 0.9104 - auc: 0.7923 - f1: 0.9092 - val_loss: 0.1056 - val_tp: 15.0000 - val_fp: 182.0000 - val_tn: 301.0000 - val_fn: 2.0000 - val_accuracy: 0.6320 - val_precision: 0.0761 - val_recall: 0.8824 - val_auc: 0.7478 - val_f1: 0.4869Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.5835 - tp: 70.0000 - fp: 609.0000 - tn: 814.0000 - fn: 7.0000 - accuracy: 0.5893 - precision: 0.1031 - recall: 0.9091 - auc: 0.7900 - f1: 0.9362 - val_loss: 0.1127 - val_tp: 17.0000 - val_fp: 256.0000 - val_tn: 227.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4880 - val_precision: 0.0623 - val_recall: 1.0000 - val_auc: 0.7549 - val_f1: 0.4765\n",
      "Validation fraction incorrect: 0.53\n",
      "\n",
      "learning rate: 1.1e-05\n",
      "past history: 7\n",
      "LSTM units: 357\n",
      "hidden layers: 8\n",
      "hidden units: 305\n",
      "hidden l2 lambda: 6.0e-02\n",
      "class 0 weight: 0.6859693229517501\n",
      "class 1 weight: 19\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 357)                579768    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 305)                109190    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 305)                93330     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 305)                93330     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 305)                93330     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 305)                93330     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 305)                93330     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 305)                93330     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (100, 305)                93330     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (100, 1)                  306       \n",
      "=================================================================\n",
      "Total params: 1,342,574\n",
      "Trainable params: 1,342,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 24s - loss: 149.0326 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1434.0000 - fn: 66.0000 - accuracy: 0.9560 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5527 - f1: 0.0000e+00 - val_loss: 32.2418 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5023 - val_f1: 0.0000e+00Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 148.6774 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1413.0000 - fn: 87.0000 - accuracy: 0.9420 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5373 - f1: 0.0000e+00 - val_loss: 32.0757 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5114 - val_f1: 0.0000e+00Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 147.6582 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1425.0000 - fn: 75.0000 - accuracy: 0.9500 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5042 - f1: 0.0000e+00 - val_loss: 31.9103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5767 - val_f1: 0.0000e+00Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 146.6970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1435.0000 - fn: 65.0000 - accuracy: 0.9567 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5297 - f1: 0.0000e+00 - val_loss: 31.7462 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6080 - val_f1: 0.0000e+00Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 146.1889 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1421.0000 - fn: 79.0000 - accuracy: 0.9473 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5445 - f1: 0.0000e+00 - val_loss: 31.5827 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5631 - val_f1: 0.0000e+00Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 145.2272 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1432.0000 - fn: 68.0000 - accuracy: 0.9547 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5445 - f1: 0.0000e+00 - val_loss: 31.4200 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6585 - val_f1: 0.0000e+00Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 7s - loss: 144.5027 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1430.0000 - fn: 70.0000 - accuracy: 0.9533 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6358 - f1: 0.0000e+00 - val_loss: 31.2585 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6170 - val_f1: 0.0000e+00Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 143.8469 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1424.0000 - fn: 76.0000 - accuracy: 0.9493 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5658 - f1: 0.0000e+00 - val_loss: 31.0975 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6222 - val_f1: 0.0000e+00Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 142.9197 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1435.0000 - fn: 65.0000 - accuracy: 0.9567 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6246 - f1: 0.0000e+00 - val_loss: 30.9375 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6416 - val_f1: 0.0000e+00Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 142.2221 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1432.0000 - fn: 68.0000 - accuracy: 0.9547 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5922 - f1: 0.0000e+00 - val_loss: 30.7782 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6449 - val_f1: 0.0000e+00Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 141.4932 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1431.0000 - fn: 69.0000 - accuracy: 0.9540 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6292 - f1: 0.0000e+00 - val_loss: 30.6200 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6776 - val_f1: 0.0000e+00Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 140.8342 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1425.0000 - fn: 75.0000 - accuracy: 0.9500 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6108 - f1: 0.0000e+00 - val_loss: 30.4625 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7215 - val_f1: 0.0000e+00Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 140.1813 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1418.0000 - fn: 82.0000 - accuracy: 0.9453 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5728 - f1: 0.0000e+00 - val_loss: 30.3062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6569 - val_f1: 0.0000e+00Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 139.3330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1427.0000 - fn: 73.0000 - accuracy: 0.9513 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5579 - f1: 0.0000e+00 - val_loss: 30.1514 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7324 - val_f1: 0.0000e+00Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 6s - loss: 138.6771 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1420.0000 - fn: 80.0000 - accuracy: 0.9467 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6666 - f1: 0.0000e+00 - val_loss: 29.9978 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6915 - val_f1: 0.0000e+00\n",
      "Validation fraction incorrect: 1.0\n",
      "\n",
      "learning rate: 1.4e-04\n",
      "past history: 22\n",
      "LSTM units: 5\n",
      "hidden layers: 5\n",
      "hidden units: 500\n",
      "hidden l2 lambda: 1.0e-04\n",
      "class 0 weight: 1.0\n",
      "class 1 weight: 13\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 5)                  1080      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 500)                3000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 1)                  501       \n",
      "=================================================================\n",
      "Total params: 1,006,581\n",
      "Trainable params: 1,006,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 19s - loss: 1.2624 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1433.0000 - fn: 67.0000 - accuracy: 0.9553 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5339 - f1: 0.0000e+00 - val_loss: 0.2319 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5596 - val_f1: 0.0000e+00Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.2750 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1425.0000 - fn: 75.0000 - accuracy: 0.9500 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4827 - f1: 0.0000e+00 - val_loss: 0.2358 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5831 - val_f1: 0.0000e+00Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.2291 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1427.0000 - fn: 73.0000 - accuracy: 0.9513 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5701 - f1: 0.0000e+00 - val_loss: 0.2268 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6908 - val_f1: 0.0000e+00Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.1934 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1426.0000 - fn: 74.0000 - accuracy: 0.9507 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6317 - f1: 0.0000e+00 - val_loss: 0.2224 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 483.0000 - val_fn: 17.0000 - val_accuracy: 0.9660 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6846 - val_f1: 0.0000e+00Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.2151 - tp: 25.0000 - fp: 239.0000 - tn: 1175.0000 - fn: 61.0000 - accuracy: 0.8000 - precision: 0.0947 - recall: 0.2907 - auc: 0.6896 - f1: 0.3447 - val_loss: 0.2243 - val_tp: 13.0000 - val_fp: 247.0000 - val_tn: 236.0000 - val_fn: 4.0000 - val_accuracy: 0.4980 - val_precision: 0.0500 - val_recall: 0.7647 - val_auc: 0.7165 - val_f1: 0.3730Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.0435 - tp: 40.0000 - fp: 413.0000 - tn: 1019.0000 - fn: 28.0000 - accuracy: 0.7060 - precision: 0.0883 - recall: 0.5882 - auc: 0.7154 - f1: 0.6524 - val_loss: 0.2068 - val_tp: 13.0000 - val_fp: 163.0000 - val_tn: 320.0000 - val_fn: 4.0000 - val_accuracy: 0.6660 - val_precision: 0.0739 - val_recall: 0.7647 - val_auc: 0.7379 - val_f1: 0.4276Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.1020 - tp: 49.0000 - fp: 490.0000 - tn: 933.0000 - fn: 28.0000 - accuracy: 0.6547 - precision: 0.0909 - recall: 0.6364 - auc: 0.7106 - f1: 0.7258 - val_loss: 0.1985 - val_tp: 8.0000 - val_fp: 82.0000 - val_tn: 401.0000 - val_fn: 9.0000 - val_accuracy: 0.8180 - val_precision: 0.0889 - val_recall: 0.4706 - val_auc: 0.7479 - val_f1: 0.3651Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9658 - tp: 42.0000 - fp: 329.0000 - tn: 1100.0000 - fn: 29.0000 - accuracy: 0.7613 - precision: 0.1132 - recall: 0.5915 - auc: 0.7797 - f1: 0.7033 - val_loss: 0.2031 - val_tp: 13.0000 - val_fp: 201.0000 - val_tn: 282.0000 - val_fn: 4.0000 - val_accuracy: 0.5900 - val_precision: 0.0607 - val_recall: 0.7647 - val_auc: 0.7562 - val_f1: 0.3862Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9701 - tp: 45.0000 - fp: 549.0000 - tn: 889.0000 - fn: 17.0000 - accuracy: 0.6227 - precision: 0.0758 - recall: 0.7258 - auc: 0.7408 - f1: 0.7050 - val_loss: 0.1922 - val_tp: 11.0000 - val_fp: 124.0000 - val_tn: 359.0000 - val_fn: 6.0000 - val_accuracy: 0.7400 - val_precision: 0.0815 - val_recall: 0.6471 - val_auc: 0.7730 - val_f1: 0.4080Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9554 - tp: 33.0000 - fp: 341.0000 - tn: 1093.0000 - fn: 33.0000 - accuracy: 0.7507 - precision: 0.0882 - recall: 0.5000 - auc: 0.7489 - f1: 0.6098 - val_loss: 0.2024 - val_tp: 15.0000 - val_fp: 244.0000 - val_tn: 239.0000 - val_fn: 2.0000 - val_accuracy: 0.5080 - val_precision: 0.0579 - val_recall: 0.8824 - val_auc: 0.7706 - val_f1: 0.4364Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.0378 - tp: 77.0000 - fp: 609.0000 - tn: 807.0000 - fn: 7.0000 - accuracy: 0.5893 - precision: 0.1122 - recall: 0.9167 - auc: 0.7520 - f1: 0.9831 - val_loss: 0.1912 - val_tp: 13.0000 - val_fp: 188.0000 - val_tn: 295.0000 - val_fn: 4.0000 - val_accuracy: 0.6160 - val_precision: 0.0647 - val_recall: 0.7647 - val_auc: 0.7764 - val_f1: 0.3921Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9550 - tp: 51.0000 - fp: 494.0000 - tn: 936.0000 - fn: 19.0000 - accuracy: 0.6580 - precision: 0.0936 - recall: 0.7286 - auc: 0.7663 - f1: 0.7970 - val_loss: 0.1878 - val_tp: 13.0000 - val_fp: 176.0000 - val_tn: 307.0000 - val_fn: 4.0000 - val_accuracy: 0.6400 - val_precision: 0.0688 - val_recall: 0.7647 - val_auc: 0.7850 - val_f1: 0.3991Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9494 - tp: 58.0000 - fp: 478.0000 - tn: 950.0000 - fn: 14.0000 - accuracy: 0.6720 - precision: 0.1082 - recall: 0.8056 - auc: 0.7796 - f1: 0.8606 - val_loss: 0.1859 - val_tp: 13.0000 - val_fp: 179.0000 - val_tn: 304.0000 - val_fn: 4.0000 - val_accuracy: 0.6340 - val_precision: 0.0677 - val_recall: 0.7647 - val_auc: 0.7774 - val_f1: 0.3950Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.9729 - tp: 69.0000 - fp: 544.0000 - tn: 875.0000 - fn: 12.0000 - accuracy: 0.6293 - precision: 0.1126 - recall: 0.8519 - auc: 0.7790 - f1: 0.9353 - val_loss: 0.1792 - val_tp: 13.0000 - val_fp: 159.0000 - val_tn: 324.0000 - val_fn: 4.0000 - val_accuracy: 0.6740 - val_precision: 0.0756 - val_recall: 0.7647 - val_auc: 0.7987 - val_f1: 0.4155Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 0.8806 - tp: 47.0000 - fp: 377.0000 - tn: 1056.0000 - fn: 20.0000 - accuracy: 0.7353 - precision: 0.1108 - recall: 0.7015 - auc: 0.7912 - f1: 0.8190 - val_loss: 0.1860 - val_tp: 14.0000 - val_fp: 200.0000 - val_tn: 283.0000 - val_fn: 3.0000 - val_accuracy: 0.5940 - val_precision: 0.0654 - val_recall: 0.8235 - val_auc: 0.8012 - val_f1: 0.4057\n",
      "Validation fraction incorrect: 0.59\n",
      "\n",
      "learning rate: 2.5e-03\n",
      "past history: 30\n",
      "LSTM units: 5\n",
      "hidden layers: 10\n",
      "hidden units: 500\n",
      "hidden l2 lambda: 1.0e-01\n",
      "class 0 weight: 0.9360990253698379\n",
      "class 1 weight: 10\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 5)                  1080      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 500)                3000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (100, 500)                250500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (100, 1)                  501       \n",
      "=================================================================\n",
      "Total params: 2,259,081\n",
      "Trainable params: 2,259,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 24s - loss: 235.6098 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1435.0000 - fn: 65.0000 - accuracy: 0.9567 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5014 - f1: 0.0000e+00 - val_loss: 16.2115 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 30.6972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1413.0000 - fn: 87.0000 - accuracy: 0.9420 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5037 - f1: 0.0000e+00 - val_loss: 1.3676 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 3.9889 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1428.0000 - fn: 72.0000 - accuracy: 0.9520 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5608 - f1: 0.0000e+00 - val_loss: 0.5951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 2.3043 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1427.0000 - fn: 73.0000 - accuracy: 0.9513 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4933 - f1: 0.0000e+00 - val_loss: 0.2961 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 1.1480 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1434.0000 - fn: 66.0000 - accuracy: 0.9560 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4403 - f1: 0.0000e+00 - val_loss: 0.1623 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 0.9558 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1425.0000 - fn: 75.0000 - accuracy: 0.9500 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5201 - f1: 0.0000e+00 - val_loss: 0.1566 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 0.8993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1429.0000 - fn: 71.0000 - accuracy: 0.9527 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4936 - f1: 0.0000e+00 - val_loss: 0.1491 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 0.9303 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1423.0000 - fn: 77.0000 - accuracy: 0.9487 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4466 - f1: 0.0000e+00 - val_loss: 0.1527 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 0.7853 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1443.0000 - fn: 57.0000 - accuracy: 0.9620 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5274 - f1: 0.0000e+00 - val_loss: 0.1447 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 0.8668 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1432.0000 - fn: 68.0000 - accuracy: 0.9547 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4194 - f1: 0.0000e+00 - val_loss: 0.1455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 3s - loss: 0.9196 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1424.0000 - fn: 76.0000 - accuracy: 0.9493 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4663 - f1: 0.0000e+00Restoring model weights from the end of the best epoch.\n",
      "1500/6300 [======>.......................] - ETA: 4s - loss: 0.9197 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1424.0000 - fn: 76.0000 - accuracy: 0.9493 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4663 - f1: 0.0000e+00 - val_loss: 0.1482 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 486.0000 - val_fn: 14.0000 - val_accuracy: 0.9720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_f1: 0.0000e+00Epoch 00011: early stopping\n",
      "\n",
      "Validation fraction incorrect: 1.0\n",
      "\n",
      "learning rate: 1.4e-03\n",
      "past history: 30\n",
      "LSTM units: 19\n",
      "hidden layers: 9\n",
      "hidden units: 193\n",
      "hidden l2 lambda: 5.3e-03\n",
      "class 0 weight: 0.6642638407270638\n",
      "class 1 weight: 20\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 19)                 5168      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 193)                3860      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 193)                37442     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 193)                37442     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 193)                37442     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 193)                37442     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 193)                37442     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 193)                37442     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (100, 193)                37442     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (100, 193)                37442     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (100, 1)                  194       \n",
      "=================================================================\n",
      "Total params: 308,758\n",
      "Trainable params: 308,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 20s - loss: 8.0101 - tp: 36.0000 - fp: 764.0000 - tn: 671.0000 - fn: 29.0000 - accuracy: 0.4713 - precision: 0.0450 - recall: 0.5538 - auc: 0.5097 - f1: 0.3107 - val_loss: 1.3405 - val_tp: 14.0000 - val_fp: 486.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0280 - val_precision: 0.0280 - val_recall: 1.0000 - val_auc: 0.6359 - val_f1: 0.3484Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 5.4141 - tp: 87.0000 - fp: 1413.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.0580 - precision: 0.0580 - recall: 1.0000 - auc: 0.5449 - f1: 0.7065 - val_loss: 0.9386 - val_tp: 14.0000 - val_fp: 486.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0280 - val_precision: 0.0280 - val_recall: 1.0000 - val_auc: 0.7540 - val_f1: 0.3484Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 2s - loss: 3.6466 - tp: 72.0000 - fp: 1395.0000 - tn: 33.0000 - fn: 0.0000e+00 - accuracy: 0.0700 - precision: 0.0491 - recall: 1.0000 - auc: 0.6092 - f1: 0.6364 - val_loss: 0.6002 - val_tp: 14.0000 - val_fp: 264.0000 - val_tn: 222.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4720 - val_precision: 0.0504 - val_recall: 1.0000 - val_auc: 0.7693 - val_f1: 0.4043Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 2.5905 - tp: 64.0000 - fp: 820.0000 - tn: 607.0000 - fn: 9.0000 - accuracy: 0.4473 - precision: 0.0724 - recall: 0.8767 - auc: 0.6965 - f1: 0.7442 - val_loss: 0.4300 - val_tp: 14.0000 - val_fp: 246.0000 - val_tn: 240.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5080 - val_precision: 0.0538 - val_recall: 1.0000 - val_auc: 0.7770 - val_f1: 0.4093Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.8949 - tp: 51.0000 - fp: 505.0000 - tn: 929.0000 - fn: 15.0000 - accuracy: 0.6533 - precision: 0.0917 - recall: 0.7727 - auc: 0.7791 - f1: 0.7478 - val_loss: 0.3552 - val_tp: 14.0000 - val_fp: 253.0000 - val_tn: 233.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4940 - val_precision: 0.0524 - val_recall: 1.0000 - val_auc: 0.7888 - val_f1: 0.4043Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.5591 - tp: 68.0000 - fp: 610.0000 - tn: 815.0000 - fn: 7.0000 - accuracy: 0.5887 - precision: 0.1003 - recall: 0.9067 - auc: 0.7693 - f1: 0.8919 - val_loss: 0.2776 - val_tp: 14.0000 - val_fp: 227.0000 - val_tn: 259.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5460 - val_precision: 0.0581 - val_recall: 1.0000 - val_auc: 0.7902 - val_f1: 0.4145Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.3253 - tp: 67.0000 - fp: 681.0000 - tn: 748.0000 - fn: 4.0000 - accuracy: 0.5433 - precision: 0.0896 - recall: 0.9437 - auc: 0.7876 - f1: 0.8965 - val_loss: 0.2483 - val_tp: 14.0000 - val_fp: 264.0000 - val_tn: 222.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4720 - val_precision: 0.0504 - val_recall: 1.0000 - val_auc: 0.7880 - val_f1: 0.3976Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.2994 - tp: 72.0000 - fp: 636.0000 - tn: 787.0000 - fn: 5.0000 - accuracy: 0.5727 - precision: 0.1017 - recall: 0.9351 - auc: 0.7561 - f1: 0.9295 - val_loss: 0.2289 - val_tp: 14.0000 - val_fp: 214.0000 - val_tn: 272.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5720 - val_precision: 0.0614 - val_recall: 1.0000 - val_auc: 0.7892 - val_f1: 0.4276Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.1329 - tp: 49.0000 - fp: 551.0000 - tn: 892.0000 - fn: 8.0000 - accuracy: 0.6273 - precision: 0.0817 - recall: 0.8596 - auc: 0.7573 - f1: 0.8056 - val_loss: 0.2116 - val_tp: 14.0000 - val_fp: 215.0000 - val_tn: 271.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5700 - val_precision: 0.0611 - val_recall: 1.0000 - val_auc: 0.7844 - val_f1: 0.4257Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.1168 - tp: 63.0000 - fp: 583.0000 - tn: 849.0000 - fn: 5.0000 - accuracy: 0.6080 - precision: 0.0975 - recall: 0.9265 - auc: 0.7695 - f1: 0.9064 - val_loss: 0.1933 - val_tp: 14.0000 - val_fp: 197.0000 - val_tn: 289.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6060 - val_precision: 0.0664 - val_recall: 1.0000 - val_auc: 0.7825 - val_f1: 0.4401Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.0937 - tp: 69.0000 - fp: 593.0000 - tn: 831.0000 - fn: 7.0000 - accuracy: 0.6000 - precision: 0.1042 - recall: 0.9079 - auc: 0.7868 - f1: 0.9212 - val_loss: 0.2077 - val_tp: 14.0000 - val_fp: 239.0000 - val_tn: 247.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5220 - val_precision: 0.0553 - val_recall: 1.0000 - val_auc: 0.7739 - val_f1: 0.4083Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.1336 - tp: 80.0000 - fp: 687.0000 - tn: 727.0000 - fn: 6.0000 - accuracy: 0.5380 - precision: 0.1043 - recall: 0.9302 - auc: 0.7784 - f1: 0.9504 - val_loss: 0.1867 - val_tp: 13.0000 - val_fp: 198.0000 - val_tn: 288.0000 - val_fn: 1.0000 - val_accuracy: 0.6020 - val_precision: 0.0616 - val_recall: 0.9286 - val_auc: 0.7750 - val_f1: 0.4184Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.0695 - tp: 74.0000 - fp: 531.0000 - tn: 890.0000 - fn: 5.0000 - accuracy: 0.6427 - precision: 0.1223 - recall: 0.9367 - auc: 0.7806 - f1: 0.9933 - val_loss: 0.1788 - val_tp: 14.0000 - val_fp: 204.0000 - val_tn: 282.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5920 - val_precision: 0.0642 - val_recall: 1.0000 - val_auc: 0.7805 - val_f1: 0.4306Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.0528 - tp: 63.0000 - fp: 619.0000 - tn: 812.0000 - fn: 6.0000 - accuracy: 0.5833 - precision: 0.0924 - recall: 0.9130 - auc: 0.7586 - f1: 0.8929 - val_loss: 0.1779 - val_tp: 12.0000 - val_fp: 192.0000 - val_tn: 294.0000 - val_fn: 2.0000 - val_accuracy: 0.6120 - val_precision: 0.0588 - val_recall: 0.8571 - val_auc: 0.7748 - val_f1: 0.4059Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 2s - loss: 1.1551 - tp: 70.0000 - fp: 636.0000 - tn: 785.0000 - fn: 9.0000 - accuracy: 0.5700 - precision: 0.0992 - recall: 0.8861 - auc: 0.7358 - f1: 0.9151 - val_loss: 0.1796 - val_tp: 14.0000 - val_fp: 211.0000 - val_tn: 275.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5780 - val_precision: 0.0622 - val_recall: 1.0000 - val_auc: 0.7817 - val_f1: 0.4237\n",
      "Validation fraction incorrect: 0.43\n",
      "\n",
      "learning rate: 1.4e-03\n",
      "past history: 30\n",
      "LSTM units: 187\n",
      "hidden layers: 8\n",
      "hidden units: 84\n",
      "hidden l2 lambda: 5.0e-03\n",
      "class 0 weight: 0.25068914944815024\n",
      "class 1 weight: 10\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 187)                176528    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 84)                 15792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 84)                 7140      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 84)                 7140      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 84)                 7140      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (100, 84)                 7140      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (100, 84)                 7140      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (100, 84)                 7140      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (100, 84)                 7140      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (100, 1)                  85        \n",
      "=================================================================\n",
      "Total params: 242,385\n",
      "Trainable params: 242,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 27s - loss: 3.6682 - tp: 9.0000 - fp: 191.0000 - tn: 1244.0000 - fn: 56.0000 - accuracy: 0.8353 - precision: 0.0450 - recall: 0.1385 - auc: 0.5219 - f1: 0.0808 - val_loss: 0.6512 - val_tp: 14.0000 - val_fp: 486.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0280 - val_precision: 0.0280 - val_recall: 1.0000 - val_auc: 0.7474 - val_f1: 0.3484Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 10s - loss: 2.7189 - tp: 87.0000 - fp: 1272.0000 - tn: 141.0000 - fn: 0.0000e+00 - accuracy: 0.1520 - precision: 0.0640 - recall: 1.0000 - auc: 0.5711 - f1: 0.7577 - val_loss: 0.4861 - val_tp: 14.0000 - val_fp: 484.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0320 - val_precision: 0.0281 - val_recall: 1.0000 - val_auc: 0.7606 - val_f1: 0.3496Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 9s - loss: 1.9877 - tp: 70.0000 - fp: 1119.0000 - tn: 309.0000 - fn: 2.0000 - accuracy: 0.2527 - precision: 0.0589 - recall: 0.9722 - auc: 0.7808 - f1: 0.7202 - val_loss: 0.3590 - val_tp: 11.0000 - val_fp: 162.0000 - val_tn: 324.0000 - val_fn: 3.0000 - val_accuracy: 0.6700 - val_precision: 0.0636 - val_recall: 0.7857 - val_auc: 0.7628 - val_f1: 0.3742Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 8s - loss: 1.5248 - tp: 67.0000 - fp: 665.0000 - tn: 762.0000 - fn: 6.0000 - accuracy: 0.5527 - precision: 0.0915 - recall: 0.9178 - auc: 0.7817 - f1: 0.8398 - val_loss: 0.2759 - val_tp: 14.0000 - val_fp: 262.0000 - val_tn: 224.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4760 - val_precision: 0.0507 - val_recall: 1.0000 - val_auc: 0.7789 - val_f1: 0.3988Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 7s - loss: 1.1833 - tp: 62.0000 - fp: 623.0000 - tn: 811.0000 - fn: 4.0000 - accuracy: 0.5820 - precision: 0.0905 - recall: 0.9394 - auc: 0.8033 - f1: 0.8812 - val_loss: 0.2233 - val_tp: 13.0000 - val_fp: 218.0000 - val_tn: 268.0000 - val_fn: 1.0000 - val_accuracy: 0.5620 - val_precision: 0.0563 - val_recall: 0.9286 - val_auc: 0.7851 - val_f1: 0.3907Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 8s - loss: 0.9710 - tp: 69.0000 - fp: 575.0000 - tn: 850.0000 - fn: 6.0000 - accuracy: 0.6127 - precision: 0.1071 - recall: 0.9200 - auc: 0.7836 - f1: 0.9347 - val_loss: 0.1770 - val_tp: 13.0000 - val_fp: 197.0000 - val_tn: 289.0000 - val_fn: 1.0000 - val_accuracy: 0.6040 - val_precision: 0.0619 - val_recall: 0.9286 - val_auc: 0.7735 - val_f1: 0.4179Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 10s - loss: 0.8278 - tp: 66.0000 - fp: 694.0000 - tn: 735.0000 - fn: 5.0000 - accuracy: 0.5340 - precision: 0.0868 - recall: 0.9296 - auc: 0.7707 - f1: 0.8746 - val_loss: 0.1501 - val_tp: 14.0000 - val_fp: 253.0000 - val_tn: 233.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4940 - val_precision: 0.0524 - val_recall: 1.0000 - val_auc: 0.7819 - val_f1: 0.4034Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 8s - loss: 0.7312 - tp: 74.0000 - fp: 796.0000 - tn: 627.0000 - fn: 3.0000 - accuracy: 0.4673 - precision: 0.0851 - recall: 0.9610 - auc: 0.7770 - f1: 0.8588 - val_loss: 0.1286 - val_tp: 14.0000 - val_fp: 203.0000 - val_tn: 283.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5940 - val_precision: 0.0645 - val_recall: 1.0000 - val_auc: 0.7765 - val_f1: 0.4316Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 10s - loss: 0.6134 - tp: 52.0000 - fp: 649.0000 - tn: 794.0000 - fn: 5.0000 - accuracy: 0.5640 - precision: 0.0742 - recall: 0.9123 - auc: 0.7861 - f1: 0.7886 - val_loss: 0.1152 - val_tp: 12.0000 - val_fp: 180.0000 - val_tn: 306.0000 - val_fn: 2.0000 - val_accuracy: 0.6360 - val_precision: 0.0625 - val_recall: 0.8571 - val_auc: 0.7800 - val_f1: 0.4262Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 9s - loss: 0.5843 - tp: 62.0000 - fp: 623.0000 - tn: 809.0000 - fn: 6.0000 - accuracy: 0.5807 - precision: 0.0905 - recall: 0.9118 - auc: 0.7719 - f1: 0.8737 - val_loss: 0.1051 - val_tp: 14.0000 - val_fp: 214.0000 - val_tn: 272.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5720 - val_precision: 0.0614 - val_recall: 1.0000 - val_auc: 0.7895 - val_f1: 0.4164Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 10s - loss: 0.5292 - tp: 74.0000 - fp: 647.0000 - tn: 777.0000 - fn: 2.0000 - accuracy: 0.5673 - precision: 0.1026 - recall: 0.9737 - auc: 0.8136 - f1: 0.9583 - val_loss: 0.1021 - val_tp: 14.0000 - val_fp: 219.0000 - val_tn: 267.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5620 - val_precision: 0.0601 - val_recall: 1.0000 - val_auc: 0.7839 - val_f1: 0.4118Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 10s - loss: 0.5563 - tp: 80.0000 - fp: 655.0000 - tn: 759.0000 - fn: 6.0000 - accuracy: 0.5593 - precision: 0.1088 - recall: 0.9302 - auc: 0.7732 - f1: 0.9697 - val_loss: 0.0941 - val_tp: 13.0000 - val_fp: 207.0000 - val_tn: 279.0000 - val_fn: 1.0000 - val_accuracy: 0.5840 - val_precision: 0.0591 - val_recall: 0.9286 - val_auc: 0.7791 - val_f1: 0.4061Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 9s - loss: 0.4889 - tp: 78.0000 - fp: 588.0000 - tn: 833.0000 - fn: 1.0000 - accuracy: 0.6073 - precision: 0.1171 - recall: 0.9873 - auc: 0.7884 - f1: 1.0140 - val_loss: 0.0896 - val_tp: 14.0000 - val_fp: 210.0000 - val_tn: 276.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5800 - val_precision: 0.0625 - val_recall: 1.0000 - val_auc: 0.7780 - val_f1: 0.4218Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 9s - loss: 0.4690 - tp: 63.0000 - fp: 564.0000 - tn: 867.0000 - fn: 6.0000 - accuracy: 0.6200 - precision: 0.1005 - recall: 0.9130 - auc: 0.8041 - f1: 0.9281 - val_loss: 0.0884 - val_tp: 13.0000 - val_fp: 186.0000 - val_tn: 300.0000 - val_fn: 1.0000 - val_accuracy: 0.6260 - val_precision: 0.0653 - val_recall: 0.9286 - val_auc: 0.7746 - val_f1: 0.4371Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 9s - loss: 0.5227 - tp: 71.0000 - fp: 633.0000 - tn: 788.0000 - fn: 8.0000 - accuracy: 0.5727 - precision: 0.1009 - recall: 0.8987 - auc: 0.7500 - f1: 0.9233 - val_loss: 0.0860 - val_tp: 14.0000 - val_fp: 228.0000 - val_tn: 258.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5440 - val_precision: 0.0579 - val_recall: 1.0000 - val_auc: 0.7842 - val_f1: 0.4083\n",
      "Validation fraction incorrect: 0.47\n",
      "\n",
      "learning rate: 2.1e-03\n",
      "past history: 30\n",
      "LSTM units: 214\n",
      "hidden layers: 1\n",
      "hidden units: 124\n",
      "hidden l2 lambda: 3.5e-02\n",
      "class 0 weight: 0.438445332342449\n",
      "class 1 weight: 15\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 214)                225128    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 124)                26660     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 1)                  125       \n",
      "=================================================================\n",
      "Total params: 251,913\n",
      "Trainable params: 251,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 28s - loss: 4.9408 - tp: 52.0000 - fp: 920.0000 - tn: 515.0000 - fn: 13.0000 - accuracy: 0.3780 - precision: 0.0535 - recall: 0.8000 - auc: 0.5916 - f1: 0.5985 - val_loss: 0.7698 - val_tp: 14.0000 - val_fp: 363.0000 - val_tn: 123.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2740 - val_precision: 0.0371 - val_recall: 1.0000 - val_auc: 0.7571 - val_f1: 0.3721Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 2.8805 - tp: 86.0000 - fp: 830.0000 - tn: 583.0000 - fn: 1.0000 - accuracy: 0.4460 - precision: 0.0939 - recall: 0.9885 - auc: 0.7816 - f1: 0.9338 - val_loss: 0.4545 - val_tp: 14.0000 - val_fp: 278.0000 - val_tn: 208.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4440 - val_precision: 0.0479 - val_recall: 1.0000 - val_auc: 0.7626 - val_f1: 0.3959Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 1.7411 - tp: 66.0000 - fp: 671.0000 - tn: 757.0000 - fn: 6.0000 - accuracy: 0.5487 - precision: 0.0896 - recall: 0.9167 - auc: 0.7861 - f1: 0.8830 - val_loss: 0.2682 - val_tp: 12.0000 - val_fp: 177.0000 - val_tn: 309.0000 - val_fn: 2.0000 - val_accuracy: 0.6420 - val_precision: 0.0635 - val_recall: 0.8571 - val_auc: 0.7798 - val_f1: 0.4307Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 1.2627 - tp: 60.0000 - fp: 627.0000 - tn: 800.0000 - fn: 13.0000 - accuracy: 0.5733 - precision: 0.0873 - recall: 0.8219 - auc: 0.7531 - f1: 0.7847 - val_loss: 0.2361 - val_tp: 14.0000 - val_fp: 336.0000 - val_tn: 150.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3280 - val_precision: 0.0400 - val_recall: 1.0000 - val_auc: 0.7770 - val_f1: 0.3785Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.9989 - tp: 62.0000 - fp: 740.0000 - tn: 694.0000 - fn: 4.0000 - accuracy: 0.5040 - precision: 0.0773 - recall: 0.9394 - auc: 0.7195 - f1: 0.8243 - val_loss: 0.1638 - val_tp: 13.0000 - val_fp: 219.0000 - val_tn: 267.0000 - val_fn: 1.0000 - val_accuracy: 0.5600 - val_precision: 0.0560 - val_recall: 0.9286 - val_auc: 0.7695 - val_f1: 0.3916Epoch 6/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.8306 - tp: 70.0000 - fp: 593.0000 - tn: 832.0000 - fn: 5.0000 - accuracy: 0.6013 - precision: 0.1056 - recall: 0.9333 - auc: 0.7878 - f1: 0.9364 - val_loss: 0.1436 - val_tp: 12.0000 - val_fp: 179.0000 - val_tn: 307.0000 - val_fn: 2.0000 - val_accuracy: 0.6380 - val_precision: 0.0628 - val_recall: 0.8571 - val_auc: 0.7732 - val_f1: 0.4210Epoch 7/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.7348 - tp: 67.0000 - fp: 675.0000 - tn: 754.0000 - fn: 4.0000 - accuracy: 0.5473 - precision: 0.0903 - recall: 0.9437 - auc: 0.7719 - f1: 0.9009 - val_loss: 0.1272 - val_tp: 13.0000 - val_fp: 213.0000 - val_tn: 273.0000 - val_fn: 1.0000 - val_accuracy: 0.5720 - val_precision: 0.0575 - val_recall: 0.9286 - val_auc: 0.7710 - val_f1: 0.4013Epoch 8/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.7153 - tp: 72.0000 - fp: 682.0000 - tn: 741.0000 - fn: 5.0000 - accuracy: 0.5420 - precision: 0.0955 - recall: 0.9351 - auc: 0.7829 - f1: 0.8929 - val_loss: 0.1213 - val_tp: 14.0000 - val_fp: 209.0000 - val_tn: 277.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5820 - val_precision: 0.0628 - val_recall: 1.0000 - val_auc: 0.7659 - val_f1: 0.4256Epoch 9/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.5783 - tp: 52.0000 - fp: 570.0000 - tn: 873.0000 - fn: 5.0000 - accuracy: 0.6167 - precision: 0.0836 - recall: 0.9123 - auc: 0.8143 - f1: 0.8317 - val_loss: 0.1085 - val_tp: 12.0000 - val_fp: 199.0000 - val_tn: 287.0000 - val_fn: 2.0000 - val_accuracy: 0.5980 - val_precision: 0.0569 - val_recall: 0.8571 - val_auc: 0.7817 - val_f1: 0.3968Epoch 10/15\n",
      "1500/6300 [======>.......................] - ETA: 10s - loss: 0.5921 - tp: 63.0000 - fp: 623.0000 - tn: 809.0000 - fn: 5.0000 - accuracy: 0.5813 - precision: 0.0918 - recall: 0.9265 - auc: 0.7878 - f1: 0.8836 - val_loss: 0.1068 - val_tp: 14.0000 - val_fp: 218.0000 - val_tn: 268.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5640 - val_precision: 0.0603 - val_recall: 1.0000 - val_auc: 0.7812 - val_f1: 0.4144Epoch 11/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.5756 - tp: 74.0000 - fp: 631.0000 - tn: 793.0000 - fn: 2.0000 - accuracy: 0.5780 - precision: 0.1050 - recall: 0.9737 - auc: 0.8178 - f1: 0.9687 - val_loss: 0.1059 - val_tp: 14.0000 - val_fp: 211.0000 - val_tn: 275.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5780 - val_precision: 0.0622 - val_recall: 1.0000 - val_auc: 0.7760 - val_f1: 0.4208Epoch 12/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.6956 - tp: 80.0000 - fp: 698.0000 - tn: 716.0000 - fn: 6.0000 - accuracy: 0.5307 - precision: 0.1028 - recall: 0.9302 - auc: 0.7771 - f1: 0.9432 - val_loss: 0.1137 - val_tp: 14.0000 - val_fp: 240.0000 - val_tn: 246.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5200 - val_precision: 0.0551 - val_recall: 1.0000 - val_auc: 0.7792 - val_f1: 0.4085Epoch 13/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.5743 - tp: 77.0000 - fp: 585.0000 - tn: 836.0000 - fn: 2.0000 - accuracy: 0.6087 - precision: 0.1163 - recall: 0.9747 - auc: 0.8077 - f1: 0.9998 - val_loss: 0.1032 - val_tp: 13.0000 - val_fp: 208.0000 - val_tn: 278.0000 - val_fn: 1.0000 - val_accuracy: 0.5820 - val_precision: 0.0588 - val_recall: 0.9286 - val_auc: 0.7747 - val_f1: 0.4052Epoch 14/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.5783 - tp: 63.0000 - fp: 523.0000 - tn: 908.0000 - fn: 6.0000 - accuracy: 0.6473 - precision: 0.1075 - recall: 0.9130 - auc: 0.8031 - f1: 0.9557 - val_loss: 0.1016 - val_tp: 12.0000 - val_fp: 173.0000 - val_tn: 313.0000 - val_fn: 2.0000 - val_accuracy: 0.6500 - val_precision: 0.0649 - val_recall: 0.8571 - val_auc: 0.7786 - val_f1: 0.4343Epoch 15/15\n",
      "1500/6300 [======>.......................] - ETA: 11s - loss: 0.6624 - tp: 74.0000 - fp: 688.0000 - tn: 733.0000 - fn: 5.0000 - accuracy: 0.5380 - precision: 0.0971 - recall: 0.9367 - auc: 0.7455 - f1: 0.9250 - val_loss: 0.1003 - val_tp: 14.0000 - val_fp: 220.0000 - val_tn: 266.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5600 - val_precision: 0.0598 - val_recall: 1.0000 - val_auc: 0.7773 - val_f1: 0.4118\n",
      "Validation fraction incorrect: 0.45\n",
      "\n",
      "learning rate: 5.9e-04\n",
      "past history: 30\n",
      "LSTM units: 460\n",
      "hidden layers: 3\n",
      "hidden units: 349\n",
      "hidden l2 lambda: 4.7e-02\n",
      "class 0 weight: 0.8557537729747847\n",
      "class 1 weight: 20\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (100, 460)                936560    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (100, 349)                160889    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (100, 349)                122150    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (100, 349)                122150    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (100, 1)                  350       \n",
      "=================================================================\n",
      "Total params: 1,342,099\n",
      "Trainable params: 1,342,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Train on 6300 samples, validate on 2300 samples\n",
      "Epoch 1/15\n",
      "1500/6300 [======>.......................] - ETA: 44s - loss: 46.9095 - tp: 28.0000 - fp: 586.0000 - tn: 849.0000 - fn: 37.0000 - accuracy: 0.5847 - precision: 0.0456 - recall: 0.4308 - auc: 0.5390 - f1: 0.3112 - val_loss: 8.7259 - val_tp: 14.0000 - val_fp: 359.0000 - val_tn: 127.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.2820 - val_precision: 0.0375 - val_recall: 1.0000 - val_auc: 0.7483 - val_f1: 0.3711Epoch 2/15\n",
      "1500/6300 [======>.......................] - ETA: 25s - loss: 35.4064 - tp: 74.0000 - fp: 794.0000 - tn: 619.0000 - fn: 13.0000 - accuracy: 0.4620 - precision: 0.0853 - recall: 0.8506 - auc: 0.7410 - f1: 0.7885 - val_loss: 6.5196 - val_tp: 14.0000 - val_fp: 286.0000 - val_tn: 200.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4280 - val_precision: 0.0467 - val_recall: 1.0000 - val_auc: 0.7683 - val_f1: 0.3852Epoch 3/15\n",
      "1500/6300 [======>.......................] - ETA: 25s - loss: 26.2636 - tp: 63.0000 - fp: 602.0000 - tn: 826.0000 - fn: 9.0000 - accuracy: 0.5927 - precision: 0.0947 - recall: 0.8750 - auc: 0.7696 - f1: 0.8959 - val_loss: 4.8018 - val_tp: 7.0000 - val_fp: 101.0000 - val_tn: 385.0000 - val_fn: 7.0000 - val_accuracy: 0.7840 - val_precision: 0.0648 - val_recall: 0.5000 - val_auc: 0.7814 - val_f1: 0.2622Epoch 4/15\n",
      "1500/6300 [======>.......................] - ETA: 25s - loss: 19.5407 - tp: 57.0000 - fp: 559.0000 - tn: 868.0000 - fn: 16.0000 - accuracy: 0.6167 - precision: 0.0925 - recall: 0.7808 - auc: 0.7473 - f1: 0.7695 - val_loss: 3.5918 - val_tp: 14.0000 - val_fp: 322.0000 - val_tn: 164.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3560 - val_precision: 0.0417 - val_recall: 1.0000 - val_auc: 0.7715 - val_f1: 0.3741Epoch 5/15\n",
      "1500/6300 [======>.......................] - ETA: 25s - loss: 14.4747 - tp: 36.0000 - fp: 388.0000 - tn: 1046.0000 - fn: 30.0000 - accuracy: 0.7213 - precision: 0.0849 - recall: 0.5455 - auc: 0.7353 - f1: 0.5226 - val_loss: 2.6100 - val_tp: 13.0000 - val_fp: 192.0000 - val_tn: 294.0000 - val_fn: 1.0000 - val_accuracy: 0.6140 - val_precision: 0.0634 - val_recall: 0.9286 - val_auc: 0.7806 - val_f1: 0.4257Epoch 6/15\n",
      " 600/6300 [=>............................] - ETA: 27s - loss: 11.5361 - tp: 29.0000 - fp: 226.0000 - tn: 345.0000 - fn: 0.0000e+00 - accuracy: 0.6233 - precision: 0.1137 - recall: 1.0000 - auc: 0.8415 - f1: 1.0291"
     ]
    }
   ],
   "source": [
    "search_result = gp_minimize(\n",
    "    func=fitness,\n",
    "    dimensions=dimensions,\n",
    "    acq_func='EI', # Expected Improvement.\n",
    "    n_calls=40,\n",
    "    x0=default_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_names = [\n",
    "    'learning_rate',\n",
    "    'past_history',\n",
    "    'lstm_units',\n",
    "    'hidden_layers',\n",
    "    'hidden_units',\n",
    "    #'lstm_l2_lambda',\n",
    "    'hidden_l2_lambda',\n",
    "    'class_0_weight',\n",
    "    'class_1_weight'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_objective(result=search_result, dimension_names=dim_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try a longer training run with the winning hyperparameters** Some of these, we will manually tweak based on the above graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = search_result.space\n",
    "winning_hyperparams = space.point_to_dict(search_result.x)\n",
    "winning_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 3.4e-02\n",
    "# past_history = 27\n",
    "# lstm_units = 193\n",
    "# hidden_layers = 1\n",
    "# hidden_units = 87\n",
    "# #lstm_l2_lambda = 1.1e-03\n",
    "# hidden_l2_lambda = 3.6e-03\n",
    "# class_0_weight = 0.1\n",
    "# class_1_weight = 10\n",
    "\n",
    "# learning rate: 3.4e-03\n",
    "# past history: 27\n",
    "# LSTM units: 193\n",
    "# hidden layers: 1\n",
    "# hidden units: 87\n",
    "# hidden l2 lambda: 3.6e-03\n",
    "# class 0 weight: 0.1\n",
    "# class 1 weight: 10\n",
    "\n",
    "learning_rate = winning_hyperparams['learning_rate']\n",
    "past_history = winning_hyperparams['past_history']\n",
    "lstm_units = winning_hyperparams['lstm_units']\n",
    "hidden_layers = winning_hyperparams['hidden_layers']\n",
    "hidden_units = winning_hyperparams['hidden_units']\n",
    "#lstm_l2_lambda = winning_hyperparams['lstm_l2_lambda']\n",
    "hidden_l2_lambda = winning_hyperparams['hidden_l2_lambda']\n",
    "class_0_weight = winning_hyperparams['class_0_weight']\n",
    "class_1_weight = winning_hyperparams['class_1_weight']\n",
    "\n",
    "future_target = 1\n",
    "step = 1\n",
    "\n",
    "initial_bias = -1.4\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "    \n",
    "class_weight = {0: class_0_weight, 1: class_1_weight}\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 100\n",
    "STEPS_PER_EPOCH = (len(training_data) * 0.5) // BATCH_SIZE\n",
    "VALIDATION_STEPS = (len(validation_data) * 0.5) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = multivariate_data(\n",
    "    training_data, \n",
    "    training_data[:, 1], \n",
    "    0,\n",
    "    None,\n",
    "    past_history,\n",
    "    future_target, \n",
    "    step\n",
    ")\n",
    "\n",
    "start_index = (x_train.shape[0] - (x_train.shape[0] % BATCH_SIZE))\n",
    "end_index = x_train.shape[0]\n",
    "x_train = np.delete(x_train, range(start_index, end_index), axis=0)\n",
    "y_train = np.delete(y_train, range(start_index, end_index), axis=0)\n",
    "\n",
    "x_validation, y_validation = multivariate_data(\n",
    "    validation_data, \n",
    "    validation_data[:, 1], \n",
    "    0,\n",
    "    None,\n",
    "    past_history,\n",
    "    future_target, \n",
    "    step\n",
    ")\n",
    "\n",
    "start_index = (x_validation.shape[0] - (x_validation.shape[0] % BATCH_SIZE))\n",
    "end_index = x_validation.shape[0]\n",
    "x_validation = np.delete(x_validation, range(start_index, end_index), axis=0)\n",
    "y_validation = np.delete(y_validation, range(start_index, end_index), axis=0)\n",
    "\n",
    "input_dim = x_train.shape[-2:]\n",
    "\n",
    "input_shape = (BATCH_SIZE, input_dim[0], input_dim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(\n",
    "    lstm_units,\n",
    "    batch_input_shape=input_shape,\n",
    "#         bias_initializer=keras.initializers.VarianceScaling(\n",
    "#             scale=1.0,\n",
    "#             mode='fan_in', \n",
    "#             distribution='normal', \n",
    "#             seed=None\n",
    "#         ),\n",
    "#         kernel_regularizer=keras.regularizers.l2(lstm_l2_lambda),\n",
    "#         activation = 'relu',\n",
    "     stateful = True\n",
    "))\n",
    "\n",
    "for i in range(hidden_layers):\n",
    "    model.add(keras.layers.Dense(\n",
    "        hidden_units,\n",
    "        bias_initializer=keras.initializers.VarianceScaling(\n",
    "            scale=1.0,\n",
    "            mode='fan_in', \n",
    "            distribution='normal', \n",
    "            seed=None\n",
    "        ),\n",
    "        kernel_regularizer=keras.regularizers.l2(hidden_l2_lambda),\n",
    "        activation = 'relu'\n",
    "    ))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    1,\n",
    "    activation = 'softmax',\n",
    "    bias_initializer = output_bias)\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr = learning_rate), \n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data=(x_validation, y_validation),\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    class_weight=class_weight,\n",
    "    workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplots(2,2,figsize=(12,8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "\n",
    "plt.plot(\n",
    "    range(len(y_train)), \n",
    "    y_train,\n",
    "    color = \"darkred\",\n",
    "    label ='True ignitions'\n",
    ")\n",
    "plt.plot(\n",
    "    range(len(y_train)), \n",
    "    predictions,\n",
    "    color = \"darkgray\",\n",
    "    label ='predicted ignitions'\n",
    ")\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Ignition')\n",
    "plt.title('Predicted vs. actual ignition')\n",
    "plt.legend()\n",
    "plt.xlim(155,176)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "\n",
    "plt.plot(\n",
    "    range(len(y_train)), \n",
    "    y_train,\n",
    "    color = \"darkred\",\n",
    "    label ='True ignitions'\n",
    ")\n",
    "plt.plot(\n",
    "    range(len(y_train)), \n",
    "    predictions,\n",
    "    color = \"darkgray\",\n",
    "    label ='predicted ignitions'\n",
    ")\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Ignition')\n",
    "plt.title('Predicted vs. actual ignition')\n",
    "plt.legend()\n",
    "plt.xlim(175,195)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "\n",
    "plt.plot(\n",
    "    range(len(y_train)), \n",
    "    y_train,\n",
    "    color = \"darkred\",\n",
    "    label ='True ignitions'\n",
    ")\n",
    "plt.plot(\n",
    "    range(len(y_train)), \n",
    "    predictions,\n",
    "    color = \"darkgray\",\n",
    "    label ='predicted ignitions'\n",
    ")\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Ignition')\n",
    "plt.title('Predicted vs. actual ignition')\n",
    "plt.legend()\n",
    "plt.xlim(195,215)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "\n",
    "plt.plot(\n",
    "    range(len(y_train)), \n",
    "    y_train,\n",
    "    color = \"darkred\",\n",
    "    label ='True ignitions'\n",
    ")\n",
    "plt.plot(\n",
    "    range(len(y_train)), \n",
    "    predictions,\n",
    "    color = \"darkgray\",\n",
    "    label ='predicted ignitions'\n",
    ")\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Ignition')\n",
    "plt.title('Predicted vs. actual ignition')\n",
    "plt.legend()\n",
    "#plt.xlim(195,215)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
